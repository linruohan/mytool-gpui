# MyTool GPUI å¾…åŠäº‹é¡¹åº”ç”¨ - å…¨é¢ä¼˜åŒ–æ–¹æ¡ˆ

> åŸºäº Rust + GPUI æ¡†æ¶çš„å¾…åŠäº‹é¡¹ç®¡ç†åº”ç”¨æ·±åº¦åˆ†æä¸ä¼˜åŒ–å»ºè®®
> 
> åˆ†ææ—¥æœŸï¼š2026-02-19
> é¡¹ç›®ç‰ˆæœ¬ï¼š0.2.2

---

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è§ˆ](#é¡¹ç›®æ¦‚è§ˆ)
2. [æ¶æ„åˆ†æ](#æ¶æ„åˆ†æ)
3. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
4. [UI/UX ä¼˜åŒ–](#uiux-ä¼˜åŒ–)
5. [ä»£ç è´¨é‡ä¼˜åŒ–](#ä»£ç è´¨é‡ä¼˜åŒ–)
6. [æ•°æ®æµä¼˜åŒ–](#æ•°æ®æµä¼˜åŒ–)
7. [å®‰å…¨æ€§ä¼˜åŒ–](#å®‰å…¨æ€§ä¼˜åŒ–)
8. [å¯ç»´æŠ¤æ€§ä¼˜åŒ–](#å¯ç»´æŠ¤æ€§ä¼˜åŒ–)
9. [ä¼˜å…ˆçº§å»ºè®®](#ä¼˜å…ˆçº§å»ºè®®)

---

## ğŸ¯ é¡¹ç›®æ¦‚è§ˆ

### æŠ€æœ¯æ ˆ
- **UI æ¡†æ¶**: GPUI (Zed ç¼–è¾‘å™¨æ¡†æ¶)
- **è¯­è¨€**: Rust (Edition 2024)
- **æ•°æ®åº“**: SQLite (SeaORM)
- **å¼‚æ­¥è¿è¡Œæ—¶**: Tokio
- **æ¶æ„æ¨¡å¼**: å•å‘æ•°æ®æµ + è§‚å¯Ÿè€…æ¨¡å¼

### æ ¸å¿ƒæ¨¡å—
```
mytool/          # ä¸»åº”ç”¨ (UI + ä¸šåŠ¡é€»è¾‘)
â”œâ”€â”€ views/       # è§†å›¾å±‚
â”œâ”€â”€ components/  # å¯å¤ç”¨ç»„ä»¶
â”œâ”€â”€ state_service/  # æ•°æ®åŠ è½½å±‚
â”œâ”€â”€ todo_actions/   # ä¸šåŠ¡æ“ä½œå±‚
â”œâ”€â”€ todo_state/     # çŠ¶æ€ç®¡ç†å±‚
â””â”€â”€ plugins/     # æ’ä»¶ç³»ç»Ÿ

todos/           # æ ¸å¿ƒæ•°æ®åº“æ“ä½œåº“
â”œâ”€â”€ entity/      # æ•°æ®æ¨¡å‹
â”œâ”€â”€ services/    # ä¸šåŠ¡æœåŠ¡
â””â”€â”€ repositories/  # æ•°æ®è®¿é—®å±‚

gconfig/         # å…¨å±€é…ç½®ç®¡ç†
```


---

## ğŸ—ï¸ æ¶æ„åˆ†æ

### å½“å‰æ¶æ„ä¼˜åŠ¿

#### âœ… 1. å•ä¸€æ•°æ®æºæ¨¡å¼ (TodoStore)
```rust
// ä¼˜ç§€çš„è®¾è®¡ï¼šæ‰€æœ‰æ•°æ®ç»Ÿä¸€ç®¡ç†
pub struct TodoStore {
    pub all_items: Vec<Arc<ItemModel>>,
    pub projects: Vec<Arc<ProjectModel>>,
    pub labels: Vec<Arc<LabelModel>>,
    pub sections: Vec<Arc<SectionModel>>,
    
    // ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
    project_index: HashMap<String, Vec<Arc<ItemModel>>>,
    section_index: HashMap<String, Vec<Arc<ItemModel>>>,
    checked_set: HashSet<String>,
    pinned_set: HashSet<String>,
}
```

**ä¼˜ç‚¹**:
- é¿å…çŠ¶æ€ä¸ä¸€è‡´
- å†…å­˜è¿‡æ»¤æ›¿ä»£æ•°æ®åº“æŸ¥è¯¢
- å“åº”å¼æ›´æ–°æœºåˆ¶

#### âœ… 2. åˆ†å±‚æ¶æ„æ¸…æ™°
```
UI Layer (Views/Components)
    â†“ è§‚å¯Ÿè€…æ¨¡å¼
State Layer (TodoStore)
    â†“ ä¸šåŠ¡æ“ä½œ
Action Layer (todo_actions)
    â†“ æ•°æ®åŠ è½½
Service Layer (state_service)
    â†“ æ•°æ®åº“æ“ä½œ
Repository Layer (todos::Store)
```

#### âœ… 3. å¢é‡æ›´æ–°ç­–ç•¥
```rust
// åªæ›´æ–°å˜åŒ–çš„æ•°æ®ï¼Œä¸å…¨é‡åˆ·æ–°
pub fn add_item(&mut self, item: Arc<ItemModel>) {
    self.all_items.push(item.clone());
    self.rebuild_indexes();  // åªé‡å»ºç´¢å¼•
}
```

### æ¶æ„é—®é¢˜ä¸æ”¹è¿›

#### âš ï¸ é—®é¢˜ 1: è¿‡åº¦çš„è§‚å¯Ÿè€…è®¢é˜…

**ç°çŠ¶**:
```rust
// board_inbox.rs - æ¯ä¸ªè§†å›¾éƒ½è®¢é˜…å…¨å±€çŠ¶æ€
cx.observe_global_in::<TodoStore>(window, move |this, window, cx| {
    let state_items = cx.global::<TodoStore>().inbox_items();
    // é‡æ–°è®¡ç®—æ‰€æœ‰æ•°æ®...
    this.base.item_rows = state_items.iter()...
    this.base.no_section_items.clear();
    this.base.section_items_map.clear();
    // ...
});
```

**é—®é¢˜**:
- ä»»ä½• TodoStore å˜åŒ–éƒ½ä¼šè§¦å‘æ‰€æœ‰è§†å›¾é‡æ–°è®¡ç®—
- å³ä½¿å˜åŒ–ä¸å½“å‰è§†å›¾æ— å…³
- å¤§é‡ä¸å¿…è¦çš„å†…å­˜åˆ†é…å’Œè®¡ç®—

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```rust
// æ–¹æ¡ˆ 1: ç»†ç²’åº¦äº‹ä»¶ç³»ç»Ÿ
pub enum TodoStoreEvent {
    ItemAdded(String),           // åªä¼ é€’ ID
    ItemUpdated(String),
    ItemDeleted(String),
    ProjectChanged(String),
    BulkUpdate,                  // æ‰¹é‡æ›´æ–°æ—¶æ‰å…¨é‡åˆ·æ–°
}

// æ–¹æ¡ˆ 2: è„æ ‡è®° + æ‡’åŠ è½½
pub struct TodoStore {
    // ... ç°æœ‰å­—æ®µ
    dirty_items: HashSet<String>,     // æ ‡è®°å˜åŒ–çš„é¡¹
    dirty_projects: HashSet<String>,
    version: usize,                   // ç‰ˆæœ¬å·
}

impl TodoStore {
    pub fn inbox_items_cached(&self, last_version: &mut usize) -> Option<Vec<Arc<ItemModel>>> {
        if *last_version == self.version {
            return None;  // æ— å˜åŒ–ï¼Œè¿”å› None
        }
        *last_version = self.version;
        Some(self.inbox_items())
    }
}

// è§†å›¾å±‚ä½¿ç”¨
struct InboxBoard {
    cached_version: usize,
    cached_items: Vec<Arc<ItemModel>>,
}

// åªåœ¨ç‰ˆæœ¬å˜åŒ–æ—¶æ›´æ–°
if let Some(new_items) = store.inbox_items_cached(&mut this.cached_version) {
    this.cached_items = new_items;
    // é‡æ–°æ¸²æŸ“...
}
```

#### âš ï¸ é—®é¢˜ 2: ç´¢å¼•é‡å»ºæ•ˆç‡ä½

**ç°çŠ¶**:
```rust
fn rebuild_indexes(&mut self) {
    self.project_index.clear();
    self.section_index.clear();
    // éå†æ‰€æœ‰ä»»åŠ¡é‡å»ºç´¢å¼•
    for item in &self.all_items {
        // ...
    }
}
```

**é—®é¢˜**:
- æ¯æ¬¡å•ä¸ªä»»åŠ¡å˜åŒ–éƒ½é‡å»ºå…¨éƒ¨ç´¢å¼•
- O(n) å¤æ‚åº¦ï¼Œæ•°æ®é‡å¤§æ—¶æ€§èƒ½å·®

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// å¢é‡ç´¢å¼•æ›´æ–°
impl TodoStore {
    pub fn add_item(&mut self, item: Arc<ItemModel>) {
        self.all_items.push(item.clone());
        
        // åªæ›´æ–°ç›¸å…³ç´¢å¼•
        if let Some(project_id) = &item.project_id {
            self.project_index.entry(project_id.clone())
                .or_default()
                .push(item.clone());
        }
        
        if item.checked {
            self.checked_set.insert(item.id.clone());
        }
        
        self.version += 1;  // å¢åŠ ç‰ˆæœ¬å·
    }
    
    pub fn update_item(&mut self, item: Arc<ItemModel>) {
        // æ‰¾åˆ°æ—§é¡¹å¹¶ç§»é™¤ç´¢å¼•
        if let Some(pos) = self.all_items.iter().position(|i| i.id == item.id) {
            let old_item = &self.all_items[pos];
            self.remove_from_indexes(old_item);
            self.all_items[pos] = item.clone();
            self.add_to_indexes(&item);
        }
        self.version += 1;
    }
    
    fn remove_from_indexes(&mut self, item: &ItemModel) {
        // ç²¾ç¡®ç§»é™¤ï¼Œä¸é‡å»ºå…¨éƒ¨
        if let Some(project_id) = &item.project_id {
            if let Some(items) = self.project_index.get_mut(project_id) {
                items.retain(|i| i.id != item.id);
            }
        }
        self.checked_set.remove(&item.id);
        self.pinned_set.remove(&item.id);
    }
}
```

#### âš ï¸ é—®é¢˜ 3: æ•°æ®åº“è¿æ¥ç®¡ç†

**ç°çŠ¶**:
```rust
// æ¯æ¬¡æ“ä½œéƒ½å…‹éš†è¿æ¥
let db = cx.global::<DBState>().conn.clone();
cx.spawn(async move |cx| {
    Store::new(db).insert_item(...).await
})
```

**é—®é¢˜**:
- é¢‘ç¹å…‹éš† DatabaseConnection
- æ²¡æœ‰è¿æ¥æ± ç®¡ç†
- å¯èƒ½å¯¼è‡´è¿æ¥æ³„æ¼

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// ä½¿ç”¨ Arc åŒ…è£…ï¼Œé¿å…å…‹éš†
pub struct DBState {
    conn: Arc<DatabaseConnection>,
}

// æˆ–è€…ä½¿ç”¨è¿æ¥æ± 
use sea_orm::DatabaseConnection;
use std::sync::Arc;

pub struct ConnectionPool {
    pool: Arc<DatabaseConnection>,
    max_connections: usize,
}

impl ConnectionPool {
    pub async fn get(&self) -> Result<Arc<DatabaseConnection>, TodoError> {
        // å®ç°è¿æ¥æ± é€»è¾‘
        Ok(self.pool.clone())
    }
}
```



---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. ç¼–è¯‘æ€§èƒ½ä¼˜åŒ–

#### å½“å‰é…ç½®åˆ†æ
```toml
[profile.dev]
codegen-units = 16
opt-level = 0
debug = 0
```

**é—®é¢˜**: å¼€å‘æ¨¡å¼ç¼–è¯‘æ…¢ï¼Œä¾èµ–ä¼˜åŒ–çº§åˆ«ä¸ä¸€è‡´

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```toml
[profile.dev]
# å¢åŠ å¹¶è¡Œç¼–è¯‘å•å…ƒ
codegen-units = 256
opt-level = 0
# å¯ç”¨å¢é‡ç¼–è¯‘
incremental = true
# åˆ†ç¦»è°ƒè¯•ä¿¡æ¯ï¼ˆä»… macOS/Linuxï¼‰
split-debuginfo = "unpacked"

[profile.dev.package]
# å…³é”®ä¾èµ–ä½¿ç”¨é«˜ä¼˜åŒ–
gpui = { opt-level = 3 }
sea-orm = { opt-level = 3 }
tokio = { opt-level = 3 }
# å…¶ä»–ä¾èµ–ä½¿ç”¨ä¸­ç­‰ä¼˜åŒ–
"*" = { opt-level = 1 }

# æ–°å¢ï¼šè¶…å¿«é€Ÿå¼€å‘æ¨¡å¼
[profile.fast-dev]
inherits = "dev"
codegen-units = 256
opt-level = 0
incremental = false  # é…åˆ sccache ä½¿ç”¨
debug = 0
lto = false
```

**ä½¿ç”¨æ–¹å¼**:
```bash
# å¿«é€Ÿç¼–è¯‘ï¼ˆå¼€å‘æ—¶ï¼‰
cargo build --profile fast-dev

# æ­£å¸¸å¼€å‘ï¼ˆéœ€è¦è°ƒè¯•ï¼‰
cargo build

# å‘å¸ƒæ„å»º
cargo build --release
```

### 2. è¿è¡Œæ—¶æ€§èƒ½ä¼˜åŒ–

#### é—®é¢˜ 1: é¢‘ç¹çš„ Vec åˆ†é…

**ç°çŠ¶**:
```rust
// æ¯æ¬¡è¿‡æ»¤éƒ½åˆ›å»ºæ–° Vec
pub fn inbox_items(&self) -> Vec<Arc<ItemModel>> {
    self.all_items
        .iter()
        .filter(|item| !item.checked && item.project_id.is_none())
        .cloned()
        .collect()
}
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// æ–¹æ¡ˆ 1: è¿”å›è¿­ä»£å™¨
pub fn inbox_items_iter(&self) -> impl Iterator<Item = &Arc<ItemModel>> {
    self.all_items
        .iter()
        .filter(|item| !item.checked && item.project_id.is_none())
}

// æ–¹æ¡ˆ 2: ä½¿ç”¨ SmallVec å‡å°‘å †åˆ†é…
use smallvec::SmallVec;

pub fn inbox_items(&self) -> SmallVec<[Arc<ItemModel>; 32]> {
    self.all_items
        .iter()
        .filter(|item| !item.checked && item.project_id.is_none())
        .cloned()
        .collect()
}

// æ–¹æ¡ˆ 3: ç¼“å­˜ç»“æœ
pub struct TodoStore {
    // ... ç°æœ‰å­—æ®µ
    inbox_cache: RefCell<Option<Vec<Arc<ItemModel>>>>,
    inbox_cache_version: Cell<usize>,
}

impl TodoStore {
    pub fn inbox_items(&self) -> Vec<Arc<ItemModel>> {
        if self.inbox_cache_version.get() == self.version {
            return self.inbox_cache.borrow().clone().unwrap();
        }
        
        let items = self.all_items
            .iter()
            .filter(|item| !item.checked && item.project_id.is_none())
            .cloned()
            .collect();
        
        *self.inbox_cache.borrow_mut() = Some(items.clone());
        self.inbox_cache_version.set(self.version);
        items
    }
}
```

#### é—®é¢˜ 2: å­—ç¬¦ä¸²æ¯”è¾ƒæ•ˆç‡

**ç°çŠ¶**:
```rust
// é¢‘ç¹çš„å­—ç¬¦ä¸²æ¯”è¾ƒ
if item.project_id.as_deref() == Some("") {
    // ...
}
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// ä½¿ç”¨å†…è”å‡½æ•°
#[inline]
fn is_empty_or_none(s: &Option<String>) -> bool {
    matches!(s, None | Some(s) if s.is_empty())
}

// æˆ–ä½¿ç”¨ Option çš„æ–¹æ³•
item.project_id.as_ref().map_or(true, |s| s.is_empty())
```

#### é—®é¢˜ 3: å¼‚æ­¥ä»»åŠ¡å¼€é”€

**ç°çŠ¶**:
```rust
// æ¯ä¸ªæ“ä½œéƒ½ spawn æ–°ä»»åŠ¡
pub fn add_item(item: Arc<ItemModel>, cx: &mut App) {
    let db = cx.global::<DBState>().conn.clone();
    cx.spawn(async move |cx| {
        // ...
    }).detach();
}
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// æ‰¹é‡æ“ä½œ
pub struct BatchOperations {
    pending_adds: Vec<Arc<ItemModel>>,
    pending_updates: Vec<Arc<ItemModel>>,
    pending_deletes: Vec<String>,
}

impl BatchOperations {
    pub fn flush(&mut self, db: Arc<DatabaseConnection>) -> impl Future<Output = ()> {
        let adds = std::mem::take(&mut self.pending_adds);
        let updates = std::mem::take(&mut self.pending_updates);
        let deletes = std::mem::take(&mut self.pending_deletes);
        
        async move {
            // æ‰¹é‡æ’å…¥
            if !adds.is_empty() {
                Store::new((*db).clone()).batch_insert_items(adds).await;
            }
            // æ‰¹é‡æ›´æ–°
            if !updates.is_empty() {
                Store::new((*db).clone()).batch_update_items(updates).await;
            }
            // æ‰¹é‡åˆ é™¤
            if !deletes.is_empty() {
                Store::new((*db).clone()).batch_delete_items(deletes).await;
            }
        }
    }
}

// ä½¿ç”¨é˜²æŠ–
use std::time::Duration;

pub fn add_item_debounced(item: Arc<ItemModel>, cx: &mut App) {
    cx.global_mut::<BatchOperations>().pending_adds.push(item);
    
    // 300ms åæ‰¹é‡æäº¤
    cx.spawn_after(Duration::from_millis(300), |cx| async move {
        let ops = cx.global_mut::<BatchOperations>();
        ops.flush(cx.global::<DBState>().conn.clone()).await;
    }).detach();
}
```

### 3. å†…å­˜ä¼˜åŒ–

#### é—®é¢˜: Arc è¿‡åº¦ä½¿ç”¨

**ç°çŠ¶**:
```rust
pub struct TodoStore {
    pub all_items: Vec<Arc<ItemModel>>,  // Arc å¥— Vec
    pub projects: Vec<Arc<ProjectModel>>,
}
```

**åˆ†æ**:
- Arc æœ‰é¢å¤–çš„å¼•ç”¨è®¡æ•°å¼€é”€
- å°å¯¹è±¡ä½¿ç”¨ Arc å¯èƒ½å¾—ä¸å¿å¤±

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// æ–¹æ¡ˆ 1: ä½¿ç”¨ Rcï¼ˆå•çº¿ç¨‹åœºæ™¯ï¼‰
use std::rc::Rc;
pub struct TodoStore {
    pub all_items: Vec<Rc<ItemModel>>,
}

// æ–¹æ¡ˆ 2: ä½¿ç”¨ Arena åˆ†é…å™¨
use typed_arena::Arena;

pub struct TodoStore {
    arena: Arena<ItemModel>,
    all_items: Vec<&'arena ItemModel>,
}

// æ–¹æ¡ˆ 3: æ··åˆç­–ç•¥
pub struct TodoStore {
    // å¤§å¯¹è±¡ä½¿ç”¨ Arc
    pub all_items: Vec<Arc<ItemModel>>,
    // å°å¯¹è±¡ç›´æ¥å­˜å‚¨
    pub sections: Vec<SectionModel>,  // ç§»é™¤ Arc
}
```



---

## ğŸ¨ UI/UX ä¼˜åŒ–

### 1. è§†è§‰è®¾è®¡ä¼˜åŒ–

#### å½“å‰é—®é¢˜
- ç¼ºå°‘è§†è§‰å±‚æ¬¡æ„Ÿ
- é¢œè‰²ä½¿ç”¨å•è°ƒ
- äº¤äº’åé¦ˆä¸æ˜æ˜¾

#### ä¼˜åŒ–æ–¹æ¡ˆ

##### 1.1 å¢å¼ºè§†è§‰å±‚æ¬¡
```rust
// å½“å‰: æ‰å¹³åŒ–è®¾è®¡
div().border_3().rounded(px(5.0))

// ä¼˜åŒ–: æ·»åŠ é˜´å½±å’Œå±‚æ¬¡
div()
    .border_1()
    .rounded(px(8.0))
    .shadow_md()  // æ·»åŠ é˜´å½±
    .bg(cx.theme().card)  // ä½¿ç”¨å¡ç‰‡èƒŒæ™¯è‰²
    .hover(|this| this.shadow_lg())  // æ‚¬åœæ—¶å¢å¼ºé˜´å½±
```

##### 1.2 æ”¹è¿›é¢œè‰²ç³»ç»Ÿ
```rust
// æ–°å¢: è¯­ä¹‰åŒ–é¢œè‰²
pub struct SemanticColors {
    // ä¼˜å…ˆçº§é¢œè‰²
    priority_high: Hsla,      // çº¢è‰²ç³»
    priority_medium: Hsla,    // é»„è‰²ç³»
    priority_low: Hsla,       // è“è‰²ç³»
    
    // çŠ¶æ€é¢œè‰²
    status_completed: Hsla,   // ç»¿è‰²
    status_overdue: Hsla,     // çº¢è‰²
    status_today: Hsla,       // æ©™è‰²
    
    // äº¤äº’é¢œè‰²
    hover_overlay: Hsla,      // åŠé€æ˜ç™½è‰²
    active_overlay: Hsla,     // åŠé€æ˜è“è‰²
}

// ä½¿ç”¨ç¤ºä¾‹
fn render_item(&self, item: &ItemModel, cx: &App) -> impl IntoElement {
    let priority_color = match item.priority {
        Priority::High => cx.theme().semantic.priority_high,
        Priority::Medium => cx.theme().semantic.priority_medium,
        Priority::Low => cx.theme().semantic.priority_low,
    };
    
    div()
        .border_l_4()
        .border_color(priority_color)
        .child(item.content.clone())
}
```

##### 1.3 åŠ¨ç”»å’Œè¿‡æ¸¡
```rust
// æ·»åŠ å¹³æ»‘è¿‡æ¸¡
use gpui::Animation;

div()
    .transition(Duration::from_millis(200))  // 200ms è¿‡æ¸¡
    .when(is_completed, |this| {
        this.opacity(0.6)
            .text_decoration_line_through()
    })

// æ·»åŠ å¾®äº¤äº’
Button::new("complete")
    .on_click(move |_, window, cx| {
        // æ’­æ”¾å®ŒæˆéŸ³æ•ˆ
        play_ogg_file("assets/sounds/success.ogg");
        
        // æ˜¾ç¤ºå®ŒæˆåŠ¨ç”»
        window.show_toast("âœ“ Task completed!", cx);
    })
```

### 2. äº¤äº’ä½“éªŒä¼˜åŒ–

#### 2.1 é”®ç›˜å¿«æ·é”®ç³»ç»Ÿ
```rust
// å½“å‰: ç¼ºå°‘å…¨å±€å¿«æ·é”®

// ä¼˜åŒ–: æ·»åŠ å®Œæ•´çš„å¿«æ·é”®ç³»ç»Ÿ
pub fn register_keybindings(cx: &mut App) {
    // ä»»åŠ¡æ“ä½œ
    cx.bind_keys([
        KeyBinding::new("cmd-n", AddItem, None),           // æ–°å»ºä»»åŠ¡
        KeyBinding::new("cmd-e", EditItem, None),          // ç¼–è¾‘ä»»åŠ¡
        KeyBinding::new("cmd-d", DeleteItem, None),        // åˆ é™¤ä»»åŠ¡
        KeyBinding::new("cmd-enter", CompleteItem, None),  // å®Œæˆä»»åŠ¡
        KeyBinding::new("cmd-p", PinItem, None),           // ç½®é¡¶ä»»åŠ¡
        
        // å¯¼èˆª
        KeyBinding::new("cmd-1", ShowInbox, None),         // æ”¶ä»¶ç®±
        KeyBinding::new("cmd-2", ShowToday, None),         // ä»Šæ—¥ä»»åŠ¡
        KeyBinding::new("cmd-3", ShowScheduled, None),     // è®¡åˆ’ä»»åŠ¡
        
        // æœç´¢å’Œè¿‡æ»¤
        KeyBinding::new("cmd-f", SearchItems, None),       // æœç´¢
        KeyBinding::new("cmd-shift-f", FilterByLabel, None), // æŒ‰æ ‡ç­¾è¿‡æ»¤
    ]);
}
```

#### 2.2 æ‹–æ‹½æ’åº
```rust
// æ·»åŠ æ‹–æ‹½åŠŸèƒ½
use gpui::DragAndDrop;

impl ItemRow {
    fn render(&mut self, window: &mut Window, cx: &mut Context<Self>) -> impl IntoElement {
        div()
            .draggable(self.item.id.clone())
            .on_drag_start(|item_id, cx| {
                cx.set_drag_data(item_id);
            })
            .on_drop(|dropped_id, target_id, cx| {
                // é‡æ–°æ’åº
                reorder_items(dropped_id, target_id, cx);
            })
            .child(/* ... */)
    }
}
```

#### 2.3 æ™ºèƒ½è¾“å…¥
```rust
// è‡ªç„¶è¯­è¨€è§£æ
pub fn parse_task_input(input: &str) -> ParsedTask {
    let mut task = ParsedTask::default();
    
    // è§£ææ—¥æœŸ: "æ˜å¤©", "ä¸‹å‘¨ä¸€", "2026-03-01"
    if let Some(date) = extract_date(input) {
        task.due_date = Some(date);
    }
    
    // è§£æä¼˜å…ˆçº§: "!é«˜", "!!!", "p1"
    if let Some(priority) = extract_priority(input) {
        task.priority = priority;
    }
    
    // è§£ææ ‡ç­¾: "#å·¥ä½œ", "#ä¸ªäºº"
    task.labels = extract_labels(input);
    
    // è§£æé¡¹ç›®: "@é¡¹ç›®å"
    task.project = extract_project(input);
    
    task
}

// ä½¿ç”¨ç¤ºä¾‹
// è¾“å…¥: "æ˜å¤©å®ŒæˆæŠ¥å‘Š #å·¥ä½œ !é«˜ @å­£åº¦æ€»ç»“"
// è§£æç»“æœ:
// - å†…å®¹: "å®ŒæˆæŠ¥å‘Š"
// - æˆªæ­¢æ—¥æœŸ: 2026-02-20
// - æ ‡ç­¾: ["å·¥ä½œ"]
// - ä¼˜å…ˆçº§: High
// - é¡¹ç›®: "å­£åº¦æ€»ç»“"
```

### 3. å“åº”å¼å¸ƒå±€

#### å½“å‰é—®é¢˜
- å›ºå®šå¸ƒå±€ï¼Œä¸é€‚åº”çª—å£å¤§å°å˜åŒ–
- å°çª—å£æ—¶å†…å®¹è¢«æˆªæ–­

#### ä¼˜åŒ–æ–¹æ¡ˆ
```rust
// å“åº”å¼å¸ƒå±€
pub fn render_responsive(&self, window: &mut Window, cx: &mut Context<Self>) -> impl IntoElement {
    let window_size = window.viewport_size();
    let is_compact = window_size.width < px(800.0);
    
    v_flex()
        .when(is_compact, |this| {
            // ç´§å‡‘æ¨¡å¼: å‚ç›´å¸ƒå±€
            this.flex_col()
                .child(self.render_sidebar_compact(cx))
                .child(self.render_content(cx))
        })
        .when(!is_compact, |this| {
            // æ­£å¸¸æ¨¡å¼: æ°´å¹³å¸ƒå±€
            this.flex_row()
                .child(self.render_sidebar(cx).w(px(250.0)))
                .child(self.render_content(cx).flex_1())
        })
}
```

### 4. å¯è®¿é—®æ€§ä¼˜åŒ–

```rust
// æ·»åŠ  ARIA æ ‡ç­¾å’Œé”®ç›˜å¯¼èˆª
Button::new("add-task")
    .label("Add Task")
    .aria_label("Add a new task to inbox")  // å±å¹•é˜…è¯»å™¨
    .keyboard_shortcut("Cmd+N")
    .tooltip("Add Task (Cmd+N)")

// ç„¦ç‚¹ç®¡ç†
impl Focusable for InboxBoard {
    fn focus_handle(&self, cx: &App) -> FocusHandle {
        self.base.focus_handle.clone()
    }
}

// é”®ç›˜å¯¼èˆª
cx.on_key_down(|event, window, cx| {
    match event.key {
        Key::ArrowUp => self.select_previous_item(cx),
        Key::ArrowDown => self.select_next_item(cx),
        Key::Enter => self.edit_selected_item(window, cx),
        Key::Delete => self.delete_selected_item(window, cx),
        _ => {}
    }
});
```



---

## ğŸ“Š æ•°æ®æµä¼˜åŒ–

### 1. å½“å‰æ•°æ®æµåˆ†æ

```mermaid
graph TB
    A[ç”¨æˆ·æ“ä½œ] --> B[View Layer]
    B --> C[todo_actions]
    C --> D[state_service]
    D --> E[todos::Store]
    E --> F[Database]
    F --> E
    E --> D
    D --> G[TodoStore]
    G --> H[è§‚å¯Ÿè€…é€šçŸ¥]
    H --> B
```

### 2. æ•°æ®æµé—®é¢˜

#### é—®é¢˜ 1: è¿‡åº¦çš„æ•°æ®åº“æŸ¥è¯¢

**ç°çŠ¶**:
```rust
// æ¯æ¬¡æ“ä½œåéƒ½é‡æ–°åŠ è½½å…¨éƒ¨æ•°æ®
pub async fn add_item(...) {
    Store::new(db).insert_item(...).await?;
    // ç„¶ååœ¨ todo_actions ä¸­é‡æ–°åŠ è½½æ‰€æœ‰ä»»åŠ¡
    let items = load_items(db).await;
    cx.update_global::<TodoStore>(|store, _| {
        store.set_items(items);  // å…¨é‡æ›¿æ¢
    });
}
```

**é—®é¢˜**:
- æ·»åŠ ä¸€ä¸ªä»»åŠ¡ï¼Œå´é‡æ–°åŠ è½½æ‰€æœ‰ä»»åŠ¡
- æ•°æ®åº“ I/O å¼€é”€å¤§
- ç½‘ç»œå»¶è¿Ÿï¼ˆå¦‚æœä½¿ç”¨è¿œç¨‹æ•°æ®åº“ï¼‰

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// æ–¹æ¡ˆ 1: å¢é‡æ›´æ–°ï¼ˆå·²éƒ¨åˆ†å®ç°ï¼Œéœ€å®Œå–„ï¼‰
pub async fn add_item(item: Arc<ItemModel>, cx: &mut App) {
    let db = cx.global::<DBState>().conn.clone();
    
    match state_service::add_item(item.clone(), db).await {
        Ok(new_item) => {
            // åªæ·»åŠ æ–°ä»»åŠ¡ï¼Œä¸é‡æ–°åŠ è½½
            cx.update_global::<TodoStore>(|store, _| {
                store.add_item(Arc::new(new_item));
            });
        }
        Err(e) => {
            // é”™è¯¯å¤„ç†
            window.show_error(&format!("Failed to add item: {}", e), cx);
        }
    }
}

// æ–¹æ¡ˆ 2: ä¹è§‚æ›´æ–°
pub fn add_item_optimistic(item: Arc<ItemModel>, cx: &mut App) {
    // 1. ç«‹å³æ›´æ–° UIï¼ˆä¹è§‚æ›´æ–°ï¼‰
    let temp_id = uuid::Uuid::new_v4().to_string();
    let mut optimistic_item = (*item).clone();
    optimistic_item.id = temp_id.clone();
    
    cx.update_global::<TodoStore>(|store, _| {
        store.add_item(Arc::new(optimistic_item.clone()));
    });
    
    // 2. å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
    let db = cx.global::<DBState>().conn.clone();
    cx.spawn(async move |cx| {
        match state_service::add_item(item, db).await {
            Ok(saved_item) => {
                // 3. ç”¨çœŸå® ID æ›¿æ¢ä¸´æ—¶ ID
                cx.update_global::<TodoStore>(|store, _| {
                    store.replace_item(&temp_id, Arc::new(saved_item));
                });
            }
            Err(e) => {
                // 4. å¤±è´¥æ—¶å›æ»š
                cx.update_global::<TodoStore>(|store, _| {
                    store.remove_item(&temp_id);
                });
                // æ˜¾ç¤ºé”™è¯¯
                cx.show_error(&format!("Failed to add item: {}", e));
            }
        }
    }).detach();
}
```

#### é—®é¢˜ 2: çŠ¶æ€åŒæ­¥å»¶è¿Ÿ

**ç°çŠ¶**:
```rust
// ItemRow é€šè¿‡è§‚å¯Ÿè€…æ›´æ–°ï¼Œå¯èƒ½æœ‰å»¶è¿Ÿ
cx.observe_global_in::<TodoStore>(window, move |this, window, cx| {
    // æ›´æ–° item
});
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// ä½¿ç”¨äº‹ä»¶æ€»çº¿å®ç°å³æ—¶é€šçŸ¥
pub struct TodoEventBus {
    subscribers: HashMap<String, Vec<Box<dyn Fn(&TodoEvent)>>>,
}

pub enum TodoEvent {
    ItemUpdated(Arc<ItemModel>),
    ItemDeleted(String),
    // ...
}

impl TodoEventBus {
    pub fn subscribe(&mut self, item_id: String, callback: impl Fn(&TodoEvent) + 'static) {
        self.subscribers.entry(item_id).or_default().push(Box::new(callback));
    }
    
    pub fn publish(&self, event: TodoEvent) {
        if let TodoEvent::ItemUpdated(item) = &event {
            if let Some(callbacks) = self.subscribers.get(&item.id) {
                for callback in callbacks {
                    callback(&event);
                }
            }
        }
    }
}

// ä½¿ç”¨
impl ItemRowState {
    pub fn new(item: Arc<ItemModel>, window: &mut Window, cx: &mut Context<Self>) -> Self {
        let item_id = item.id.clone();
        let view = cx.entity();
        
        // è®¢é˜…ç‰¹å®šä»»åŠ¡çš„æ›´æ–°
        cx.global_mut::<TodoEventBus>().subscribe(item_id, move |event| {
            if let TodoEvent::ItemUpdated(updated_item) = event {
                view.update(cx, |this, cx| {
                    this.item = updated_item.clone();
                    cx.notify();
                });
            }
        });
        
        Self { item, /* ... */ }
    }
}
```

### 3. ç¦»çº¿æ”¯æŒ

```rust
// æ·»åŠ ç¦»çº¿é˜Ÿåˆ—
pub struct OfflineQueue {
    pending_operations: Vec<PendingOperation>,
    is_online: bool,
}

pub enum PendingOperation {
    AddItem(ItemModel),
    UpdateItem(ItemModel),
    DeleteItem(String),
}

impl OfflineQueue {
    pub fn enqueue(&mut self, op: PendingOperation) {
        self.pending_operations.push(op);
        
        if self.is_online {
            self.flush();
        }
    }
    
    pub async fn flush(&mut self) {
        while let Some(op) = self.pending_operations.pop() {
            match op {
                PendingOperation::AddItem(item) => {
                    // å°è¯•åŒæ­¥åˆ°æœåŠ¡å™¨
                    if let Err(e) = sync_add_item(item).await {
                        // å¤±è´¥æ—¶é‡æ–°å…¥é˜Ÿ
                        self.pending_operations.push(PendingOperation::AddItem(item));
                        break;
                    }
                }
                // ...
            }
        }
    }
}
```

### 4. æ•°æ®é¢„åŠ è½½

```rust
// é¢„åŠ è½½ç›¸å…³æ•°æ®
pub async fn preload_related_data(project_id: &str, db: Arc<DatabaseConnection>) {
    tokio::join!(
        load_project_items(project_id, db.clone()),
        load_project_sections(project_id, db.clone()),
        load_project_labels(project_id, db.clone()),
    );
}

// æ™ºèƒ½é¢„æµ‹
pub fn predict_next_view(current_view: &str) -> Vec<String> {
    match current_view {
        "inbox" => vec!["today", "scheduled"],  // ç”¨æˆ·å¯èƒ½æ¥ä¸‹æ¥æŸ¥çœ‹è¿™äº›
        "today" => vec!["inbox", "completed"],
        _ => vec![],
    }
}

// åå°é¢„åŠ è½½
pub fn preload_predicted_views(predictions: Vec<String>, cx: &mut App) {
    let db = cx.global::<DBState>().conn.clone();
    
    cx.spawn(async move |cx| {
        for view in predictions {
            // é¢„åŠ è½½æ•°æ®åˆ°ç¼“å­˜
            preload_view_data(&view, db.clone()).await;
        }
    }).detach();
}
```



---

## ğŸ”’ å®‰å…¨æ€§ä¼˜åŒ–

### 1. æ•°æ®åŠ å¯†

#### å½“å‰çŠ¶æ€
```rust
// gconfig/src/crypto.rs å·²æœ‰åŠ å¯†åŠŸèƒ½ï¼Œä½†æœªå……åˆ†ä½¿ç”¨
```

#### ä¼˜åŒ–æ–¹æ¡ˆ

##### 1.1 æ•æ„Ÿæ•°æ®åŠ å¯†
```rust
// åŠ å¯†ä»»åŠ¡å†…å®¹ï¼ˆå¦‚æœåŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
pub struct EncryptedItemModel {
    pub id: String,
    pub encrypted_content: Vec<u8>,  // åŠ å¯†åçš„å†…å®¹
    pub nonce: Vec<u8>,              // åŠ å¯†éšæœºæ•°
    pub is_encrypted: bool,          // æ ‡è®°æ˜¯å¦åŠ å¯†
}

impl ItemModel {
    pub fn encrypt(&self, key: &[u8]) -> Result<EncryptedItemModel, CryptoError> {
        use aes_gcm::{Aes256Gcm, KeyInit, Nonce};
        use aes_gcm::aead::Aead;
        
        let cipher = Aes256Gcm::new_from_slice(key)?;
        let nonce = Nonce::from_slice(b"unique nonce");
        
        let encrypted_content = cipher.encrypt(nonce, self.content.as_bytes())?;
        
        Ok(EncryptedItemModel {
            id: self.id.clone(),
            encrypted_content,
            nonce: nonce.to_vec(),
            is_encrypted: true,
        })
    }
    
    pub fn decrypt(encrypted: &EncryptedItemModel, key: &[u8]) -> Result<Self, CryptoError> {
        // è§£å¯†é€»è¾‘
        // ...
    }
}
```

##### 1.2 æ•°æ®åº“åŠ å¯†
```rust
// ä½¿ç”¨ SQLCipher åŠ å¯†æ•´ä¸ªæ•°æ®åº“
[dependencies]
sea-orm = { version = "1.1", features = ["sqlx-sqlite", "sqlcipher"] }

// åˆå§‹åŒ–åŠ å¯†æ•°æ®åº“
pub async fn init_encrypted_db(password: &str) -> Result<DatabaseConnection, DbErr> {
    let db_url = format!("sqlite://db.sqlite?key={}", password);
    Database::connect(&db_url).await
}
```

### 2. è¾“å…¥éªŒè¯

```rust
// ä¸¥æ ¼çš„è¾“å…¥éªŒè¯
pub struct ItemValidator;

impl ItemValidator {
    pub fn validate_content(content: &str) -> Result<(), ValidationError> {
        // é•¿åº¦é™åˆ¶
        if content.is_empty() {
            return Err(ValidationError::EmptyContent);
        }
        if content.len() > 10000 {
            return Err(ValidationError::ContentTooLong);
        }
        
        // XSS é˜²æŠ¤ï¼šè¿‡æ»¤å±é™©å­—ç¬¦
        if content.contains("<script>") || content.contains("javascript:") {
            return Err(ValidationError::DangerousContent);
        }
        
        Ok(())
    }
    
    pub fn sanitize_content(content: &str) -> String {
        // HTML è½¬ä¹‰
        content
            .replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
            .replace("\"", "&quot;")
            .replace("'", "&#x27;")
    }
}

// ä½¿ç”¨
pub fn add_item(item: Arc<ItemModel>, cx: &mut App) {
    // éªŒè¯è¾“å…¥
    if let Err(e) = ItemValidator::validate_content(&item.content) {
        window.show_error(&format!("Invalid input: {}", e), cx);
        return;
    }
    
    // æ¸…ç†å†…å®¹
    let mut safe_item = (*item).clone();
    safe_item.content = ItemValidator::sanitize_content(&item.content);
    
    // ç»§ç»­å¤„ç†...
}
```

### 3. æƒé™æ§åˆ¶

```rust
// æ·»åŠ æƒé™ç³»ç»Ÿ
pub enum Permission {
    ReadItem,
    WriteItem,
    DeleteItem,
    ManageProject,
    ManageSettings,
}

pub struct User {
    pub id: String,
    pub permissions: HashSet<Permission>,
}

pub struct PermissionChecker;

impl PermissionChecker {
    pub fn check(user: &User, permission: Permission) -> Result<(), PermissionError> {
        if !user.permissions.contains(&permission) {
            return Err(PermissionError::Forbidden);
        }
        Ok(())
    }
}

// ä½¿ç”¨
pub fn delete_item(item: Arc<ItemModel>, cx: &mut App) {
    let user = cx.global::<CurrentUser>();
    
    // æ£€æŸ¥æƒé™
    if let Err(e) = PermissionChecker::check(user, Permission::DeleteItem) {
        window.show_error("You don't have permission to delete items", cx);
        return;
    }
    
    // ç»§ç»­åˆ é™¤...
}
```

### 4. å®‰å…¨æ—¥å¿—

```rust
// è®°å½•å®‰å…¨ç›¸å…³æ“ä½œ
pub struct SecurityLogger;

impl SecurityLogger {
    pub fn log_access(user_id: &str, resource: &str, action: &str) {
        tracing::info!(
            target: "security",
            user_id = user_id,
            resource = resource,
            action = action,
            timestamp = chrono::Utc::now().to_rfc3339(),
            "Access log"
        );
    }
    
    pub fn log_failed_attempt(user_id: &str, reason: &str) {
        tracing::warn!(
            target: "security",
            user_id = user_id,
            reason = reason,
            timestamp = chrono::Utc::now().to_rfc3339(),
            "Failed access attempt"
        );
    }
}
```

---

## ğŸ› ï¸ ä»£ç è´¨é‡ä¼˜åŒ–

### 1. é”™è¯¯å¤„ç†æ”¹è¿›

#### å½“å‰é—®é¢˜
```rust
// é”™è¯¯è¢«å¿½ç•¥æˆ–ç®€å•æ‰“å°
match crate::state_service::add_item(item, db).await {
    Ok(new_item) => { /* ... */ },
    Err(e) => {
        error!("add_item failed: {:?}", e);  // åªæ‰“å°æ—¥å¿—
    },
}
```

#### ä¼˜åŒ–æ–¹æ¡ˆ
```rust
// å®šä¹‰è¯¦ç»†çš„é”™è¯¯ç±»å‹
#[derive(Debug, thiserror::Error)]
pub enum TodoActionError {
    #[error("Database error: {0}")]
    Database(#[from] TodoError),
    
    #[error("Validation error: {0}")]
    Validation(String),
    
    #[error("Permission denied: {0}")]
    Permission(String),
    
    #[error("Item not found: {0}")]
    NotFound(String),
    
    #[error("Network error: {0}")]
    Network(String),
}

// ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
pub fn handle_error(error: TodoActionError, window: &mut Window, cx: &mut App) {
    match error {
        TodoActionError::Database(e) => {
            window.show_error(&format!("Database error: {}", e), cx);
            tracing::error!("Database error: {:?}", e);
        }
        TodoActionError::Validation(msg) => {
            window.show_warning(&msg, cx);
        }
        TodoActionError::Permission(msg) => {
            window.show_error(&format!("Permission denied: {}", msg), cx);
            SecurityLogger::log_failed_attempt("user_id", &msg);
        }
        TodoActionError::NotFound(id) => {
            window.show_warning(&format!("Item not found: {}", id), cx);
        }
        TodoActionError::Network(msg) => {
            window.show_error(&format!("Network error: {}", msg), cx);
            // æ·»åŠ åˆ°ç¦»çº¿é˜Ÿåˆ—
            cx.global_mut::<OfflineQueue>().mark_offline();
        }
    }
}

// ä½¿ç”¨ Result é“¾å¼å¤„ç†
pub async fn add_item_with_validation(
    item: Arc<ItemModel>,
    cx: &mut App,
) -> Result<(), TodoActionError> {
    // éªŒè¯
    ItemValidator::validate_content(&item.content)
        .map_err(|e| TodoActionError::Validation(e.to_string()))?;
    
    // æ£€æŸ¥æƒé™
    let user = cx.global::<CurrentUser>();
    PermissionChecker::check(user, Permission::WriteItem)
        .map_err(|e| TodoActionError::Permission(e.to_string()))?;
    
    // ä¿å­˜
    let db = cx.global::<DBState>().conn.clone();
    let new_item = state_service::add_item(item, db).await?;
    
    // æ›´æ–°çŠ¶æ€
    cx.update_global::<TodoStore>(|store, _| {
        store.add_item(Arc::new(new_item));
    });
    
    Ok(())
}
```

### 2. æµ‹è¯•è¦†ç›–

```rust
// å•å…ƒæµ‹è¯•
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_inbox_items_filter() {
        let mut store = TodoStore::new();
        
        // æ·»åŠ æµ‹è¯•æ•°æ®
        let item1 = Arc::new(ItemModel {
            id: "1".to_string(),
            content: "Test 1".to_string(),
            checked: false,
            project_id: None,
            ..Default::default()
        });
        
        let item2 = Arc::new(ItemModel {
            id: "2".to_string(),
            content: "Test 2".to_string(),
            checked: false,
            project_id: Some("project1".to_string()),
            ..Default::default()
        });
        
        store.add_item(item1.clone());
        store.add_item(item2.clone());
        
        // éªŒè¯è¿‡æ»¤
        let inbox = store.inbox_items();
        assert_eq!(inbox.len(), 1);
        assert_eq!(inbox[0].id, "1");
    }
    
    #[tokio::test]
    async fn test_add_item_incremental() {
        // é›†æˆæµ‹è¯•
        let db = setup_test_db().await;
        let mut store = TodoStore::new();
        
        let item = Arc::new(ItemModel::default());
        let result = add_item_to_store(item, &mut store, db).await;
        
        assert!(result.is_ok());
        assert_eq!(store.all_items.len(), 1);
    }
}

// æ€§èƒ½æµ‹è¯•
#[cfg(test)]
mod bench {
    use criterion::{black_box, criterion_group, criterion_main, Criterion};
    
    fn bench_inbox_filter(c: &mut Criterion) {
        let mut store = TodoStore::new();
        
        // æ·»åŠ  1000 ä¸ªä»»åŠ¡
        for i in 0..1000 {
            store.add_item(Arc::new(ItemModel {
                id: i.to_string(),
                content: format!("Task {}", i),
                checked: i % 2 == 0,
                project_id: if i % 3 == 0 { Some("p1".to_string()) } else { None },
                ..Default::default()
            }));
        }
        
        c.bench_function("inbox_items", |b| {
            b.iter(|| {
                black_box(store.inbox_items())
            })
        });
    }
    
    criterion_group!(benches, bench_inbox_filter);
    criterion_main!(benches);
}
```

### 3. æ–‡æ¡£å®Œå–„

```rust
//! # TodoStore - ç»Ÿä¸€çš„ä»»åŠ¡çŠ¶æ€ç®¡ç†
//!
//! ## æ¦‚è¿°
//! TodoStore æ˜¯åº”ç”¨ä¸­æ‰€æœ‰ä»»åŠ¡æ•°æ®çš„å”¯ä¸€æ•°æ®æºï¼ˆSingle Source of Truthï¼‰ã€‚
//! å®ƒé€šè¿‡å†…å­˜ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼Œé¿å…é¢‘ç¹çš„æ•°æ®åº“è®¿é—®ã€‚
//!
//! ## æ¶æ„
//! ```text
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚         TodoStore (Global)          â”‚
//! â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
//! â”‚  â”‚  all_items: Vec<Arc<Item>>   â”‚   â”‚
//! â”‚  â”‚  projects: Vec<Arc<Project>> â”‚   â”‚
//! â”‚  â”‚  labels: Vec<Arc<Label>>     â”‚   â”‚
//! â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
//! â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
//! â”‚  â”‚  Indexes (HashMap/HashSet)   â”‚   â”‚
//! â”‚  â”‚  - project_index             â”‚   â”‚
//! â”‚  â”‚  - section_index             â”‚   â”‚
//! â”‚  â”‚  - checked_set               â”‚   â”‚
//! â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//!          â†“ observe_global
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚          Views (Observers)          â”‚
//! â”‚  - InboxBoard                       â”‚
//! â”‚  - TodayBoard                       â”‚
//! â”‚  - ProjectBoard                     â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//! ```
//!
//! ## ä½¿ç”¨ç¤ºä¾‹
//! ```rust
//! // è·å–æ”¶ä»¶ç®±ä»»åŠ¡
//! let inbox = cx.global::<TodoStore>().inbox_items();
//!
//! // æ·»åŠ ä»»åŠ¡ï¼ˆå¢é‡æ›´æ–°ï¼‰
//! cx.update_global::<TodoStore>(|store, _| {
//!     store.add_item(Arc::new(new_item));
//! });
//!
//! // è§‚å¯Ÿå˜åŒ–
//! cx.observe_global::<TodoStore>(|this, cx| {
//!     // è‡ªåŠ¨å“åº”çŠ¶æ€å˜åŒ–
//! });
//! ```
//!
//! ## æ€§èƒ½ç‰¹æ€§
//! - **O(1)** ç´¢å¼•æŸ¥è¯¢ï¼ˆé€šè¿‡ HashMapï¼‰
//! - **å¢é‡æ›´æ–°**ï¼šåªæ›´æ–°å˜åŒ–çš„æ•°æ®
//! - **å†…å­˜è¿‡æ»¤**ï¼šé¿å…æ•°æ®åº“æŸ¥è¯¢
//!
//! ## æ³¨æ„äº‹é¡¹
//! - TodoStore æ˜¯å…¨å±€å•ä¾‹ï¼Œé€šè¿‡ GPUI çš„ Global trait ç®¡ç†
//! - æ‰€æœ‰ä¿®æ”¹å¿…é¡»é€šè¿‡ `update_global` è¿›è¡Œ
//! - ç´¢å¼•ä¼šåœ¨æ•°æ®å˜åŒ–æ—¶è‡ªåŠ¨é‡å»º
```



### 4. ä»£ç ç»„ç»‡ä¼˜åŒ–

#### é—®é¢˜: æ¨¡å—èŒè´£ä¸å¤Ÿæ¸…æ™°

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```rust
// é‡æ–°ç»„ç»‡æ¨¡å—ç»“æ„
crates/mytool/src/
â”œâ”€â”€ core/                    # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ state/              # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ store.rs        # TodoStore
â”‚   â”‚   â”œâ”€â”€ cache.rs        # ç¼“å­˜å±‚
â”‚   â”‚   â””â”€â”€ sync.rs         # åŒæ­¥é€»è¾‘
â”‚   â”œâ”€â”€ actions/            # ä¸šåŠ¡æ“ä½œ
â”‚   â”‚   â”œâ”€â”€ item.rs
â”‚   â”‚   â”œâ”€â”€ project.rs
â”‚   â”‚   â””â”€â”€ batch.rs        # æ‰¹é‡æ“ä½œ
â”‚   â””â”€â”€ services/           # æœåŠ¡å±‚
â”‚       â”œâ”€â”€ database.rs
â”‚       â”œâ”€â”€ validation.rs
â”‚       â””â”€â”€ permission.rs
â”œâ”€â”€ ui/                     # UI å±‚
â”‚   â”œâ”€â”€ views/              # è§†å›¾
â”‚   â”œâ”€â”€ components/         # ç»„ä»¶
â”‚   â”œâ”€â”€ theme/              # ä¸»é¢˜
â”‚   â””â”€â”€ layout/             # å¸ƒå±€
â”œâ”€â”€ domain/                 # é¢†åŸŸæ¨¡å‹
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ validators/
â”‚   â””â”€â”€ events/
â””â”€â”€ infrastructure/         # åŸºç¡€è®¾æ–½
    â”œâ”€â”€ database/
    â”œâ”€â”€ cache/
    â””â”€â”€ logging/
```

---

## ğŸ¯ å¯ç»´æŠ¤æ€§ä¼˜åŒ–

### 1. é…ç½®ç®¡ç†æ”¹è¿›

#### å½“å‰é—®é¢˜
```toml
# application.toml - é…ç½®æ‰å¹³åŒ–
[app]
language = "zh"
theme = "light"
clock_format = "24h"
```

#### ä¼˜åŒ–æ–¹æ¡ˆ
```toml
# application.toml - ç»“æ„åŒ–é…ç½®
[app]
version = "0.2.2"

[app.ui]
language = "zh"
theme = "light"
clock_format = "24h"
font_size = 14
window_size = { width = 1200, height = 800 }

[app.behavior]
auto_save = true
auto_save_interval = 30  # ç§’
confirm_delete = true
enable_shortcuts = true

[app.performance]
cache_size = 1000        # ç¼“å­˜ä»»åŠ¡æ•°é‡
preload_enabled = true
batch_size = 50          # æ‰¹é‡æ“ä½œå¤§å°

[app.sync]
enabled = false
server_url = ""
sync_interval = 300      # ç§’

[database]
db_type = "sqlite"
path = "db.sqlite"
pool_size = 10
backup_enabled = true
backup_interval = 3600   # ç§’

[logging]
level = "info"
file_enabled = true
file_path = "logs/app.log"
max_file_size = "10MB"
max_backups = 5
```

### 2. æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–

```rust
// ç»“æ„åŒ–æ—¥å¿—
use tracing::{info, warn, error, debug, instrument};

#[instrument(skip(cx))]
pub fn add_item(item: Arc<ItemModel>, cx: &mut App) {
    info!(
        item_id = %item.id,
        content_length = item.content.len(),
        has_project = item.project_id.is_some(),
        "Adding new item"
    );
    
    let db = cx.global::<DBState>().conn.clone();
    cx.spawn(async move |cx| {
        let start = std::time::Instant::now();
        
        match state_service::add_item(item.clone(), db).await {
            Ok(new_item) => {
                info!(
                    item_id = %new_item.id,
                    duration_ms = start.elapsed().as_millis(),
                    "Item added successfully"
                );
                
                cx.update_global::<TodoStore>(|store, _| {
                    store.add_item(Arc::new(new_item));
                });
            }
            Err(e) => {
                error!(
                    item_id = %item.id,
                    error = %e,
                    duration_ms = start.elapsed().as_millis(),
                    "Failed to add item"
                );
            }
        }
    }).detach();
}

// æ€§èƒ½ç›‘æ§
pub struct PerformanceMonitor;

impl PerformanceMonitor {
    pub fn track_operation<F, R>(name: &str, f: F) -> R
    where
        F: FnOnce() -> R,
    {
        let start = std::time::Instant::now();
        let result = f();
        let duration = start.elapsed();
        
        if duration.as_millis() > 100 {
            warn!(
                operation = name,
                duration_ms = duration.as_millis(),
                "Slow operation detected"
            );
        } else {
            debug!(
                operation = name,
                duration_ms = duration.as_millis(),
                "Operation completed"
            );
        }
        
        result
    }
}

// ä½¿ç”¨
let items = PerformanceMonitor::track_operation("inbox_items", || {
    store.inbox_items()
});
```

### 3. ç‰ˆæœ¬è¿ç§»

```rust
// æ•°æ®åº“è¿ç§»ç³»ç»Ÿ
pub struct Migration {
    version: u32,
    description: String,
    up: Box<dyn Fn(&DatabaseConnection) -> BoxFuture<'static, Result<(), DbErr>>>,
    down: Box<dyn Fn(&DatabaseConnection) -> BoxFuture<'static, Result<(), DbErr>>>,
}

pub struct MigrationManager {
    migrations: Vec<Migration>,
}

impl MigrationManager {
    pub fn new() -> Self {
        let mut manager = Self { migrations: vec![] };
        
        // æ³¨å†Œè¿ç§»
        manager.add_migration(Migration {
            version: 1,
            description: "Add priority field to items".to_string(),
            up: Box::new(|db| {
                Box::pin(async move {
                    db.execute_unprepared(
                        "ALTER TABLE items ADD COLUMN priority INTEGER DEFAULT 0"
                    ).await?;
                    Ok(())
                })
            }),
            down: Box::new(|db| {
                Box::pin(async move {
                    db.execute_unprepared(
                        "ALTER TABLE items DROP COLUMN priority"
                    ).await?;
                    Ok(())
                })
            }),
        });
        
        manager
    }
    
    pub async fn migrate_to_latest(&self, db: &DatabaseConnection) -> Result<(), DbErr> {
        let current_version = self.get_current_version(db).await?;
        
        for migration in &self.migrations {
            if migration.version > current_version {
                info!("Running migration {}: {}", migration.version, migration.description);
                (migration.up)(db).await?;
                self.set_version(db, migration.version).await?;
            }
        }
        
        Ok(())
    }
}
```

### 4. ç›‘æ§å’Œè¯Šæ–­

```rust
// å¥åº·æ£€æŸ¥
pub struct HealthCheck;

impl HealthCheck {
    pub async fn check_all() -> HealthStatus {
        let mut status = HealthStatus::default();
        
        // æ£€æŸ¥æ•°æ®åº“
        status.database = Self::check_database().await;
        
        // æ£€æŸ¥å†…å­˜ä½¿ç”¨
        status.memory = Self::check_memory();
        
        // æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        status.performance = Self::check_performance();
        
        status
    }
    
    async fn check_database() -> ComponentStatus {
        // å°è¯•ç®€å•æŸ¥è¯¢
        match timeout(Duration::from_secs(5), test_db_query()).await {
            Ok(Ok(_)) => ComponentStatus::Healthy,
            Ok(Err(e)) => ComponentStatus::Unhealthy(e.to_string()),
            Err(_) => ComponentStatus::Unhealthy("Database timeout".to_string()),
        }
    }
    
    fn check_memory() -> ComponentStatus {
        let usage = get_memory_usage();
        if usage > 0.9 {  // 90% å†…å­˜ä½¿ç”¨
            ComponentStatus::Warning("High memory usage".to_string())
        } else {
            ComponentStatus::Healthy
        }
    }
}

// è¯Šæ–­å·¥å…·
pub struct DiagnosticTool;

impl DiagnosticTool {
    pub fn generate_report(cx: &App) -> DiagnosticReport {
        DiagnosticReport {
            timestamp: chrono::Utc::now(),
            version: env!("CARGO_PKG_VERSION").to_string(),
            
            // çŠ¶æ€ä¿¡æ¯
            store_stats: Self::collect_store_stats(cx),
            
            // æ€§èƒ½æŒ‡æ ‡
            performance_metrics: Self::collect_performance_metrics(),
            
            // é”™è¯¯æ—¥å¿—
            recent_errors: Self::collect_recent_errors(),
            
            // ç³»ç»Ÿä¿¡æ¯
            system_info: Self::collect_system_info(),
        }
    }
    
    fn collect_store_stats(cx: &App) -> StoreStats {
        let store = cx.global::<TodoStore>();
        StoreStats {
            total_items: store.all_items.len(),
            total_projects: store.projects.len(),
            total_labels: store.labels.len(),
            inbox_count: store.inbox_items().len(),
            today_count: store.today_items().len(),
            completed_count: store.all_items.iter().filter(|i| i.checked).count(),
        }
    }
}
```



---

## ğŸ“ˆ ä¼˜å…ˆçº§å»ºè®®

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰

#### 1. æ€§èƒ½å…³é”®ä¼˜åŒ–
- **ç´¢å¼•å¢é‡æ›´æ–°** (é¢„è®¡æå‡ 50% æ€§èƒ½)
  - æ–‡ä»¶: `crates/mytool/src/todo_state/todo_store.rs`
  - å·¥ä½œé‡: 2-3 å¤©
  - å½±å“: æ‰€æœ‰è§†å›¾çš„å“åº”é€Ÿåº¦

- **è§‚å¯Ÿè€…ä¼˜åŒ–** (å‡å°‘ 70% ä¸å¿…è¦çš„é‡æ–°æ¸²æŸ“)
  - æ–‡ä»¶: `crates/mytool/src/views/boards/*.rs`
  - å·¥ä½œé‡: 3-4 å¤©
  - å½±å“: UI æµç•…åº¦

- **æ•°æ®åº“è¿æ¥ç®¡ç†**
  - æ–‡ä»¶: `crates/mytool/src/todo_state/database.rs`
  - å·¥ä½œé‡: 1 å¤©
  - å½±å“: é˜²æ­¢è¿æ¥æ³„æ¼

#### 2. ç”¨æˆ·ä½“éªŒæ”¹è¿›
- **é”™è¯¯å¤„ç†ç»Ÿä¸€**
  - æ–‡ä»¶: `crates/mytool/src/todo_actions/*.rs`
  - å·¥ä½œé‡: 2 å¤©
  - å½±å“: ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º

- **é”®ç›˜å¿«æ·é”®ç³»ç»Ÿ**
  - æ–‡ä»¶: æ–°å»º `crates/mytool/src/shortcuts.rs`
  - å·¥ä½œé‡: 2-3 å¤©
  - å½±å“: æå‡æ“ä½œæ•ˆç‡

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆè¿‘æœŸå®æ–½ï¼‰

#### 3. æ¶æ„æ”¹è¿›
- **äº‹ä»¶æ€»çº¿ç³»ç»Ÿ**
  - æ–‡ä»¶: æ–°å»º `crates/mytool/src/core/events.rs`
  - å·¥ä½œé‡: 3-4 å¤©
  - å½±å“: è§£è€¦ç»„ä»¶ï¼Œæå‡å¯ç»´æŠ¤æ€§

- **ç¼“å­˜å±‚**
  - æ–‡ä»¶: æ–°å»º `crates/mytool/src/core/cache.rs`
  - å·¥ä½œé‡: 2-3 å¤©
  - å½±å“: å‡å°‘é‡å¤è®¡ç®—

#### 4. UI ä¼˜åŒ–
- **è§†è§‰å±‚æ¬¡ä¼˜åŒ–**
  - æ–‡ä»¶: `crates/mytool/src/themes.rs`, å„ç»„ä»¶æ–‡ä»¶
  - å·¥ä½œé‡: 3-5 å¤©
  - å½±å“: æå‡è§†è§‰ä½“éªŒ

- **å“åº”å¼å¸ƒå±€**
  - æ–‡ä»¶: `crates/mytool/src/views/*.rs`
  - å·¥ä½œé‡: 4-5 å¤©
  - å½±å“: é€‚åº”ä¸åŒçª—å£å¤§å°

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆé•¿æœŸè§„åˆ’ï¼‰

#### 5. é«˜çº§åŠŸèƒ½
- **ç¦»çº¿æ”¯æŒ**
  - å·¥ä½œé‡: 5-7 å¤©
  - å½±å“: æå‡å¯ç”¨æ€§

- **æ•°æ®åŠ å¯†**
  - å·¥ä½œé‡: 3-4 å¤©
  - å½±å“: æå‡å®‰å…¨æ€§

- **æ™ºèƒ½è¾“å…¥è§£æ**
  - å·¥ä½œé‡: 5-7 å¤©
  - å½±å“: æå‡è¾“å…¥æ•ˆç‡

#### 6. å¼€å‘ä½“éªŒ
- **æµ‹è¯•è¦†ç›–**
  - å·¥ä½œé‡: æŒç»­è¿›è¡Œ
  - å½±å“: ä»£ç è´¨é‡

- **æ–‡æ¡£å®Œå–„**
  - å·¥ä½œé‡: æŒç»­è¿›è¡Œ
  - å½±å“: å¯ç»´æŠ¤æ€§

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### ç¬¬ä¸€é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**: æå‡åº”ç”¨å“åº”é€Ÿåº¦å’Œæµç•…åº¦

**ä»»åŠ¡æ¸…å•**:
- [ ] å®ç°ç´¢å¼•å¢é‡æ›´æ–°
- [ ] ä¼˜åŒ–è§‚å¯Ÿè€…æ¨¡å¼ï¼ˆæ·»åŠ è„æ ‡è®°ï¼‰
- [ ] æ”¹è¿›æ•°æ®åº“è¿æ¥ç®¡ç†
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§

**éªŒæ”¶æ ‡å‡†**:
- ä»»åŠ¡æ·»åŠ /æ›´æ–°å“åº”æ—¶é—´ < 50ms
- è§†å›¾åˆ‡æ¢å»¶è¿Ÿ < 100ms
- å†…å­˜ä½¿ç”¨ç¨³å®šï¼ˆæ— æ³„æ¼ï¼‰

### ç¬¬äºŒé˜¶æ®µï¼šç”¨æˆ·ä½“éªŒï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**: æå‡æ“ä½œä¾¿æ·æ€§å’Œè§†è§‰ä½“éªŒ

**ä»»åŠ¡æ¸…å•**:
- [ ] å®ç°é”®ç›˜å¿«æ·é”®ç³»ç»Ÿ
- [ ] ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæç¤º
- [ ] ä¼˜åŒ–è§†è§‰å±‚æ¬¡ï¼ˆé˜´å½±ã€é¢œè‰²ï¼‰
- [ ] æ·»åŠ åŠ¨ç”»å’Œè¿‡æ¸¡æ•ˆæœ

**éªŒæ”¶æ ‡å‡†**:
- æ‰€æœ‰ä¸»è¦æ“ä½œæ”¯æŒå¿«æ·é”®
- é”™è¯¯æç¤ºæ¸…æ™°å‹å¥½
- UI è§†è§‰å±‚æ¬¡åˆ†æ˜

### ç¬¬ä¸‰é˜¶æ®µï¼šæ¶æ„é‡æ„ï¼ˆ3-4 å‘¨ï¼‰

**ç›®æ ‡**: æå‡ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§

**ä»»åŠ¡æ¸…å•**:
- [ ] å®ç°äº‹ä»¶æ€»çº¿ç³»ç»Ÿ
- [ ] æ·»åŠ ç¼“å­˜å±‚
- [ ] é‡ç»„æ¨¡å—ç»“æ„
- [ ] å®Œå–„æ–‡æ¡£å’Œæµ‹è¯•

**éªŒæ”¶æ ‡å‡†**:
- æ¨¡å—èŒè´£æ¸…æ™°
- æµ‹è¯•è¦†ç›–ç‡ > 60%
- æ ¸å¿ƒ API æœ‰å®Œæ•´æ–‡æ¡£

### ç¬¬å››é˜¶æ®µï¼šé«˜çº§åŠŸèƒ½ï¼ˆ4-6 å‘¨ï¼‰

**ç›®æ ‡**: å¢å¼ºåº”ç”¨åŠŸèƒ½å’Œå®‰å…¨æ€§

**ä»»åŠ¡æ¸…å•**:
- [ ] å®ç°ç¦»çº¿æ”¯æŒ
- [ ] æ·»åŠ æ•°æ®åŠ å¯†
- [ ] æ™ºèƒ½è¾“å…¥è§£æ
- [ ] å“åº”å¼å¸ƒå±€

**éªŒæ”¶æ ‡å‡†**:
- ç¦»çº¿æ¨¡å¼æ­£å¸¸å·¥ä½œ
- æ•æ„Ÿæ•°æ®åŠ å¯†å­˜å‚¨
- è‡ªç„¶è¯­è¨€è¾“å…¥å¯ç”¨

---

## ğŸ“ å…·ä½“å®æ–½ç¤ºä¾‹

### ç¤ºä¾‹ 1: ç´¢å¼•å¢é‡æ›´æ–°

**æ–‡ä»¶**: `crates/mytool/src/todo_state/todo_store.rs`

```rust
// å½“å‰å®ç°ï¼ˆéœ€è¦ä¼˜åŒ–ï¼‰
impl TodoStore {
    fn rebuild_indexes(&mut self) {
        self.project_index.clear();
        self.section_index.clear();
        self.checked_set.clear();
        self.pinned_set.clear();
        
        for item in &self.all_items {
            // é‡å»ºæ‰€æœ‰ç´¢å¼•...
        }
    }
}

// ä¼˜åŒ–åçš„å®ç°
impl TodoStore {
    /// æ·»åŠ ä»»åŠ¡ï¼ˆå¢é‡æ›´æ–°ç´¢å¼•ï¼‰
    pub fn add_item(&mut self, item: Arc<ItemModel>) {
        // 1. æ·»åŠ åˆ°ä¸»åˆ—è¡¨
        self.all_items.push(item.clone());
        
        // 2. å¢é‡æ›´æ–°ç´¢å¼•
        self.add_to_indexes(&item);
        
        // 3. å¢åŠ ç‰ˆæœ¬å·
        self.version += 1;
        
        // 4. æ¸…é™¤ç›¸å…³ç¼“å­˜
        self.invalidate_cache(&item);
    }
    
    /// æ›´æ–°ä»»åŠ¡ï¼ˆç²¾ç¡®æ›´æ–°ç´¢å¼•ï¼‰
    pub fn update_item(&mut self, item: Arc<ItemModel>) {
        if let Some(pos) = self.all_items.iter().position(|i| i.id == item.id) {
            let old_item = &self.all_items[pos];
            
            // 1. ä»æ—§ç´¢å¼•ä¸­ç§»é™¤
            self.remove_from_indexes(old_item);
            
            // 2. æ›´æ–°ä¸»åˆ—è¡¨
            self.all_items[pos] = item.clone();
            
            // 3. æ·»åŠ åˆ°æ–°ç´¢å¼•
            self.add_to_indexes(&item);
            
            // 4. å¢åŠ ç‰ˆæœ¬å·
            self.version += 1;
            
            // 5. æ¸…é™¤ç›¸å…³ç¼“å­˜
            self.invalidate_cache(&item);
        }
    }
    
    /// åˆ é™¤ä»»åŠ¡ï¼ˆç²¾ç¡®ç§»é™¤ç´¢å¼•ï¼‰
    pub fn remove_item(&mut self, item_id: &str) {
        if let Some(pos) = self.all_items.iter().position(|i| i.id == item_id) {
            let item = self.all_items.remove(pos);
            
            // ä»æ‰€æœ‰ç´¢å¼•ä¸­ç§»é™¤
            self.remove_from_indexes(&item);
            
            self.version += 1;
            self.invalidate_cache(&item);
        }
    }
    
    // è¾…åŠ©æ–¹æ³•
    #[inline]
    fn add_to_indexes(&mut self, item: &ItemModel) {
        // é¡¹ç›®ç´¢å¼•
        if let Some(project_id) = &item.project_id {
            if !project_id.is_empty() {
                self.project_index
                    .entry(project_id.clone())
                    .or_default()
                    .push(Arc::new(item.clone()));
            }
        }
        
        // åˆ†åŒºç´¢å¼•
        if let Some(section_id) = &item.section_id {
            if !section_id.is_empty() {
                self.section_index
                    .entry(section_id.clone())
                    .or_default()
                    .push(Arc::new(item.clone()));
            }
        }
        
        // çŠ¶æ€ç´¢å¼•
        if item.checked {
            self.checked_set.insert(item.id.clone());
        }
        if item.pinned {
            self.pinned_set.insert(item.id.clone());
        }
    }
    
    #[inline]
    fn remove_from_indexes(&mut self, item: &ItemModel) {
        // ä»é¡¹ç›®ç´¢å¼•ç§»é™¤
        if let Some(project_id) = &item.project_id {
            if let Some(items) = self.project_index.get_mut(project_id) {
                items.retain(|i| i.id != item.id);
            }
        }
        
        // ä»åˆ†åŒºç´¢å¼•ç§»é™¤
        if let Some(section_id) = &item.section_id {
            if let Some(items) = self.section_index.get_mut(section_id) {
                items.retain(|i| i.id != item.id);
            }
        }
        
        // ä»çŠ¶æ€ç´¢å¼•ç§»é™¤
        self.checked_set.remove(&item.id);
        self.pinned_set.remove(&item.id);
    }
    
    #[inline]
    fn invalidate_cache(&mut self, item: &ItemModel) {
        // æ¸…é™¤å—å½±å“çš„ç¼“å­˜
        self.inbox_cache.borrow_mut().take();
        self.today_cache.borrow_mut().take();
        
        if let Some(project_id) = &item.project_id {
            self.project_cache.borrow_mut().remove(project_id);
        }
    }
}
```

**é¢„æœŸæ•ˆæœ**:
- æ·»åŠ ä»»åŠ¡: ä» O(n) é™åˆ° O(1)
- æ›´æ–°ä»»åŠ¡: ä» O(n) é™åˆ° O(1)
- åˆ é™¤ä»»åŠ¡: ä» O(n) é™åˆ° O(1)

### ç¤ºä¾‹ 2: è§‚å¯Ÿè€…ä¼˜åŒ–

**æ–‡ä»¶**: `crates/mytool/src/views/boards/board_inbox.rs`

```rust
// å½“å‰å®ç°ï¼ˆæ¯æ¬¡éƒ½é‡æ–°è®¡ç®—ï¼‰
cx.observe_global_in::<TodoStore>(window, move |this, window, cx| {
    let state_items = cx.global::<TodoStore>().inbox_items();
    // é‡æ–°è®¡ç®—æ‰€æœ‰æ•°æ®...
    this.base.item_rows = state_items.iter()...
});

// ä¼˜åŒ–åçš„å®ç°ï¼ˆä½¿ç”¨ç‰ˆæœ¬å·ï¼‰
pub struct InboxBoard {
    base: BoardBase,
    cached_version: usize,  // æ·»åŠ ç‰ˆæœ¬ç¼“å­˜
}

impl InboxBoard {
    pub(crate) fn new(window: &mut Window, cx: &mut Context<Self>) -> Self {
        let mut base = BoardBase::new(window, cx);
        
        base._subscriptions = vec![
            cx.observe_global_in::<TodoStore>(window, move |this, window, cx| {
                let store = cx.global::<TodoStore>();
                
                // æ£€æŸ¥ç‰ˆæœ¬å·ï¼Œåªåœ¨å˜åŒ–æ—¶æ›´æ–°
                if this.cached_version == store.version {
                    return;  // æ— å˜åŒ–ï¼Œç›´æ¥è¿”å›
                }
                
                this.cached_version = store.version;
                
                // åªè·å–éœ€è¦çš„æ•°æ®
                let state_items = store.inbox_items();
                
                // æ›´æ–°è§†å›¾...
                this.update_view(state_items, window, cx);
                cx.notify();
            }),
        ];
        
        Self { base, cached_version: 0 }
    }
    
    fn update_view(&mut self, items: Vec<Arc<ItemModel>>, window: &mut Window, cx: &mut Context<Self>) {
        // åˆ†ç¦»æ›´æ–°é€»è¾‘ï¼Œä¾¿äºæµ‹è¯•å’Œç»´æŠ¤
        self.base.item_rows = items
            .iter()
            .filter(|item| !item.checked)
            .map(|item| cx.new(|cx| ItemRowState::new(item.clone(), window, cx)))
            .collect();
        
        // é‡æ–°åˆ†ç»„
        self.regroup_items(&items);
    }
    
    fn regroup_items(&mut self, items: &[Arc<ItemModel>]) {
        self.base.no_section_items.clear();
        self.base.section_items_map.clear();
        self.base.pinned_items.clear();
        
        for (i, item) in items.iter().enumerate() {
            if item.checked {
                continue;
            }
            
            if item.pinned {
                self.base.pinned_items.push((i, item.clone()));
            } else {
                match item.section_id.as_deref() {
                    None | Some("") => {
                        self.base.no_section_items.push((i, item.clone()))
                    }
                    Some(sid) => {
                        self.base.section_items_map
                            .entry(sid.to_string())
                            .or_default()
                            .push((i, item.clone()));
                    }
                }
            }
        }
    }
}
```

**é¢„æœŸæ•ˆæœ**:
- å‡å°‘ 70% çš„ä¸å¿…è¦é‡æ–°æ¸²æŸ“
- æå‡è§†å›¾åˆ‡æ¢æµç•…åº¦
- é™ä½ CPU ä½¿ç”¨ç‡



---

## ğŸ”§ å·¥å…·å’Œè„šæœ¬

### æ€§èƒ½åˆ†æè„šæœ¬

```bash
#!/bin/bash
# scripts/benchmark.sh

echo "Running performance benchmarks..."

# ç¼–è¯‘ä¼˜åŒ–ç‰ˆæœ¬
cargo build --release

# è¿è¡ŒåŸºå‡†æµ‹è¯•
cargo bench --bench store_bench

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
cargo flamegraph --bench store_bench

# å†…å­˜åˆ†æ
valgrind --tool=massif --massif-out-file=massif.out \
    target/release/mytool

# ç”Ÿæˆå†…å­˜æŠ¥å‘Š
ms_print massif.out > memory_report.txt

echo "Benchmark complete. Check target/criterion for results."
```

### ä»£ç è´¨é‡æ£€æŸ¥

```bash
#!/bin/bash
# scripts/quality_check.sh

echo "Running code quality checks..."

# æ ¼å¼åŒ–æ£€æŸ¥
cargo fmt --check

# Clippy æ£€æŸ¥
cargo clippy --all-targets --all-features -- -D warnings

# å®‰å…¨å®¡è®¡
cargo audit

# ä¾èµ–æ£€æŸ¥
cargo machete

# æµ‹è¯•è¦†ç›–ç‡
cargo tarpaulin --out Html --output-dir coverage

echo "Quality check complete."
```

### æ•°æ®åº“è¿ç§»å·¥å…·

```rust
// tools/migrate.rs
use clap::{Parser, Subcommand};

#[derive(Parser)]
#[command(name = "migrate")]
#[command(about = "Database migration tool")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Run all pending migrations
    Up,
    /// Rollback the last migration
    Down,
    /// Show migration status
    Status,
    /// Create a new migration
    Create { name: String },
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();
    let db = init_db().await?;
    let manager = MigrationManager::new();
    
    match cli.command {
        Commands::Up => {
            manager.migrate_to_latest(&db).await?;
            println!("Migrations applied successfully");
        }
        Commands::Down => {
            manager.rollback_last(&db).await?;
            println!("Last migration rolled back");
        }
        Commands::Status => {
            let status = manager.get_status(&db).await?;
            println!("Current version: {}", status.current_version);
            println!("Pending migrations: {}", status.pending_count);
        }
        Commands::Create { name } => {
            manager.create_migration(&name)?;
            println!("Migration created: {}", name);
        }
    }
    
    Ok(())
}
```

---

## ğŸ“š å‚è€ƒèµ„æº

### æ€§èƒ½ä¼˜åŒ–
- [Rust Performance Book](https://nnethercote.github.io/perf-book/)
- [GPUI Performance Guide](https://github.com/zed-industries/zed/blob/main/docs/performance.md)
- [SeaORM Performance Tips](https://www.sea-ql.org/SeaORM/docs/advanced-query/performance/)

### UI/UX è®¾è®¡
- [Material Design Guidelines](https://material.io/design)
- [Apple Human Interface Guidelines](https://developer.apple.com/design/human-interface-guidelines/)
- [Accessibility Guidelines](https://www.w3.org/WAI/WCAG21/quickref/)

### Rust æœ€ä½³å®è·µ
- [Rust API Guidelines](https://rust-lang.github.io/api-guidelines/)
- [Effective Rust](https://www.lurklurk.org/effective-rust/)
- [Rust Design Patterns](https://rust-unofficial.github.io/patterns/)

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒä¼˜åŒ–ç‚¹

1. **æ€§èƒ½ä¼˜åŒ–**
   - ç´¢å¼•å¢é‡æ›´æ–°ï¼šæå‡ 50% æ€§èƒ½
   - è§‚å¯Ÿè€…ä¼˜åŒ–ï¼šå‡å°‘ 70% é‡æ–°æ¸²æŸ“
   - ç¼“å­˜ç­–ç•¥ï¼šé¿å…é‡å¤è®¡ç®—

2. **ç”¨æˆ·ä½“éªŒ**
   - é”®ç›˜å¿«æ·é”®ï¼šæå‡æ“ä½œæ•ˆç‡
   - è§†è§‰ä¼˜åŒ–ï¼šå¢å¼ºå±‚æ¬¡æ„Ÿ
   - é”™è¯¯å¤„ç†ï¼šå‹å¥½çš„æç¤º

3. **æ¶æ„æ”¹è¿›**
   - äº‹ä»¶æ€»çº¿ï¼šè§£è€¦ç»„ä»¶
   - æ¨¡å—é‡ç»„ï¼šæ¸…æ™°èŒè´£
   - æµ‹è¯•è¦†ç›–ï¼šä¿è¯è´¨é‡

4. **å¯ç»´æŠ¤æ€§**
   - ç»“æ„åŒ–æ—¥å¿—ï¼šä¾¿äºè°ƒè¯•
   - å®Œå–„æ–‡æ¡£ï¼šé™ä½å­¦ä¹ æˆæœ¬
   - è¿ç§»ç³»ç»Ÿï¼šå¹³æ»‘å‡çº§

### é¢„æœŸæ”¶ç›Š

- **æ€§èƒ½**: å“åº”é€Ÿåº¦æå‡ 50%+
- **ä½“éªŒ**: æ“ä½œæ•ˆç‡æå‡ 30%+
- **è´¨é‡**: ä»£ç å¯ç»´æŠ¤æ€§æå‡ 40%+
- **ç¨³å®šæ€§**: Bug ç‡é™ä½ 50%+

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å¼€å§‹**: å®æ–½é«˜ä¼˜å…ˆçº§ä¼˜åŒ–ï¼ˆç´¢å¼•ã€è§‚å¯Ÿè€…ï¼‰
2. **æŒç»­æ”¹è¿›**: æŒ‰è·¯çº¿å›¾é€æ­¥å®æ–½
3. **ç›‘æ§æ•ˆæœ**: ä½¿ç”¨æ€§èƒ½ç›‘æ§å·¥å…·è·Ÿè¸ªæ”¹è¿›
4. **æ”¶é›†åé¦ˆ**: æ ¹æ®ç”¨æˆ·åé¦ˆè°ƒæ•´ä¼˜å…ˆçº§

---

## ğŸ“ è”ç³»å’Œåé¦ˆ

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- **Issue Tracker**: é¡¹ç›® GitHub Issues
- **è®¨è®ºåŒº**: GitHub Discussions
- **é‚®ä»¶**: [é¡¹ç›®ç»´æŠ¤è€…é‚®ç®±]

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2026-02-19  
**ä½œè€…**: Claude (Kiro AI Assistant)



---

## ğŸš€ é«˜çº§ä¼˜åŒ–æ–¹æ¡ˆ

### 10. æ’ä»¶ç³»ç»Ÿæ·±åº¦ä¼˜åŒ–

#### å½“å‰çŠ¶æ€åˆ†æ
```rust
// æ’ä»¶ç³»ç»Ÿå·²æœ‰åŸºç¡€æ¡†æ¶ï¼Œä½†åŠŸèƒ½æœ‰é™
pub trait Plugin {
    fn metadata(&self) -> PluginMetadata;
    fn init(&mut self, window: &mut Window, cx: &mut App);
    fn cleanup(&mut self, cx: &mut App);
    fn is_enabled(&self) -> bool;
    fn set_enabled(&mut self, enabled: bool);
}
```

#### é—®é¢˜è¯†åˆ«
1. ç¼ºå°‘æ’ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†
2. æ²¡æœ‰æ’ä»¶é—´é€šä¿¡æœºåˆ¶
3. ç¼ºå°‘æ’ä»¶çƒ­é‡è½½
4. æ²¡æœ‰æ’ä»¶ä¾èµ–ç®¡ç†
5. ç¼ºå°‘æ’ä»¶æ²™ç®±éš”ç¦»

#### ä¼˜åŒ–æ–¹æ¡ˆ

##### 10.1 å®Œæ•´çš„æ’ä»¶ç”Ÿå‘½å‘¨æœŸ
```rust
// æ‰©å±•æ’ä»¶ç”Ÿå‘½å‘¨æœŸ
pub trait Plugin: Send + Sync {
    fn metadata(&self) -> PluginMetadata;
    
    // ç”Ÿå‘½å‘¨æœŸé’©å­
    fn on_load(&mut self, cx: &mut App) -> Result<(), PluginError>;
    fn on_enable(&mut self, window: &mut Window, cx: &mut App) -> Result<(), PluginError>;
    fn on_disable(&mut self, cx: &mut App) -> Result<(), PluginError>;
    fn on_unload(&mut self, cx: &mut App) -> Result<(), PluginError>;
    fn on_update(&mut self, cx: &mut App) -> Result<(), PluginError>;
    
    // é…ç½®ç®¡ç†
    fn get_config(&self) -> Option<serde_json::Value>;
    fn set_config(&mut self, config: serde_json::Value) -> Result<(), PluginError>;
    
    // ä¾èµ–å£°æ˜
    fn dependencies(&self) -> Vec<PluginDependency> {
        vec![]
    }
    
    // æƒé™å£°æ˜
    fn required_permissions(&self) -> Vec<Permission> {
        vec![]
    }
    
    // å¥åº·æ£€æŸ¥
    fn health_check(&self) -> PluginHealth {
        PluginHealth::Healthy
    }
}

// æ’ä»¶ä¾èµ–
#[derive(Debug, Clone)]
pub struct PluginDependency {
    pub plugin_id: String,
    pub version_requirement: String,  // å¦‚ ">=1.0.0, <2.0.0"
    pub optional: bool,
}

// æ’ä»¶å¥åº·çŠ¶æ€
#[derive(Debug, Clone, PartialEq)]
pub enum PluginHealth {
    Healthy,
    Degraded(String),
    Unhealthy(String),
}

// æ’ä»¶é”™è¯¯
#[derive(Debug, thiserror::Error)]
pub enum PluginError {
    #[error("Plugin initialization failed: {0}")]
    InitFailed(String),
    
    #[error("Plugin dependency not met: {0}")]
    DependencyNotMet(String),
    
    #[error("Plugin permission denied: {0}")]
    PermissionDenied(String),
    
    #[error("Plugin configuration error: {0}")]
    ConfigError(String),
}
```

##### 10.2 æ’ä»¶é€šä¿¡æ€»çº¿
```rust
// æ’ä»¶é—´é€šä¿¡
pub struct PluginBus {
    channels: Arc<RwLock<HashMap<String, broadcast::Sender<PluginMessage>>>>,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PluginMessage {
    pub from: String,
    pub to: Option<String>,  // None = å¹¿æ’­
    pub topic: String,
    pub payload: serde_json::Value,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

impl PluginBus {
    pub fn new() -> Self {
        Self {
            channels: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    // å‘é€æ¶ˆæ¯
    pub async fn send(&self, message: PluginMessage) -> Result<(), PluginError> {
        let channels = self.channels.read().await;
        
        if let Some(to) = &message.to {
            // ç‚¹å¯¹ç‚¹æ¶ˆæ¯
            if let Some(tx) = channels.get(to) {
                tx.send(message).map_err(|e| {
                    PluginError::InitFailed(format!("Failed to send message: {}", e))
                })?;
            }
        } else {
            // å¹¿æ’­æ¶ˆæ¯
            for tx in channels.values() {
                let _ = tx.send(message.clone());
            }
        }
        
        Ok(())
    }
    
    // è®¢é˜…æ¶ˆæ¯
    pub async fn subscribe(&self, plugin_id: String) -> broadcast::Receiver<PluginMessage> {
        let mut channels = self.channels.write().await;
        let (tx, rx) = broadcast::channel(100);
        channels.insert(plugin_id, tx);
        rx
    }
    
    // è¯·æ±‚-å“åº”æ¨¡å¼
    pub async fn request(
        &self,
        from: String,
        to: String,
        topic: String,
        payload: serde_json::Value,
        timeout: Duration,
    ) -> Result<PluginMessage, PluginError> {
        let request = PluginMessage {
            from: from.clone(),
            to: Some(to),
            topic,
            payload,
            timestamp: chrono::Utc::now(),
        };
        
        // åˆ›å»ºä¸´æ—¶å“åº”é€šé“
        let (response_tx, mut response_rx) = tokio::sync::mpsc::channel(1);
        
        // å‘é€è¯·æ±‚
        self.send(request).await?;
        
        // ç­‰å¾…å“åº”
        tokio::time::timeout(timeout, response_rx.recv())
            .await
            .map_err(|_| PluginError::InitFailed("Request timeout".to_string()))?
            .ok_or_else(|| PluginError::InitFailed("No response".to_string()))
    }
}
```

##### 10.3 æ’ä»¶çƒ­é‡è½½
```rust
// æ’ä»¶çƒ­é‡è½½ç®¡ç†å™¨
pub struct PluginHotReloader {
    watcher: Arc<Mutex<notify::RecommendedWatcher>>,
    plugin_paths: Arc<RwLock<HashMap<String, PathBuf>>>,
}

impl PluginHotReloader {
    pub fn new() -> Result<Self, PluginError> {
        let (tx, rx) = std::sync::mpsc::channel();
        
        let watcher = notify::recommended_watcher(move |res: Result<notify::Event, _>| {
            if let Ok(event) = res {
                let _ = tx.send(event);
            }
        }).map_err(|e| PluginError::InitFailed(format!("Failed to create watcher: {}", e)))?;
        
        Ok(Self {
            watcher: Arc::new(Mutex::new(watcher)),
            plugin_paths: Arc::new(RwLock::new(HashMap::new())),
        })
    }
    
    pub async fn watch_plugin(&self, plugin_id: String, path: PathBuf) -> Result<(), PluginError> {
        let mut watcher = self.watcher.lock().await;
        watcher.watch(&path, notify::RecursiveMode::NonRecursive)
            .map_err(|e| PluginError::InitFailed(format!("Failed to watch plugin: {}", e)))?;
        
        let mut paths = self.plugin_paths.write().await;
        paths.insert(plugin_id, path);
        
        Ok(())
    }
    
    pub async fn reload_plugin(
        &self,
        plugin_id: &str,
        registry: &mut PluginRegistry,
        cx: &mut App,
    ) -> Result<(), PluginError> {
        // 1. å¸è½½æ—§æ’ä»¶
        if let Some(plugin) = registry.get_plugin(plugin_id) {
            plugin.on_unload(cx)?;
        }
        
        // 2. é‡æ–°åŠ è½½æ’ä»¶
        let paths = self.plugin_paths.read().await;
        if let Some(path) = paths.get(plugin_id) {
            let new_plugin = Self::load_plugin_from_path(path)?;
            registry.register_plugin(new_plugin);
        }
        
        // 3. åˆå§‹åŒ–æ–°æ’ä»¶
        if let Some(plugin) = registry.get_plugin(plugin_id) {
            plugin.on_load(cx)?;
        }
        
        Ok(())
    }
    
    fn load_plugin_from_path(path: &Path) -> Result<Box<dyn Plugin>, PluginError> {
        // åŠ¨æ€åŠ è½½æ’ä»¶ï¼ˆä½¿ç”¨ libloading æˆ–ç±»ä¼¼åº“ï¼‰
        // è¿™é‡Œæ˜¯ç®€åŒ–ç¤ºä¾‹
        todo!("Implement dynamic plugin loading")
    }
}
```

##### 10.4 æ’ä»¶æ²™ç®±
```rust
// æ’ä»¶æ²™ç®± - é™åˆ¶æ’ä»¶æƒé™
pub struct PluginSandbox {
    allowed_permissions: HashSet<Permission>,
    resource_limits: ResourceLimits,
}

#[derive(Debug, Clone, Hash, PartialEq, Eq)]
pub enum Permission {
    ReadDatabase,
    WriteDatabase,
    ReadFiles,
    WriteFiles,
    NetworkAccess,
    SystemCommands,
    UIModification,
}

#[derive(Debug, Clone)]
pub struct ResourceLimits {
    pub max_memory: usize,      // å­—èŠ‚
    pub max_cpu_time: Duration,  // CPU æ—¶é—´
    pub max_threads: usize,
}

impl PluginSandbox {
    pub fn new(permissions: HashSet<Permission>, limits: ResourceLimits) -> Self {
        Self {
            allowed_permissions: permissions,
            resource_limits: limits,
        }
    }
    
    pub fn check_permission(&self, permission: &Permission) -> Result<(), PluginError> {
        if self.allowed_permissions.contains(permission) {
            Ok(())
        } else {
            Err(PluginError::PermissionDenied(format!("{:?}", permission)))
        }
    }
    
    pub async fn execute_with_limits<F, T>(
        &self,
        f: F,
    ) -> Result<T, PluginError>
    where
        F: Future<Output = T> + Send + 'static,
        T: Send + 'static,
    {
        // ä½¿ç”¨ tokio çš„è¶…æ—¶å’Œèµ„æºé™åˆ¶
        tokio::time::timeout(self.resource_limits.max_cpu_time, f)
            .await
            .map_err(|_| PluginError::InitFailed("Plugin execution timeout".to_string()))
    }
}

// æ’ä»¶åŒ…è£…å™¨ - è‡ªåŠ¨åº”ç”¨æ²™ç®±
pub struct SandboxedPlugin {
    inner: Box<dyn Plugin>,
    sandbox: PluginSandbox,
}

impl Plugin for SandboxedPlugin {
    fn metadata(&self) -> PluginMetadata {
        self.inner.metadata()
    }
    
    fn on_load(&mut self, cx: &mut App) -> Result<(), PluginError> {
        // æ£€æŸ¥æƒé™
        for permission in self.inner.required_permissions() {
            self.sandbox.check_permission(&permission)?;
        }
        
        // åœ¨æ²™ç®±ä¸­æ‰§è¡Œ
        self.inner.on_load(cx)
    }
    
    // ... å…¶ä»–æ–¹æ³•ç±»ä¼¼
}
```

##### 10.5 æ’ä»¶å¸‚åœºå’Œè‡ªåŠ¨æ›´æ–°
```rust
// æ’ä»¶å¸‚åœºå®¢æˆ·ç«¯
pub struct PluginMarketplace {
    api_url: String,
    client: reqwest::Client,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct PluginInfo {
    pub id: String,
    pub name: String,
    pub version: String,
    pub description: String,
    pub author: String,
    pub download_url: String,
    pub checksum: String,
    pub required_app_version: String,
}

impl PluginMarketplace {
    pub fn new(api_url: String) -> Self {
        Self {
            api_url,
            client: reqwest::Client::new(),
        }
    }
    
    // æœç´¢æ’ä»¶
    pub async fn search(&self, query: &str) -> Result<Vec<PluginInfo>, PluginError> {
        let url = format!("{}/plugins/search?q={}", self.api_url, query);
        let response = self.client.get(&url).send().await
            .map_err(|e| PluginError::InitFailed(format!("Search failed: {}", e)))?;
        
        response.json().await
            .map_err(|e| PluginError::InitFailed(format!("Parse failed: {}", e)))
    }
    
    // ä¸‹è½½æ’ä»¶
    pub async fn download(&self, plugin_id: &str) -> Result<Vec<u8>, PluginError> {
        let info = self.get_plugin_info(plugin_id).await?;
        
        let response = self.client.get(&info.download_url).send().await
            .map_err(|e| PluginError::InitFailed(format!("Download failed: {}", e)))?;
        
        let bytes = response.bytes().await
            .map_err(|e| PluginError::InitFailed(format!("Read failed: {}", e)))?;
        
        // éªŒè¯æ ¡éªŒå’Œ
        let checksum = Self::calculate_checksum(&bytes);
        if checksum != info.checksum {
            return Err(PluginError::InitFailed("Checksum mismatch".to_string()));
        }
        
        Ok(bytes.to_vec())
    }
    
    // æ£€æŸ¥æ›´æ–°
    pub async fn check_updates(
        &self,
        installed_plugins: &HashMap<String, String>,  // id -> version
    ) -> Result<Vec<PluginInfo>, PluginError> {
        let mut updates = Vec::new();
        
        for (id, current_version) in installed_plugins {
            let info = self.get_plugin_info(id).await?;
            
            if Self::is_newer_version(&info.version, current_version) {
                updates.push(info);
            }
        }
        
        Ok(updates)
    }
    
    async fn get_plugin_info(&self, plugin_id: &str) -> Result<PluginInfo, PluginError> {
        let url = format!("{}/plugins/{}", self.api_url, plugin_id);
        let response = self.client.get(&url).send().await
            .map_err(|e| PluginError::InitFailed(format!("Get info failed: {}", e)))?;
        
        response.json().await
            .map_err(|e| PluginError::InitFailed(format!("Parse failed: {}", e)))
    }
    
    fn calculate_checksum(data: &[u8]) -> String {
        use sha2::{Sha256, Digest};
        let mut hasher = Sha256::new();
        hasher.update(data);
        format!("{:x}", hasher.finalize())
    }
    
    fn is_newer_version(new: &str, current: &str) -> bool {
        // ç®€å•çš„ç‰ˆæœ¬æ¯”è¾ƒï¼Œå®é™…åº”ä½¿ç”¨ semver
        new > current
    }
}
```



### 11. æ™ºèƒ½åŒ–åŠŸèƒ½ä¼˜åŒ–

#### 11.1 AI è¾…åŠ©ä»»åŠ¡ç®¡ç†
```rust
// AI åŠ©æ‰‹é›†æˆ
pub struct AIAssistant {
    model: String,
    api_key: String,
    client: reqwest::Client,
}

impl AIAssistant {
    // æ™ºèƒ½ä»»åŠ¡åˆ†è§£
    pub async fn break_down_task(&self, task: &str) -> Result<Vec<String>, AIError> {
        let prompt = format!(
            "å°†ä»¥ä¸‹ä»»åŠ¡åˆ†è§£ä¸ºå…·ä½“çš„å­ä»»åŠ¡ï¼š\n{}\n\nè¯·ä»¥åˆ—è¡¨å½¢å¼è¿”å›å­ä»»åŠ¡ã€‚",
            task
        );
        
        let subtasks = self.query(&prompt).await?;
        Ok(self.parse_list(&subtasks))
    }
    
    // æ™ºèƒ½ä¼˜å…ˆçº§å»ºè®®
    pub async fn suggest_priority(&self, item: &ItemModel) -> Result<Priority, AIError> {
        let prompt = format!(
            "æ ¹æ®ä»¥ä¸‹ä»»åŠ¡ä¿¡æ¯ï¼Œå»ºè®®ä¼˜å…ˆçº§ï¼ˆé«˜/ä¸­/ä½ï¼‰ï¼š\n\
             ä»»åŠ¡ï¼š{}\n\
             æˆªæ­¢æ—¥æœŸï¼š{:?}\n\
             é¡¹ç›®ï¼š{:?}",
            item.content, item.due_date, item.project_id
        );
        
        let response = self.query(&prompt).await?;
        self.parse_priority(&response)
    }
    
    // æ™ºèƒ½æ—¶é—´ä¼°ç®—
    pub async fn estimate_duration(&self, task: &str) -> Result<Duration, AIError> {
        let prompt = format!(
            "ä¼°ç®—å®Œæˆä»¥ä¸‹ä»»åŠ¡éœ€è¦çš„æ—¶é—´ï¼ˆä»¥åˆ†é’Ÿä¸ºå•ä½ï¼‰ï¼š\n{}",
            task
        );
        
        let response = self.query(&prompt).await?;
        let minutes: u64 = response.trim().parse()
            .map_err(|_| AIError::ParseError)?;
        
        Ok(Duration::from_secs(minutes * 60))
    }
    
    // æ™ºèƒ½æ ‡ç­¾å»ºè®®
    pub async fn suggest_labels(&self, task: &str) -> Result<Vec<String>, AIError> {
        let prompt = format!(
            "ä¸ºä»¥ä¸‹ä»»åŠ¡å»ºè®®åˆé€‚çš„æ ‡ç­¾ï¼ˆæœ€å¤š5ä¸ªï¼‰ï¼š\n{}",
            task
        );
        
        let response = self.query(&prompt).await?;
        Ok(self.parse_list(&response))
    }
    
    // æ™ºèƒ½æ—¥ç¨‹å®‰æ’
    pub async fn suggest_schedule(
        &self,
        tasks: &[ItemModel],
        available_time: Duration,
    ) -> Result<Vec<ScheduledTask>, AIError> {
        let tasks_json = serde_json::to_string(tasks)
            .map_err(|_| AIError::SerializationError)?;
        
        let prompt = format!(
            "æ ¹æ®ä»¥ä¸‹ä»»åŠ¡å’Œå¯ç”¨æ—¶é—´ï¼Œå»ºè®®æœ€ä¼˜çš„æ—¥ç¨‹å®‰æ’ï¼š\n\
             ä»»åŠ¡åˆ—è¡¨ï¼š{}\n\
             å¯ç”¨æ—¶é—´ï¼š{} å°æ—¶",
            tasks_json,
            available_time.as_secs() / 3600
        );
        
        let response = self.query(&prompt).await?;
        self.parse_schedule(&response)
    }
    
    async fn query(&self, prompt: &str) -> Result<String, AIError> {
        // è°ƒç”¨ AI APIï¼ˆOpenAIã€Claude ç­‰ï¼‰
        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .json(&serde_json::json!({
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
            }))
            .send()
            .await
            .map_err(|e| AIError::NetworkError(e.to_string()))?;
        
        let json: serde_json::Value = response.json().await
            .map_err(|e| AIError::ParseError)?;
        
        json["choices"][0]["message"]["content"]
            .as_str()
            .ok_or(AIError::ParseError)
            .map(|s| s.to_string())
    }
    
    fn parse_list(&self, text: &str) -> Vec<String> {
        text.lines()
            .filter_map(|line| {
                let trimmed = line.trim();
                if trimmed.starts_with('-') || trimmed.starts_with('â€¢') {
                    Some(trimmed[1..].trim().to_string())
                } else if trimmed.chars().next()?.is_numeric() {
                    Some(trimmed.split_once('.')?.1.trim().to_string())
                } else {
                    None
                }
            })
            .collect()
    }
    
    fn parse_priority(&self, text: &str) -> Result<Priority, AIError> {
        let lower = text.to_lowercase();
        if lower.contains("é«˜") || lower.contains("high") {
            Ok(Priority::High)
        } else if lower.contains("ä½") || lower.contains("low") {
            Ok(Priority::Low)
        } else {
            Ok(Priority::Medium)
        }
    }
    
    fn parse_schedule(&self, text: &str) -> Result<Vec<ScheduledTask>, AIError> {
        // è§£æ AI è¿”å›çš„æ—¥ç¨‹å®‰æ’
        // å®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„è§£æé€»è¾‘
        todo!("Implement schedule parsing")
    }
}

#[derive(Debug, thiserror::Error)]
pub enum AIError {
    #[error("Network error: {0}")]
    NetworkError(String),
    
    #[error("Parse error")]
    ParseError,
    
    #[error("Serialization error")]
    SerializationError,
}

#[derive(Debug, Clone)]
pub struct ScheduledTask {
    pub task_id: String,
    pub start_time: chrono::DateTime<chrono::Local>,
    pub duration: Duration,
}
```

#### 11.2 æ™ºèƒ½æœç´¢å’Œè¿‡æ»¤
```rust
// å…¨æ–‡æœç´¢å¼•æ“
pub struct SearchEngine {
    index: Arc<RwLock<tantivy::Index>>,
    schema: tantivy::schema::Schema,
}

impl SearchEngine {
    pub fn new() -> Result<Self, SearchError> {
        // å®šä¹‰æœç´¢æ¨¡å¼
        let mut schema_builder = tantivy::schema::Schema::builder();
        
        schema_builder.add_text_field("id", tantivy::schema::STRING | tantivy::schema::STORED);
        schema_builder.add_text_field("content", tantivy::schema::TEXT | tantivy::schema::STORED);
        schema_builder.add_text_field("tags", tantivy::schema::TEXT);
        schema_builder.add_date_field("created_at", tantivy::schema::INDEXED);
        schema_builder.add_u64_field("priority", tantivy::schema::INDEXED);
        
        let schema = schema_builder.build();
        let index = tantivy::Index::create_in_ram(schema.clone());
        
        Ok(Self {
            index: Arc::new(RwLock::new(index)),
            schema,
        })
    }
    
    // ç´¢å¼•ä»»åŠ¡
    pub async fn index_item(&self, item: &ItemModel) -> Result<(), SearchError> {
        let index = self.index.write().await;
        let mut index_writer = index.writer(50_000_000)?;
        
        let id = self.schema.get_field("id").unwrap();
        let content = self.schema.get_field("content").unwrap();
        let tags = self.schema.get_field("tags").unwrap();
        let created_at = self.schema.get_field("created_at").unwrap();
        let priority = self.schema.get_field("priority").unwrap();
        
        let mut doc = tantivy::Document::new();
        doc.add_text(id, &item.id);
        doc.add_text(content, &item.content);
        
        if let Some(labels) = &item.labels {
            doc.add_text(tags, labels);
        }
        
        if let Some(created) = item.created_at {
            doc.add_date(created_at, tantivy::DateTime::from_timestamp_secs(created.timestamp()));
        }
        
        doc.add_u64(priority, item.priority as u64);
        
        index_writer.add_document(doc)?;
        index_writer.commit()?;
        
        Ok(())
    }
    
    // æ™ºèƒ½æœç´¢
    pub async fn search(&self, query: &str, limit: usize) -> Result<Vec<SearchResult>, SearchError> {
        let index = self.index.read().await;
        let reader = index.reader()?;
        let searcher = reader.searcher();
        
        // è§£ææŸ¥è¯¢
        let query_parser = tantivy::query::QueryParser::for_index(
            &index,
            vec![
                self.schema.get_field("content").unwrap(),
                self.schema.get_field("tags").unwrap(),
            ],
        );
        
        let query = query_parser.parse_query(query)?;
        
        // æ‰§è¡Œæœç´¢
        let top_docs = searcher.search(&query, &tantivy::collector::TopDocs::with_limit(limit))?;
        
        // è½¬æ¢ç»“æœ
        let mut results = Vec::new();
        for (_score, doc_address) in top_docs {
            let retrieved_doc = searcher.doc(doc_address)?;
            let id = retrieved_doc
                .get_first(self.schema.get_field("id").unwrap())
                .and_then(|v| v.as_text())
                .unwrap_or("")
                .to_string();
            
            let content = retrieved_doc
                .get_first(self.schema.get_field("content").unwrap())
                .and_then(|v| v.as_text())
                .unwrap_or("")
                .to_string();
            
            results.push(SearchResult { id, content, score: _score });
        }
        
        Ok(results)
    }
    
    // æ¨¡ç³Šæœç´¢
    pub async fn fuzzy_search(&self, query: &str, max_distance: u8) -> Result<Vec<SearchResult>, SearchError> {
        let index = self.index.read().await;
        let reader = index.reader()?;
        let searcher = reader.searcher();
        
        let content_field = self.schema.get_field("content").unwrap();
        let fuzzy_query = tantivy::query::FuzzyTermQuery::new(
            tantivy::Term::from_field_text(content_field, query),
            max_distance,
            true,
        );
        
        let top_docs = searcher.search(&fuzzy_query, &tantivy::collector::TopDocs::with_limit(10))?;
        
        let mut results = Vec::new();
        for (_score, doc_address) in top_docs {
            let retrieved_doc = searcher.doc(doc_address)?;
            let id = retrieved_doc
                .get_first(self.schema.get_field("id").unwrap())
                .and_then(|v| v.as_text())
                .unwrap_or("")
                .to_string();
            
            let content = retrieved_doc
                .get_first(self.schema.get_field("content").unwrap())
                .and_then(|v| v.as_text())
                .unwrap_or("")
                .to_string();
            
            results.push(SearchResult { id, content, score: _score });
        }
        
        Ok(results)
    }
}

#[derive(Debug, Clone)]
pub struct SearchResult {
    pub id: String,
    pub content: String,
    pub score: f32,
}

#[derive(Debug, thiserror::Error)]
pub enum SearchError {
    #[error("Tantivy error: {0}")]
    Tantivy(#[from] tantivy::TantivyError),
    
    #[error("Query parse error: {0}")]
    QueryParse(#[from] tantivy::query::QueryParserError),
}
```

#### 11.3 æ™ºèƒ½æé†’ç³»ç»Ÿ
```rust
// æ™ºèƒ½æé†’å¼•æ“
pub struct SmartReminderEngine {
    scheduler: Arc<Mutex<tokio_cron_scheduler::JobScheduler>>,
    ai_assistant: AIAssistant,
}

impl SmartReminderEngine {
    pub async fn new(ai_assistant: AIAssistant) -> Result<Self, ReminderError> {
        let scheduler = tokio_cron_scheduler::JobScheduler::new().await?;
        
        Ok(Self {
            scheduler: Arc::new(Mutex::new(scheduler)),
            ai_assistant,
        })
    }
    
    // æ™ºèƒ½æé†’æ—¶é—´å»ºè®®
    pub async fn suggest_reminder_time(
        &self,
        item: &ItemModel,
        user_habits: &UserHabits,
    ) -> Result<chrono::DateTime<chrono::Local>, ReminderError> {
        // åˆ†æç”¨æˆ·ä¹ æƒ¯
        let productive_hours = user_habits.most_productive_hours();
        
        // è€ƒè™‘ä»»åŠ¡æˆªæ­¢æ—¥æœŸ
        let due_date = item.due_date.ok_or(ReminderError::NoDueDate)?;
        
        // è€ƒè™‘ä»»åŠ¡ä¼˜å…ˆçº§
        let advance_time = match item.priority {
            Priority::High => Duration::from_secs(24 * 3600),  // æå‰1å¤©
            Priority::Medium => Duration::from_secs(12 * 3600), // æå‰12å°æ—¶
            Priority::Low => Duration::from_secs(6 * 3600),     // æå‰6å°æ—¶
        };
        
        // è®¡ç®—å»ºè®®æ—¶é—´
        let suggested_time = due_date - chrono::Duration::from_std(advance_time)?;
        
        // è°ƒæ•´åˆ°ç”¨æˆ·çš„é«˜æ•ˆæ—¶æ®µ
        let adjusted_time = self.adjust_to_productive_hours(suggested_time, productive_hours);
        
        Ok(adjusted_time)
    }
    
    // åˆ›å»ºæ™ºèƒ½æé†’
    pub async fn create_smart_reminder(
        &self,
        item: Arc<ItemModel>,
        cx: &mut App,
    ) -> Result<String, ReminderError> {
        let user_habits = cx.global::<UserHabits>();
        let reminder_time = self.suggest_reminder_time(&item, user_habits).await?;
        
        // ç”Ÿæˆæé†’æ¶ˆæ¯
        let message = self.generate_reminder_message(&item).await?;
        
        // åˆ›å»ºå®šæ—¶ä»»åŠ¡
        let job_id = self.schedule_reminder(reminder_time, message, item.id.clone()).await?;
        
        Ok(job_id)
    }
    
    async fn generate_reminder_message(&self, item: &ItemModel) -> Result<String, ReminderError> {
        let prompt = format!(
            "ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆä¸€æ¡å‹å¥½çš„æé†’æ¶ˆæ¯ï¼š\n\
             ä»»åŠ¡ï¼š{}\n\
             ä¼˜å…ˆçº§ï¼š{:?}\n\
             æˆªæ­¢æ—¥æœŸï¼š{:?}",
            item.content, item.priority, item.due_date
        );
        
        self.ai_assistant.query(&prompt).await
            .map_err(|e| ReminderError::AIError(e.to_string()))
    }
    
    async fn schedule_reminder(
        &self,
        time: chrono::DateTime<chrono::Local>,
        message: String,
        item_id: String,
    ) -> Result<String, ReminderError> {
        let scheduler = self.scheduler.lock().await;
        
        // åˆ›å»ºä¸€æ¬¡æ€§ä»»åŠ¡
        let job = tokio_cron_scheduler::Job::new_one_shot_async(
            time.into(),
            move |_uuid, _lock| {
                let message = message.clone();
                let item_id = item_id.clone();
                Box::pin(async move {
                    // å‘é€é€šçŸ¥
                    Self::send_notification(&message, &item_id).await;
                })
            },
        )?;
        
        let job_id = job.guid().to_string();
        scheduler.add(job).await?;
        
        Ok(job_id)
    }
    
    async fn send_notification(message: &str, item_id: &str) {
        // å‘é€ç³»ç»Ÿé€šçŸ¥
        #[cfg(target_os = "windows")]
        {
            use winrt_notification::{Toast, Duration as ToastDuration};
            Toast::new(Toast::POWERSHELL_APP_ID)
                .title("ä»»åŠ¡æé†’")
                .text1(message)
                .duration(ToastDuration::Short)
                .show()
                .ok();
        }
        
        #[cfg(target_os = "macos")]
        {
            use mac_notification_sys::*;
            let _ = send_notification(
                "ä»»åŠ¡æé†’",
                &None,
                message,
                &None,
            );
        }
        
        #[cfg(target_os = "linux")]
        {
            use notify_rust::Notification;
            Notification::new()
                .summary("ä»»åŠ¡æé†’")
                .body(message)
                .show()
                .ok();
        }
    }
    
    fn adjust_to_productive_hours(
        &self,
        time: chrono::DateTime<chrono::Local>,
        productive_hours: &[u32],
    ) -> chrono::DateTime<chrono::Local> {
        let hour = time.hour();
        
        if productive_hours.contains(&hour) {
            return time;
        }
        
        // æ‰¾åˆ°æœ€è¿‘çš„é«˜æ•ˆæ—¶æ®µ
        let closest_hour = productive_hours
            .iter()
            .min_by_key(|&&h| {
                let diff = if h > hour { h - hour } else { hour - h };
                diff
            })
            .copied()
            .unwrap_or(9); // é»˜è®¤æ—©ä¸Š9ç‚¹
        
        time.with_hour(closest_hour).unwrap_or(time)
    }
}

// ç”¨æˆ·ä¹ æƒ¯åˆ†æ
#[derive(Clone)]
pub struct UserHabits {
    completion_times: Vec<chrono::DateTime<chrono::Local>>,
    productive_hours_cache: Option<Vec<u32>>,
}

impl UserHabits {
    pub fn new() -> Self {
        Self {
            completion_times: Vec::new(),
            productive_hours_cache: None,
        }
    }
    
    pub fn record_completion(&mut self, time: chrono::DateTime<chrono::Local>) {
        self.completion_times.push(time);
        self.productive_hours_cache = None; // æ¸…é™¤ç¼“å­˜
    }
    
    pub fn most_productive_hours(&mut self) -> &[u32] {
        if let Some(ref hours) = self.productive_hours_cache {
            return hours;
        }
        
        // ç»Ÿè®¡æ¯å°æ—¶çš„å®Œæˆæ¬¡æ•°
        let mut hour_counts: HashMap<u32, usize> = HashMap::new();
        for time in &self.completion_times {
            *hour_counts.entry(time.hour()).or_insert(0) += 1;
        }
        
        // æ‰¾å‡ºå‰3ä¸ªæœ€é«˜æ•ˆçš„æ—¶æ®µ
        let mut hours: Vec<_> = hour_counts.into_iter().collect();
        hours.sort_by_key(|(_, count)| std::cmp::Reverse(*count));
        
        let productive_hours: Vec<u32> = hours
            .into_iter()
            .take(3)
            .map(|(hour, _)| hour)
            .collect();
        
        self.productive_hours_cache = Some(productive_hours);
        self.productive_hours_cache.as_ref().unwrap()
    }
}

#[derive(Debug, thiserror::Error)]
pub enum ReminderError {
    #[error("No due date")]
    NoDueDate,
    
    #[error("Scheduler error: {0}")]
    Scheduler(#[from] tokio_cron_scheduler::JobSchedulerError),
    
    #[error("AI error: {0}")]
    AIError(String),
    
    #[error("Time error: {0}")]
    TimeError(#[from] chrono::OutOfRangeError),
}
```



### 12. åä½œå’ŒåŒæ­¥ä¼˜åŒ–

#### 12.1 å®æ—¶åä½œç³»ç»Ÿ
```rust
// WebSocket å®æ—¶åŒæ­¥
pub struct CollaborationServer {
    connections: Arc<RwLock<HashMap<String, Vec<WebSocketConnection>>>>,
    event_bus: Arc<EventBus>,
}

#[derive(Clone)]
pub struct WebSocketConnection {
    user_id: String,
    tx: tokio::sync::mpsc::UnboundedSender<CollaborationMessage>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CollaborationMessage {
    ItemUpdated {
        item_id: String,
        user_id: String,
        changes: ItemChanges,
        timestamp: i64,
    },
    ItemCreated {
        item: ItemModel,
        user_id: String,
    },
    ItemDeleted {
        item_id: String,
        user_id: String,
    },
    UserJoined {
        user_id: String,
        project_id: String,
    },
    UserLeft {
        user_id: String,
        project_id: String,
    },
    CursorMoved {
        user_id: String,
        item_id: String,
        position: usize,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ItemChanges {
    pub field: String,
    pub old_value: serde_json::Value,
    pub new_value: serde_json::Value,
}

impl CollaborationServer {
    pub fn new(event_bus: Arc<EventBus>) -> Self {
        Self {
            connections: Arc::new(RwLock::new(HashMap::new())),
            event_bus,
        }
    }
    
    // ç”¨æˆ·åŠ å…¥é¡¹ç›®
    pub async fn join_project(
        &self,
        user_id: String,
        project_id: String,
        tx: tokio::sync::mpsc::UnboundedSender<CollaborationMessage>,
    ) {
        let connection = WebSocketConnection { user_id: user_id.clone(), tx };
        
        let mut connections = self.connections.write().await;
        connections.entry(project_id.clone()).or_default().push(connection);
        
        // å¹¿æ’­ç”¨æˆ·åŠ å…¥æ¶ˆæ¯
        self.broadcast_to_project(
            &project_id,
            CollaborationMessage::UserJoined { user_id, project_id },
            None,
        ).await;
    }
    
    // ç”¨æˆ·ç¦»å¼€é¡¹ç›®
    pub async fn leave_project(&self, user_id: &str, project_id: &str) {
        let mut connections = self.connections.write().await;
        
        if let Some(project_connections) = connections.get_mut(project_id) {
            project_connections.retain(|conn| conn.user_id != user_id);
            
            if project_connections.is_empty() {
                connections.remove(project_id);
            }
        }
        
        // å¹¿æ’­ç”¨æˆ·ç¦»å¼€æ¶ˆæ¯
        self.broadcast_to_project(
            project_id,
            CollaborationMessage::UserLeft {
                user_id: user_id.to_string(),
                project_id: project_id.to_string(),
            },
            None,
        ).await;
    }
    
    // å¹¿æ’­æ¶ˆæ¯åˆ°é¡¹ç›®
    pub async fn broadcast_to_project(
        &self,
        project_id: &str,
        message: CollaborationMessage,
        exclude_user: Option<&str>,
    ) {
        let connections = self.connections.read().await;
        
        if let Some(project_connections) = connections.get(project_id) {
            for conn in project_connections {
                if let Some(exclude) = exclude_user {
                    if conn.user_id == exclude {
                        continue;
                    }
                }
                
                let _ = conn.tx.send(message.clone());
            }
        }
    }
    
    // å¤„ç†ä»»åŠ¡æ›´æ–°
    pub async fn handle_item_update(
        &self,
        project_id: &str,
        item_id: &str,
        user_id: &str,
        changes: ItemChanges,
    ) {
        let message = CollaborationMessage::ItemUpdated {
            item_id: item_id.to_string(),
            user_id: user_id.to_string(),
            changes,
            timestamp: chrono::Utc::now().timestamp(),
        };
        
        self.broadcast_to_project(project_id, message, Some(user_id)).await;
    }
}

// å†²çªè§£å†³ç­–ç•¥
pub struct ConflictResolver;

impl ConflictResolver {
    // ä½¿ç”¨æ“ä½œè½¬æ¢ï¼ˆOperational Transformationï¼‰è§£å†³å†²çª
    pub fn resolve_conflict(
        local_changes: &ItemChanges,
        remote_changes: &ItemChanges,
    ) -> ItemChanges {
        // ç®€åŒ–çš„å†²çªè§£å†³ï¼šæœ€åå†™å…¥è·èƒœï¼ˆLast Write Winsï¼‰
        if local_changes.field == remote_changes.field {
            // æ¯”è¾ƒæ—¶é—´æˆ³ï¼Œé€‰æ‹©è¾ƒæ–°çš„
            remote_changes.clone()
        } else {
            // ä¸åŒå­—æ®µï¼Œå¯ä»¥åˆå¹¶
            local_changes.clone()
        }
    }
    
    // ä½¿ç”¨ CRDTï¼ˆConflict-free Replicated Data Typeï¼‰
    pub fn merge_with_crdt(
        local_state: &ItemModel,
        remote_state: &ItemModel,
    ) -> ItemModel {
        let mut merged = local_state.clone();
        
        // åˆå¹¶å„ä¸ªå­—æ®µ
        if remote_state.updated_at > local_state.updated_at {
            merged.content = remote_state.content.clone();
        }
        
        // åˆå¹¶æ ‡ç­¾ï¼ˆå–å¹¶é›†ï¼‰
        if let (Some(local_labels), Some(remote_labels)) = (&local_state.labels, &remote_state.labels) {
            let mut labels_set: HashSet<String> = local_labels.split(',').map(|s| s.to_string()).collect();
            labels_set.extend(remote_labels.split(',').map(|s| s.to_string()));
            merged.labels = Some(labels_set.into_iter().collect::<Vec<_>>().join(","));
        }
        
        merged
    }
}
```

#### 12.2 ç¦»çº¿ä¼˜å…ˆæ¶æ„
```rust
// ç¦»çº¿ä¼˜å…ˆæ•°æ®åŒæ­¥
pub struct OfflineFirstSync {
    local_db: Arc<DatabaseConnection>,
    remote_api: Arc<RemoteAPI>,
    sync_queue: Arc<Mutex<VecDeque<SyncOperation>>>,
    conflict_resolver: ConflictResolver,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SyncOperation {
    Create { entity_type: String, data: serde_json::Value, local_id: String },
    Update { entity_type: String, id: String, changes: serde_json::Value },
    Delete { entity_type: String, id: String },
}

impl OfflineFirstSync {
    pub fn new(
        local_db: Arc<DatabaseConnection>,
        remote_api: Arc<RemoteAPI>,
    ) -> Self {
        Self {
            local_db,
            remote_api,
            sync_queue: Arc::new(Mutex::new(VecDeque::new())),
            conflict_resolver: ConflictResolver,
        }
    }
    
    // æ·»åŠ æ“ä½œåˆ°åŒæ­¥é˜Ÿåˆ—
    pub async fn queue_operation(&self, operation: SyncOperation) {
        let mut queue = self.sync_queue.lock().await;
        queue.push_back(operation);
        
        // å¦‚æœåœ¨çº¿ï¼Œç«‹å³å°è¯•åŒæ­¥
        if self.is_online().await {
            drop(queue); // é‡Šæ”¾é”
            self.sync().await.ok();
        }
    }
    
    // æ‰§è¡ŒåŒæ­¥
    pub async fn sync(&self) -> Result<SyncResult, SyncError> {
        if !self.is_online().await {
            return Err(SyncError::Offline);
        }
        
        let mut queue = self.sync_queue.lock().await;
        let mut synced = 0;
        let mut failed = 0;
        let mut conflicts = Vec::new();
        
        while let Some(operation) = queue.pop_front() {
            match self.sync_operation(&operation).await {
                Ok(_) => synced += 1,
                Err(SyncError::Conflict(conflict)) => {
                    conflicts.push(conflict);
                    failed += 1;
                }
                Err(e) => {
                    // é‡æ–°å…¥é˜Ÿ
                    queue.push_front(operation);
                    failed += 1;
                    tracing::error!("Sync failed: {:?}", e);
                    break;
                }
            }
        }
        
        Ok(SyncResult { synced, failed, conflicts })
    }
    
    async fn sync_operation(&self, operation: &SyncOperation) -> Result<(), SyncError> {
        match operation {
            SyncOperation::Create { entity_type, data, local_id } => {
                // åˆ›å»ºè¿œç¨‹å®ä½“
                let remote_entity = self.remote_api.create(entity_type, data).await?;
                
                // æ›´æ–°æœ¬åœ° ID æ˜ å°„
                self.update_id_mapping(local_id, &remote_entity["id"].as_str().unwrap()).await?;
                
                Ok(())
            }
            SyncOperation::Update { entity_type, id, changes } => {
                // è·å–è¿œç¨‹æœ€æ–°çŠ¶æ€
                let remote_state = self.remote_api.get(entity_type, id).await?;
                
                // è·å–æœ¬åœ°çŠ¶æ€
                let local_state = self.get_local_state(entity_type, id).await?;
                
                // æ£€æŸ¥å†²çª
                if self.has_conflict(&local_state, &remote_state) {
                    return Err(SyncError::Conflict(Conflict {
                        entity_type: entity_type.clone(),
                        id: id.clone(),
                        local_state,
                        remote_state,
                    }));
                }
                
                // æ›´æ–°è¿œç¨‹
                self.remote_api.update(entity_type, id, changes).await?;
                
                Ok(())
            }
            SyncOperation::Delete { entity_type, id } => {
                self.remote_api.delete(entity_type, id).await?;
                Ok(())
            }
        }
    }
    
    // åŒå‘åŒæ­¥
    pub async fn bidirectional_sync(&self) -> Result<SyncResult, SyncError> {
        // 1. æ¨é€æœ¬åœ°æ›´æ”¹
        let push_result = self.sync().await?;
        
        // 2. æ‹‰å–è¿œç¨‹æ›´æ”¹
        let pull_result = self.pull_remote_changes().await?;
        
        Ok(SyncResult {
            synced: push_result.synced + pull_result.synced,
            failed: push_result.failed + pull_result.failed,
            conflicts: [push_result.conflicts, pull_result.conflicts].concat(),
        })
    }
    
    async fn pull_remote_changes(&self) -> Result<SyncResult, SyncError> {
        let last_sync_time = self.get_last_sync_time().await?;
        let remote_changes = self.remote_api.get_changes_since(last_sync_time).await?;
        
        let mut synced = 0;
        let mut conflicts = Vec::new();
        
        for change in remote_changes {
            match self.apply_remote_change(&change).await {
                Ok(_) => synced += 1,
                Err(SyncError::Conflict(conflict)) => {
                    conflicts.push(conflict);
                }
                Err(e) => {
                    tracing::error!("Failed to apply remote change: {:?}", e);
                }
            }
        }
        
        self.update_last_sync_time().await?;
        
        Ok(SyncResult { synced, failed: 0, conflicts })
    }
    
    async fn apply_remote_change(&self, change: &RemoteChange) -> Result<(), SyncError> {
        let local_state = self.get_local_state(&change.entity_type, &change.id).await.ok();
        
        if let Some(local) = local_state {
            // æ£€æŸ¥å†²çª
            if self.has_conflict(&local, &change.data) {
                // å°è¯•è‡ªåŠ¨è§£å†³
                let resolved = self.conflict_resolver.merge_with_crdt(
                    &serde_json::from_value(local)?,
                    &serde_json::from_value(change.data.clone())?,
                );
                
                self.update_local_state(&change.entity_type, &change.id, &resolved).await?;
            } else {
                // æ— å†²çªï¼Œç›´æ¥åº”ç”¨
                self.update_local_state(&change.entity_type, &change.id, &change.data).await?;
            }
        } else {
            // æœ¬åœ°ä¸å­˜åœ¨ï¼Œåˆ›å»º
            self.create_local_entity(&change.entity_type, &change.data).await?;
        }
        
        Ok(())
    }
    
    async fn is_online(&self) -> bool {
        self.remote_api.health_check().await.is_ok()
    }
    
    async fn has_conflict(
        &self,
        local: &serde_json::Value,
        remote: &serde_json::Value,
    ) -> bool {
        // æ¯”è¾ƒç‰ˆæœ¬å·æˆ–æ—¶é—´æˆ³
        let local_version = local["version"].as_u64().unwrap_or(0);
        let remote_version = remote["version"].as_u64().unwrap_or(0);
        
        local_version != remote_version - 1
    }
    
    async fn get_local_state(
        &self,
        entity_type: &str,
        id: &str,
    ) -> Result<serde_json::Value, SyncError> {
        // ä»æœ¬åœ°æ•°æ®åº“è·å–
        todo!("Implement local state retrieval")
    }
    
    async fn update_local_state(
        &self,
        entity_type: &str,
        id: &str,
        data: &serde_json::Value,
    ) -> Result<(), SyncError> {
        // æ›´æ–°æœ¬åœ°æ•°æ®åº“
        todo!("Implement local state update")
    }
    
    async fn create_local_entity(
        &self,
        entity_type: &str,
        data: &serde_json::Value,
    ) -> Result<(), SyncError> {
        // åœ¨æœ¬åœ°æ•°æ®åº“åˆ›å»º
        todo!("Implement local entity creation")
    }
    
    async fn update_id_mapping(&self, local_id: &str, remote_id: &str) -> Result<(), SyncError> {
        // æ›´æ–° ID æ˜ å°„è¡¨
        todo!("Implement ID mapping update")
    }
    
    async fn get_last_sync_time(&self) -> Result<chrono::DateTime<chrono::Utc>, SyncError> {
        // è·å–ä¸Šæ¬¡åŒæ­¥æ—¶é—´
        todo!("Implement last sync time retrieval")
    }
    
    async fn update_last_sync_time(&self) -> Result<(), SyncError> {
        // æ›´æ–°åŒæ­¥æ—¶é—´
        todo!("Implement last sync time update")
    }
}

#[derive(Debug, Clone)]
pub struct SyncResult {
    pub synced: usize,
    pub failed: usize,
    pub conflicts: Vec<Conflict>,
}

#[derive(Debug, Clone)]
pub struct Conflict {
    pub entity_type: String,
    pub id: String,
    pub local_state: serde_json::Value,
    pub remote_state: serde_json::Value,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RemoteChange {
    pub entity_type: String,
    pub id: String,
    pub operation: String,  // "create", "update", "delete"
    pub data: serde_json::Value,
    pub timestamp: i64,
}

#[derive(Debug, thiserror::Error)]
pub enum SyncError {
    #[error("Offline")]
    Offline,
    
    #[error("Conflict: {0:?}")]
    Conflict(Conflict),
    
    #[error("Network error: {0}")]
    Network(String),
    
    #[error("Serialization error: {0}")]
    Serialization(#[from] serde_json::Error),
    
    #[error("Database error: {0}")]
    Database(String),
}

// è¿œç¨‹ API å®¢æˆ·ç«¯
pub struct RemoteAPI {
    base_url: String,
    client: reqwest::Client,
    auth_token: Arc<RwLock<Option<String>>>,
}

impl RemoteAPI {
    pub async fn create(
        &self,
        entity_type: &str,
        data: &serde_json::Value,
    ) -> Result<serde_json::Value, SyncError> {
        let url = format!("{}/api/{}", self.base_url, entity_type);
        let response = self.authenticated_request()
            .post(&url)
            .json(data)
            .send()
            .await
            .map_err(|e| SyncError::Network(e.to_string()))?;
        
        response.json().await
            .map_err(|e| SyncError::Network(e.to_string()))
    }
    
    pub async fn get(
        &self,
        entity_type: &str,
        id: &str,
    ) -> Result<serde_json::Value, SyncError> {
        let url = format!("{}/api/{}/{}", self.base_url, entity_type, id);
        let response = self.authenticated_request()
            .get(&url)
            .send()
            .await
            .map_err(|e| SyncError::Network(e.to_string()))?;
        
        response.json().await
            .map_err(|e| SyncError::Network(e.to_string()))
    }
    
    pub async fn update(
        &self,
        entity_type: &str,
        id: &str,
        changes: &serde_json::Value,
    ) -> Result<serde_json::Value, SyncError> {
        let url = format!("{}/api/{}/{}", self.base_url, entity_type, id);
        let response = self.authenticated_request()
            .patch(&url)
            .json(changes)
            .send()
            .await
            .map_err(|e| SyncError::Network(e.to_string()))?;
        
        response.json().await
            .map_err(|e| SyncError::Network(e.to_string()))
    }
    
    pub async fn delete(
        &self,
        entity_type: &str,
        id: &str,
    ) -> Result<(), SyncError> {
        let url = format!("{}/api/{}/{}", self.base_url, entity_type, id);
        self.authenticated_request()
            .delete(&url)
            .send()
            .await
            .map_err(|e| SyncError::Network(e.to_string()))?;
        
        Ok(())
    }
    
    pub async fn get_changes_since(
        &self,
        since: chrono::DateTime<chrono::Utc>,
    ) -> Result<Vec<RemoteChange>, SyncError> {
        let url = format!("{}/api/changes?since={}", self.base_url, since.timestamp());
        let response = self.authenticated_request()
            .get(&url)
            .send()
            .await
            .map_err(|e| SyncError::Network(e.to_string()))?;
        
        response.json().await
            .map_err(|e| SyncError::Network(e.to_string()))
    }
    
    pub async fn health_check(&self) -> Result<(), SyncError> {
        let url = format!("{}/health", self.base_url);
        self.client
            .get(&url)
            .timeout(Duration::from_secs(5))
            .send()
            .await
            .map_err(|e| SyncError::Network(e.to_string()))?;
        
        Ok(())
    }
    
    fn authenticated_request(&self) -> reqwest::RequestBuilder {
        let mut builder = self.client.get(&self.base_url);
        
        if let Some(token) = self.auth_token.try_read().ok().and_then(|t| t.clone()) {
            builder = builder.header("Authorization", format!("Bearer {}", token));
        }
        
        builder
    }
}
```



### 13. æ•°æ®åˆ†æå’Œå¯è§†åŒ–

#### 13.1 ä»»åŠ¡ç»Ÿè®¡åˆ†æ
```rust
// ä»»åŠ¡åˆ†æå¼•æ“
pub struct TaskAnalytics {
    db: Arc<DatabaseConnection>,
    cache: Arc<RwLock<AnalyticsCache>>,
}

#[derive(Clone)]
struct AnalyticsCache {
    productivity_stats: Option<(ProductivityStats, Instant)>,
    time_distribution: Option<(TimeDistribution, Instant)>,
    cache_ttl: Duration,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProductivityStats {
    pub total_tasks: usize,
    pub completed_tasks: usize,
    pub completion_rate: f64,
    pub avg_completion_time: Duration,
    pub tasks_by_priority: HashMap<Priority, usize>,
    pub tasks_by_project: HashMap<String, usize>,
    pub daily_completions: Vec<(chrono::NaiveDate, usize)>,
    pub weekly_trend: Vec<f64>,  // æœ€è¿‘å‡ å‘¨çš„å®Œæˆç‡è¶‹åŠ¿
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeDistribution {
    pub by_hour: HashMap<u32, usize>,
    pub by_day_of_week: HashMap<chrono::Weekday, usize>,
    pub by_month: HashMap<u32, usize>,
    pub peak_hours: Vec<u32>,
    pub peak_days: Vec<chrono::Weekday>,
}

impl TaskAnalytics {
    pub fn new(db: Arc<DatabaseConnection>) -> Self {
        Self {
            db,
            cache: Arc::new(RwLock::new(AnalyticsCache {
                productivity_stats: None,
                time_distribution: None,
                cache_ttl: Duration::from_secs(300), // 5åˆ†é’Ÿç¼“å­˜
            })),
        }
    }
    
    // è·å–ç”Ÿäº§åŠ›ç»Ÿè®¡
    pub async fn get_productivity_stats(
        &self,
        start_date: chrono::NaiveDate,
        end_date: chrono::NaiveDate,
    ) -> Result<ProductivityStats, AnalyticsError> {
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.cache.read().await;
            if let Some((stats, cached_at)) = &cache.productivity_stats {
                if cached_at.elapsed() < cache.cache_ttl {
                    return Ok(stats.clone());
                }
            }
        }
        
        // è®¡ç®—ç»Ÿè®¡æ•°æ®
        let stats = self.calculate_productivity_stats(start_date, end_date).await?;
        
        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.cache.write().await;
            cache.productivity_stats = Some((stats.clone(), Instant::now()));
        }
        
        Ok(stats)
    }
    
    async fn calculate_productivity_stats(
        &self,
        start_date: chrono::NaiveDate,
        end_date: chrono::NaiveDate,
    ) -> Result<ProductivityStats, AnalyticsError> {
        let store = Store::new((*self.db).clone());
        
        // è·å–æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰ä»»åŠ¡
        let all_tasks = store.get_items_in_date_range(start_date, end_date).await?;
        let completed_tasks: Vec<_> = all_tasks.iter().filter(|t| t.checked).collect();
        
        let total_tasks = all_tasks.len();
        let completed_count = completed_tasks.len();
        let completion_rate = if total_tasks > 0 {
            completed_count as f64 / total_tasks as f64
        } else {
            0.0
        };
        
        // è®¡ç®—å¹³å‡å®Œæˆæ—¶é—´
        let mut total_completion_time = Duration::ZERO;
        let mut completion_count = 0;
        
        for task in &completed_tasks {
            if let (Some(created), Some(completed)) = (task.created_at, task.completed_at) {
                let duration = completed.signed_duration_since(created);
                if let Ok(std_duration) = duration.to_std() {
                    total_completion_time += std_duration;
                    completion_count += 1;
                }
            }
        }
        
        let avg_completion_time = if completion_count > 0 {
            total_completion_time / completion_count as u32
        } else {
            Duration::ZERO
        };
        
        // æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
        let mut tasks_by_priority = HashMap::new();
        for task in &all_tasks {
            *tasks_by_priority.entry(task.priority).or_insert(0) += 1;
        }
        
        // æŒ‰é¡¹ç›®ç»Ÿè®¡
        let mut tasks_by_project = HashMap::new();
        for task in &all_tasks {
            if let Some(project_id) = &task.project_id {
                *tasks_by_project.entry(project_id.clone()).or_insert(0) += 1;
            }
        }
        
        // æ¯æ—¥å®Œæˆæ•°
        let mut daily_completions: HashMap<chrono::NaiveDate, usize> = HashMap::new();
        for task in &completed_tasks {
            if let Some(completed_at) = task.completed_at {
                *daily_completions.entry(completed_at.date_naive()).or_insert(0) += 1;
            }
        }
        
        let daily_completions: Vec<_> = daily_completions.into_iter().collect();
        
        // å‘¨è¶‹åŠ¿
        let weekly_trend = self.calculate_weekly_trend(&completed_tasks).await;
        
        Ok(ProductivityStats {
            total_tasks,
            completed_tasks: completed_count,
            completion_rate,
            avg_completion_time,
            tasks_by_priority,
            tasks_by_project,
            daily_completions,
            weekly_trend,
        })
    }
    
    async fn calculate_weekly_trend(&self, completed_tasks: &[&ItemModel]) -> Vec<f64> {
        let mut weekly_counts: HashMap<u32, usize> = HashMap::new();
        
        for task in completed_tasks {
            if let Some(completed_at) = task.completed_at {
                let week = completed_at.iso_week().week();
                *weekly_counts.entry(week).or_insert(0) += 1;
            }
        }
        
        // è½¬æ¢ä¸ºè¶‹åŠ¿æ•°æ®ï¼ˆæœ€è¿‘8å‘¨ï¼‰
        let current_week = chrono::Local::now().iso_week().week();
        (0..8)
            .map(|i| {
                let week = if current_week >= i { current_week - i } else { 52 + current_week - i };
                *weekly_counts.get(&week).unwrap_or(&0) as f64
            })
            .rev()
            .collect()
    }
    
    // è·å–æ—¶é—´åˆ†å¸ƒ
    pub async fn get_time_distribution(&self) -> Result<TimeDistribution, AnalyticsError> {
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.cache.read().await;
            if let Some((dist, cached_at)) = &cache.time_distribution {
                if cached_at.elapsed() < cache.cache_ttl {
                    return Ok(dist.clone());
                }
            }
        }
        
        let dist = self.calculate_time_distribution().await?;
        
        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.cache.write().await;
            cache.time_distribution = Some((dist.clone(), Instant::now()));
        }
        
        Ok(dist)
    }
    
    async fn calculate_time_distribution(&self) -> Result<TimeDistribution, AnalyticsError> {
        let store = Store::new((*self.db).clone());
        let completed_tasks = store.get_completed_items().await?;
        
        let mut by_hour: HashMap<u32, usize> = HashMap::new();
        let mut by_day_of_week: HashMap<chrono::Weekday, usize> = HashMap::new();
        let mut by_month: HashMap<u32, usize> = HashMap::new();
        
        for task in &completed_tasks {
            if let Some(completed_at) = task.completed_at {
                *by_hour.entry(completed_at.hour()).or_insert(0) += 1;
                *by_day_of_week.entry(completed_at.weekday()).or_insert(0) += 1;
                *by_month.entry(completed_at.month()).or_insert(0) += 1;
            }
        }
        
        // æ‰¾å‡ºé«˜å³°æ—¶æ®µ
        let mut hour_vec: Vec<_> = by_hour.iter().collect();
        hour_vec.sort_by_key(|(_, count)| std::cmp::Reverse(*count));
        let peak_hours: Vec<u32> = hour_vec.iter().take(3).map(|(hour, _)| **hour).collect();
        
        // æ‰¾å‡ºé«˜å³°æ—¥æœŸ
        let mut day_vec: Vec<_> = by_day_of_week.iter().collect();
        day_vec.sort_by_key(|(_, count)| std::cmp::Reverse(*count));
        let peak_days: Vec<chrono::Weekday> = day_vec.iter().take(3).map(|(day, _)| **day).collect();
        
        Ok(TimeDistribution {
            by_hour,
            by_day_of_week,
            by_month,
            peak_hours,
            peak_days,
        })
    }
    
    // é¢„æµ‹æœªæ¥å·¥ä½œé‡
    pub async fn predict_workload(
        &self,
        days_ahead: usize,
    ) -> Result<Vec<(chrono::NaiveDate, f64)>, AnalyticsError> {
        let stats = self.get_productivity_stats(
            chrono::Local::now().date_naive() - chrono::Duration::days(30),
            chrono::Local::now().date_naive(),
        ).await?;
        
        // ä½¿ç”¨ç®€å•çš„ç§»åŠ¨å¹³å‡é¢„æµ‹
        let avg_daily_tasks = stats.daily_completions.iter()
            .map(|(_, count)| *count as f64)
            .sum::<f64>() / stats.daily_completions.len() as f64;
        
        let mut predictions = Vec::new();
        let today = chrono::Local::now().date_naive();
        
        for i in 1..=days_ahead {
            let date = today + chrono::Duration::days(i as i64);
            // è€ƒè™‘å‘¨æœ«å› ç´ 
            let factor = if date.weekday() == chrono::Weekday::Sat || date.weekday() == chrono::Weekday::Sun {
                0.5  // å‘¨æœ«å·¥ä½œé‡å‡åŠ
            } else {
                1.0
            };
            
            predictions.push((date, avg_daily_tasks * factor));
        }
        
        Ok(predictions)
    }
    
    // ç”ŸæˆæŠ¥å‘Š
    pub async fn generate_report(
        &self,
        start_date: chrono::NaiveDate,
        end_date: chrono::NaiveDate,
    ) -> Result<AnalyticsReport, AnalyticsError> {
        let productivity = self.get_productivity_stats(start_date, end_date).await?;
        let time_dist = self.get_time_distribution().await?;
        let predictions = self.predict_workload(7).await?;
        
        Ok(AnalyticsReport {
            period: (start_date, end_date),
            productivity,
            time_distribution: time_dist,
            predictions,
            generated_at: chrono::Utc::now(),
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AnalyticsReport {
    pub period: (chrono::NaiveDate, chrono::NaiveDate),
    pub productivity: ProductivityStats,
    pub time_distribution: TimeDistribution,
    pub predictions: Vec<(chrono::NaiveDate, f64)>,
    pub generated_at: chrono::DateTime<chrono::Utc>,
}

#[derive(Debug, thiserror::Error)]
pub enum AnalyticsError {
    #[error("Database error: {0}")]
    Database(#[from] todos::error::TodoError),
    
    #[error("Calculation error: {0}")]
    Calculation(String),
}
```

#### 13.2 å¯è§†åŒ–å›¾è¡¨ç»„ä»¶
```rust
// å›¾è¡¨æ¸²æŸ“ç»„ä»¶
pub struct ChartView {
    chart_type: ChartType,
    data: ChartData,
}

#[derive(Debug, Clone)]
pub enum ChartType {
    Line,
    Bar,
    Pie,
    Heatmap,
}

#[derive(Debug, Clone)]
pub struct ChartData {
    pub labels: Vec<String>,
    pub datasets: Vec<Dataset>,
}

#[derive(Debug, Clone)]
pub struct Dataset {
    pub label: String,
    pub data: Vec<f64>,
    pub color: Hsla,
}

impl ChartView {
    pub fn new(chart_type: ChartType, data: ChartData) -> Self {
        Self { chart_type, data }
    }
    
    // æ¸²æŸ“æŠ˜çº¿å›¾
    fn render_line_chart(&self, cx: &mut Context<Self>) -> impl IntoElement {
        let max_value = self.data.datasets
            .iter()
            .flat_map(|ds| &ds.data)
            .fold(0.0f64, |a, &b| a.max(b));
        
        let chart_width = px(600.0);
        let chart_height = px(300.0);
        
        v_flex()
            .size_full()
            .child(
                // å›¾è¡¨æ ‡é¢˜
                div().text_lg().child("ä»»åŠ¡å®Œæˆè¶‹åŠ¿")
            )
            .child(
                // å›¾è¡¨åŒºåŸŸ
                svg()
                    .size(chart_width, chart_height)
                    .child(
                        // ç»˜åˆ¶ç½‘æ ¼çº¿
                        self.render_grid(chart_width, chart_height)
                    )
                    .children(
                        // ç»˜åˆ¶æ•°æ®çº¿
                        self.data.datasets.iter().map(|dataset| {
                            self.render_line(dataset, max_value, chart_width, chart_height)
                        })
                    )
            )
            .child(
                // å›¾ä¾‹
                self.render_legend(cx)
            )
    }
    
    fn render_line(
        &self,
        dataset: &Dataset,
        max_value: f64,
        width: Pixels,
        height: Pixels,
    ) -> impl IntoElement {
        let points: Vec<(f64, f64)> = dataset.data
            .iter()
            .enumerate()
            .map(|(i, &value)| {
                let x = (i as f64 / (dataset.data.len() - 1) as f64) * width.0 as f64;
                let y = height.0 as f64 - (value / max_value * height.0 as f64);
                (x, y)
            })
            .collect();
        
        // ç”Ÿæˆ SVG è·¯å¾„
        let path_data = points
            .iter()
            .enumerate()
            .map(|(i, (x, y))| {
                if i == 0 {
                    format!("M {} {}", x, y)
                } else {
                    format!("L {} {}", x, y)
                }
            })
            .collect::<Vec<_>>()
            .join(" ");
        
        svg::path()
            .attr("d", path_data)
            .attr("stroke", dataset.color.to_string())
            .attr("stroke-width", "2")
            .attr("fill", "none")
    }
    
    fn render_grid(&self, width: Pixels, height: Pixels) -> impl IntoElement {
        let grid_lines = 5;
        
        v_flex()
            .children((0..=grid_lines).map(|i| {
                let y = (i as f64 / grid_lines as f64) * height.0 as f64;
                svg::line()
                    .attr("x1", "0")
                    .attr("y1", y.to_string())
                    .attr("x2", width.0.to_string())
                    .attr("y2", y.to_string())
                    .attr("stroke", "#e0e0e0")
                    .attr("stroke-width", "1")
            }))
    }
    
    fn render_legend(&self, cx: &mut Context<Self>) -> impl IntoElement {
        h_flex()
            .gap_4()
            .children(self.data.datasets.iter().map(|dataset| {
                h_flex()
                    .gap_2()
                    .child(
                        div()
                            .w(px(16.0))
                            .h(px(16.0))
                            .bg(dataset.color)
                    )
                    .child(div().child(&dataset.label))
            }))
    }
    
    // æ¸²æŸ“æŸ±çŠ¶å›¾
    fn render_bar_chart(&self, cx: &mut Context<Self>) -> impl IntoElement {
        let max_value = self.data.datasets
            .iter()
            .flat_map(|ds| &ds.data)
            .fold(0.0f64, |a, &b| a.max(b));
        
        let chart_width = px(600.0);
        let chart_height = px(300.0);
        let bar_width = chart_width.0 / self.data.labels.len() as f32 * 0.8;
        
        v_flex()
            .size_full()
            .child(div().text_lg().child("ä»»åŠ¡ç»Ÿè®¡"))
            .child(
                h_flex()
                    .gap_2()
                    .children(self.data.labels.iter().enumerate().map(|(i, label)| {
                        let value = self.data.datasets[0].data[i];
                        let bar_height = (value / max_value * chart_height.0 as f64) as f32;
                        
                        v_flex()
                            .items_center()
                            .child(
                                div()
                                    .w(px(bar_width))
                                    .h(px(bar_height))
                                    .bg(self.data.datasets[0].color)
                                    .rounded(px(4.0))
                            )
                            .child(div().text_sm().child(label))
                    }))
            )
    }
    
    // æ¸²æŸ“é¥¼å›¾
    fn render_pie_chart(&self, cx: &mut Context<Self>) -> impl IntoElement {
        let total: f64 = self.data.datasets[0].data.iter().sum();
        let mut current_angle = 0.0;
        
        let radius = 100.0;
        let center_x = 150.0;
        let center_y = 150.0;
        
        v_flex()
            .size_full()
            .child(div().text_lg().child("ä»»åŠ¡åˆ†å¸ƒ"))
            .child(
                svg()
                    .size(px(300.0), px(300.0))
                    .children(self.data.labels.iter().enumerate().map(|(i, label)| {
                        let value = self.data.datasets[0].data[i];
                        let angle = (value / total) * 360.0;
                        
                        let start_angle = current_angle;
                        current_angle += angle;
                        
                        self.render_pie_slice(
                            center_x,
                            center_y,
                            radius,
                            start_angle,
                            angle,
                            self.get_color(i),
                        )
                    }))
            )
            .child(self.render_legend(cx))
    }
    
    fn render_pie_slice(
        &self,
        cx: f64,
        cy: f64,
        radius: f64,
        start_angle: f64,
        angle: f64,
        color: Hsla,
    ) -> impl IntoElement {
        let start_rad = start_angle.to_radians();
        let end_rad = (start_angle + angle).to_radians();
        
        let x1 = cx + radius * start_rad.cos();
        let y1 = cy + radius * start_rad.sin();
        let x2 = cx + radius * end_rad.cos();
        let y2 = cy + radius * end_rad.sin();
        
        let large_arc = if angle > 180.0 { 1 } else { 0 };
        
        let path_data = format!(
            "M {} {} L {} {} A {} {} 0 {} 1 {} {} Z",
            cx, cy, x1, y1, radius, radius, large_arc, x2, y2
        );
        
        svg::path()
            .attr("d", path_data)
            .attr("fill", color.to_string())
    }
    
    fn get_color(&self, index: usize) -> Hsla {
        let colors = vec![
            gpui::rgb(0x3584e4),
            gpui::rgb(0x33d17a),
            gpui::rgb(0xf6d32d),
            gpui::rgb(0xff7800),
            gpui::rgb(0xe01b24),
        ];
        
        colors[index % colors.len()].into()
    }
}

impl Render for ChartView {
    fn render(&mut self, _window: &mut Window, cx: &mut Context<Self>) -> impl IntoElement {
        match self.chart_type {
            ChartType::Line => self.render_line_chart(cx),
            ChartType::Bar => self.render_bar_chart(cx),
            ChartType::Pie => self.render_pie_chart(cx),
            ChartType::Heatmap => todo!("Implement heatmap"),
        }
    }
}
```



### 14. å›½é™…åŒ–å’Œæœ¬åœ°åŒ–æ·±åº¦ä¼˜åŒ–

#### 14.1 åŠ¨æ€è¯­è¨€åˆ‡æ¢
```rust
// å¢å¼ºçš„å›½é™…åŒ–ç³»ç»Ÿ
pub struct I18nManager {
    current_locale: Arc<RwLock<String>>,
    translations: Arc<RwLock<HashMap<String, HashMap<String, String>>>>,
    fallback_locale: String,
    pluralization_rules: HashMap<String, Box<dyn Fn(i32) -> usize + Send + Sync>>,
}

impl I18nManager {
    pub fn new(default_locale: &str) -> Self {
        let mut manager = Self {
            current_locale: Arc::new(RwLock::new(default_locale.to_string())),
            translations: Arc::new(RwLock::new(HashMap::new())),
            fallback_locale: "en".to_string(),
            pluralization_rules: HashMap::new(),
        };
        
        // æ³¨å†Œå¤æ•°è§„åˆ™
        manager.register_pluralization_rules();
        manager
    }
    
    // æ³¨å†Œå¤æ•°è§„åˆ™
    fn register_pluralization_rules(&mut self) {
        // è‹±è¯­è§„åˆ™
        self.pluralization_rules.insert(
            "en".to_string(),
            Box::new(|n| if n == 1 { 0 } else { 1 }),
        );
        
        // ä¸­æ–‡è§„åˆ™ï¼ˆæ— å¤æ•°ï¼‰
        self.pluralization_rules.insert(
            "zh".to_string(),
            Box::new(|_| 0),
        );
        
        // ä¿„è¯­è§„åˆ™ï¼ˆå¤æ‚ï¼‰
        self.pluralization_rules.insert(
            "ru".to_string(),
            Box::new(|n| {
                if n % 10 == 1 && n % 100 != 11 {
                    0
                } else if n % 10 >= 2 && n % 10 <= 4 && (n % 100 < 10 || n % 100 >= 20) {
                    1
                } else {
                    2
                }
            }),
        );
    }
    
    // ç¿»è¯‘æ–‡æœ¬
    pub async fn translate(&self, key: &str) -> String {
        let locale = self.current_locale.read().await;
        let translations = self.translations.read().await;
        
        // å°è¯•å½“å‰è¯­è¨€
        if let Some(locale_translations) = translations.get(&*locale) {
            if let Some(translation) = locale_translations.get(key) {
                return translation.clone();
            }
        }
        
        // å›é€€åˆ°é»˜è®¤è¯­è¨€
        if let Some(fallback_translations) = translations.get(&self.fallback_locale) {
            if let Some(translation) = fallback_translations.get(key) {
                return translation.clone();
            }
        }
        
        // è¿”å›é”®å
        key.to_string()
    }
    
    // å¸¦å‚æ•°çš„ç¿»è¯‘
    pub async fn translate_with_params(
        &self,
        key: &str,
        params: HashMap<String, String>,
    ) -> String {
        let mut text = self.translate(key).await;
        
        for (param_key, param_value) in params {
            text = text.replace(&format!("{{{}}}", param_key), &param_value);
        }
        
        text
    }
    
    // å¤æ•°ç¿»è¯‘
    pub async fn translate_plural(&self, key: &str, count: i32) -> String {
        let locale = self.current_locale.read().await;
        
        // è·å–å¤æ•°å½¢å¼ç´¢å¼•
        let plural_index = if let Some(rule) = self.pluralization_rules.get(&*locale) {
            rule(count)
        } else {
            if count == 1 { 0 } else { 1 }
        };
        
        // æ„å»ºé”®å
        let plural_key = format!("{}_{}", key, plural_index);
        
        let mut text = self.translate(&plural_key).await;
        text = text.replace("{count}", &count.to_string());
        
        text
    }
    
    // æ—¥æœŸæ ¼å¼åŒ–
    pub async fn format_date(&self, date: chrono::DateTime<chrono::Local>) -> String {
        let locale = self.current_locale.read().await;
        
        match locale.as_str() {
            "zh" => date.format("%Yå¹´%mæœˆ%dæ—¥").to_string(),
            "en" => date.format("%B %d, %Y").to_string(),
            "de" => date.format("%d. %B %Y").to_string(),
            _ => date.format("%Y-%m-%d").to_string(),
        }
    }
    
    // ç›¸å¯¹æ—¶é—´
    pub async fn format_relative_time(&self, date: chrono::DateTime<chrono::Local>) -> String {
        let now = chrono::Local::now();
        let duration = now.signed_duration_since(date);
        
        let locale = self.current_locale.read().await;
        
        if duration.num_seconds() < 60 {
            self.translate("time.just_now").await
        } else if duration.num_minutes() < 60 {
            let minutes = duration.num_minutes();
            self.translate_plural("time.minutes_ago", minutes as i32).await
        } else if duration.num_hours() < 24 {
            let hours = duration.num_hours();
            self.translate_plural("time.hours_ago", hours as i32).await
        } else if duration.num_days() < 7 {
            let days = duration.num_days();
            self.translate_plural("time.days_ago", days as i32).await
        } else {
            self.format_date(date).await
        }
    }
    
    // æ•°å­—æ ¼å¼åŒ–
    pub async fn format_number(&self, number: f64) -> String {
        let locale = self.current_locale.read().await;
        
        match locale.as_str() {
            "zh" => {
                // ä¸­æ–‡æ•°å­—æ ¼å¼ï¼š1,234.56
                format!("{:,.2}", number)
            }
            "de" => {
                // å¾·è¯­æ•°å­—æ ¼å¼ï¼š1.234,56
                let formatted = format!("{:.2}", number);
                formatted.replace(".", ",").replace(",", ".")
            }
            _ => {
                // é»˜è®¤æ ¼å¼
                format!("{:,.2}", number)
            }
        }
    }
    
    // åˆ‡æ¢è¯­è¨€
    pub async fn set_locale(&self, locale: &str) -> Result<(), I18nError> {
        // éªŒè¯è¯­è¨€æ˜¯å¦æ”¯æŒ
        let translations = self.translations.read().await;
        if !translations.contains_key(locale) {
            return Err(I18nError::UnsupportedLocale(locale.to_string()));
        }
        
        let mut current = self.current_locale.write().await;
        *current = locale.to_string();
        
        Ok(())
    }
    
    // åŠ è½½ç¿»è¯‘æ–‡ä»¶
    pub async fn load_translations(&self, locale: &str, path: &Path) -> Result<(), I18nError> {
        let content = tokio::fs::read_to_string(path).await
            .map_err(|e| I18nError::LoadError(e.to_string()))?;
        
        let translations: HashMap<String, String> = serde_json::from_str(&content)
            .map_err(|e| I18nError::ParseError(e.to_string()))?;
        
        let mut all_translations = self.translations.write().await;
        all_translations.insert(locale.to_string(), translations);
        
        Ok(())
    }
}

#[derive(Debug, thiserror::Error)]
pub enum I18nError {
    #[error("Unsupported locale: {0}")]
    UnsupportedLocale(String),
    
    #[error("Failed to load translations: {0}")]
    LoadError(String),
    
    #[error("Failed to parse translations: {0}")]
    ParseError(String),
}

// ç¿»è¯‘å®
#[macro_export]
macro_rules! t {
    ($key:expr) => {
        $crate::i18n::I18nManager::translate($key).await
    };
    ($key:expr, $($param_key:expr => $param_value:expr),+) => {{
        let mut params = std::collections::HashMap::new();
        $(
            params.insert($param_key.to_string(), $param_value.to_string());
        )+
        $crate::i18n::I18nManager::translate_with_params($key, params).await
    }};
}
```

#### 14.2 RTLï¼ˆä»å³åˆ°å·¦ï¼‰è¯­è¨€æ”¯æŒ
```rust
// RTL å¸ƒå±€ç®¡ç†å™¨
pub struct RTLLayoutManager {
    is_rtl: bool,
}

impl RTLLayoutManager {
    pub fn new(locale: &str) -> Self {
        let rtl_locales = vec!["ar", "he", "fa", "ur"];
        let is_rtl = rtl_locales.contains(&locale);
        
        Self { is_rtl }
    }
    
    // åº”ç”¨ RTL æ ·å¼
    pub fn apply_rtl_styles<T: Styled>(&self, element: T) -> T {
        if self.is_rtl {
            element.flex_row_reverse()
        } else {
            element
        }
    }
    
    // æ–‡æœ¬å¯¹é½
    pub fn text_align(&self) -> TextAlign {
        if self.is_rtl {
            TextAlign::Right
        } else {
            TextAlign::Left
        }
    }
    
    // è¾¹è·è°ƒæ•´
    pub fn margin_start(&self, value: Pixels) -> StyleRefinement {
        if self.is_rtl {
            StyleRefinement::default().margin_right(value)
        } else {
            StyleRefinement::default().margin_left(value)
        }
    }
    
    pub fn margin_end(&self, value: Pixels) -> StyleRefinement {
        if self.is_rtl {
            StyleRefinement::default().margin_left(value)
        } else {
            StyleRefinement::default().margin_right(value)
        }
    }
}
```

### 15. é«˜çº§æ„å»ºå’Œéƒ¨ç½²ä¼˜åŒ–

#### 15.1 å¢é‡æ„å»ºä¼˜åŒ–
```toml
# Cargo.toml å¢å¼ºé…ç½®

[profile.dev]
# å¢é‡ç¼–è¯‘
incremental = true
# åˆ†ç¦»è°ƒè¯•ä¿¡æ¯
split-debuginfo = "unpacked"  # macOS/Linux
# å¹¶è¡Œç¼–è¯‘
codegen-units = 256

[profile.dev.build-override]
# æ„å»ºè„šæœ¬ä¼˜åŒ–
opt-level = 3
codegen-units = 1

# æ–°å¢ï¼šCI æ„å»ºé…ç½®
[profile.ci]
inherits = "dev"
incremental = false  # CI ä¸­ç¦ç”¨å¢é‡ç¼–è¯‘
debug = 0
opt-level = 1

# æ–°å¢ï¼šåŸºå‡†æµ‹è¯•é…ç½®
[profile.bench]
inherits = "release"
lto = true
codegen-units = 1
```

#### 15.2 è·¨å¹³å°æ‰“åŒ…è„šæœ¬
```bash
#!/bin/bash
# scripts/build_release.sh

set -e

echo "Building MyTool for multiple platforms..."

# ç‰ˆæœ¬å·
VERSION=$(grep '^version' Cargo.toml | head -1 | cut -d'"' -f2)
echo "Version: $VERSION"

# æ¸…ç†æ—§æ„å»º
cargo clean

# Windows æ„å»º
echo "Building for Windows..."
cargo build --release --target x86_64-pc-windows-msvc
mkdir -p dist/windows
cp target/x86_64-pc-windows-msvc/release/mytool.exe dist/windows/
cp -r themes dist/windows/
cp -r assets dist/windows/

# åˆ›å»º Windows å®‰è£…ç¨‹åº
if command -v makensis &> /dev/null; then
    makensis scripts/windows_installer.nsi
fi

# macOS æ„å»º
echo "Building for macOS..."
cargo build --release --target x86_64-apple-darwin
cargo build --release --target aarch64-apple-darwin

# åˆ›å»ºé€šç”¨äºŒè¿›åˆ¶
lipo -create \
    target/x86_64-apple-darwin/release/mytool \
    target/aarch64-apple-darwin/release/mytool \
    -output dist/macos/mytool

# åˆ›å»º .app åŒ…
./scripts/create_macos_app.sh

# Linux æ„å»º
echo "Building for Linux..."
cargo build --release --target x86_64-unknown-linux-gnu
mkdir -p dist/linux
cp target/x86_64-unknown-linux-gnu/release/mytool dist/linux/
cp -r themes dist/linux/
cp -r assets dist/linux/

# åˆ›å»º AppImage
if command -v appimagetool &> /dev/null; then
    ./scripts/create_appimage.sh
fi

# åˆ›å»ºå‹ç¼©åŒ…
echo "Creating archives..."
cd dist
tar -czf mytool-${VERSION}-linux-x86_64.tar.gz linux/
zip -r mytool-${VERSION}-windows-x86_64.zip windows/
zip -r mytool-${VERSION}-macos-universal.zip macos/

echo "Build complete! Artifacts in dist/"
```

#### 15.3 è‡ªåŠ¨æ›´æ–°ç³»ç»Ÿ
```rust
// è‡ªåŠ¨æ›´æ–°å®¢æˆ·ç«¯
pub struct AutoUpdater {
    current_version: String,
    update_url: String,
    client: reqwest::Client,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct UpdateInfo {
    pub version: String,
    pub download_url: String,
    pub changelog: String,
    pub required: bool,  // æ˜¯å¦å¼ºåˆ¶æ›´æ–°
    pub checksum: String,
}

impl AutoUpdater {
    pub fn new(current_version: String, update_url: String) -> Self {
        Self {
            current_version,
            update_url,
            client: reqwest::Client::new(),
        }
    }
    
    // æ£€æŸ¥æ›´æ–°
    pub async fn check_for_updates(&self) -> Result<Option<UpdateInfo>, UpdateError> {
        let url = format!("{}/latest?current={}", self.update_url, self.current_version);
        
        let response = self.client.get(&url)
            .timeout(Duration::from_secs(10))
            .send()
            .await
            .map_err(|e| UpdateError::Network(e.to_string()))?;
        
        if response.status() == 204 {
            // æ— æ›´æ–°
            return Ok(None);
        }
        
        let update_info: UpdateInfo = response.json().await
            .map_err(|e| UpdateError::Parse(e.to_string()))?;
        
        Ok(Some(update_info))
    }
    
    // ä¸‹è½½æ›´æ–°
    pub async fn download_update(
        &self,
        update_info: &UpdateInfo,
        progress_callback: impl Fn(u64, u64),
    ) -> Result<PathBuf, UpdateError> {
        let response = self.client.get(&update_info.download_url)
            .send()
            .await
            .map_err(|e| UpdateError::Network(e.to_string()))?;
        
        let total_size = response.content_length().unwrap_or(0);
        
        // ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
        let temp_path = std::env::temp_dir().join(format!("mytool_update_{}", update_info.version));
        let mut file = tokio::fs::File::create(&temp_path).await
            .map_err(|e| UpdateError::IO(e.to_string()))?;
        
        let mut downloaded = 0u64;
        let mut stream = response.bytes_stream();
        
        while let Some(chunk) = stream.next().await {
            let chunk = chunk.map_err(|e| UpdateError::Network(e.to_string()))?;
            file.write_all(&chunk).await
                .map_err(|e| UpdateError::IO(e.to_string()))?;
            
            downloaded += chunk.len() as u64;
            progress_callback(downloaded, total_size);
        }
        
        // éªŒè¯æ ¡éªŒå’Œ
        let checksum = self.calculate_checksum(&temp_path).await?;
        if checksum != update_info.checksum {
            tokio::fs::remove_file(&temp_path).await.ok();
            return Err(UpdateError::ChecksumMismatch);
        }
        
        Ok(temp_path)
    }
    
    // åº”ç”¨æ›´æ–°
    pub async fn apply_update(&self, update_path: &Path) -> Result<(), UpdateError> {
        let current_exe = std::env::current_exe()
            .map_err(|e| UpdateError::IO(e.to_string()))?;
        
        let backup_path = current_exe.with_extension("exe.bak");
        
        // å¤‡ä»½å½“å‰ç‰ˆæœ¬
        tokio::fs::copy(&current_exe, &backup_path).await
            .map_err(|e| UpdateError::IO(e.to_string()))?;
        
        // æ›¿æ¢å¯æ‰§è¡Œæ–‡ä»¶
        #[cfg(target_os = "windows")]
        {
            // Windows: éœ€è¦é‡å¯åº”ç”¨
            self.schedule_update_on_restart(update_path, &current_exe).await?;
        }
        
        #[cfg(not(target_os = "windows"))]
        {
            // Unix: å¯ä»¥ç›´æ¥æ›¿æ¢
            tokio::fs::copy(update_path, &current_exe).await
                .map_err(|e| UpdateError::IO(e.to_string()))?;
            
            // è®¾ç½®æ‰§è¡Œæƒé™
            #[cfg(unix)]
            {
                use std::os::unix::fs::PermissionsExt;
                let mut perms = tokio::fs::metadata(&current_exe).await
                    .map_err(|e| UpdateError::IO(e.to_string()))?
                    .permissions();
                perms.set_mode(0o755);
                tokio::fs::set_permissions(&current_exe, perms).await
                    .map_err(|e| UpdateError::IO(e.to_string()))?;
            }
        }
        
        Ok(())
    }
    
    #[cfg(target_os = "windows")]
    async fn schedule_update_on_restart(
        &self,
        update_path: &Path,
        target_path: &Path,
    ) -> Result<(), UpdateError> {
        // åˆ›å»ºæ›´æ–°è„šæœ¬
        let script_path = std::env::temp_dir().join("mytool_update.bat");
        let script_content = format!(
            r#"@echo off
timeout /t 2 /nobreak > nul
move /y "{}" "{}"
start "" "{}"
del "%~f0"
"#,
            update_path.display(),
            target_path.display(),
            target_path.display()
        );
        
        tokio::fs::write(&script_path, script_content).await
            .map_err(|e| UpdateError::IO(e.to_string()))?;
        
        // å¯åŠ¨è„šæœ¬
        std::process::Command::new("cmd")
            .args(&["/C", "start", "", script_path.to_str().unwrap()])
            .spawn()
            .map_err(|e| UpdateError::IO(e.to_string()))?;
        
        Ok(())
    }
    
    async fn calculate_checksum(&self, path: &Path) -> Result<String, UpdateError> {
        use sha2::{Sha256, Digest};
        
        let mut file = tokio::fs::File::open(path).await
            .map_err(|e| UpdateError::IO(e.to_string()))?;
        
        let mut hasher = Sha256::new();
        let mut buffer = vec![0; 8192];
        
        loop {
            let n = file.read(&mut buffer).await
                .map_err(|e| UpdateError::IO(e.to_string()))?;
            
            if n == 0 {
                break;
            }
            
            hasher.update(&buffer[..n]);
        }
        
        Ok(format!("{:x}", hasher.finalize()))
    }
}

#[derive(Debug, thiserror::Error)]
pub enum UpdateError {
    #[error("Network error: {0}")]
    Network(String),
    
    #[error("Parse error: {0}")]
    Parse(String),
    
    #[error("IO error: {0}")]
    IO(String),
    
    #[error("Checksum mismatch")]
    ChecksumMismatch,
}
```



### 16. å¯æ‰©å±•æ€§å’Œæ¨¡å—åŒ–ä¼˜åŒ–

#### 16.1 é¢†åŸŸé©±åŠ¨è®¾è®¡ï¼ˆDDDï¼‰é‡æ„
```rust
// é¢†åŸŸæ¨¡å‹å±‚
pub mod domain {
    // å€¼å¯¹è±¡
    #[derive(Debug, Clone, PartialEq, Eq)]
    pub struct TaskId(String);
    
    impl TaskId {
        pub fn new() -> Self {
            Self(uuid::Uuid::new_v4().to_string())
        }
        
        pub fn from_string(s: String) -> Result<Self, DomainError> {
            if s.is_empty() {
                return Err(DomainError::InvalidId);
            }
            Ok(Self(s))
        }
        
        pub fn value(&self) -> &str {
            &self.0
        }
    }
    
    // å®ä½“
    #[derive(Debug, Clone)]
    pub struct Task {
        id: TaskId,
        content: TaskContent,
        status: TaskStatus,
        priority: Priority,
        due_date: Option<DueDate>,
        created_at: chrono::DateTime<chrono::Utc>,
        updated_at: chrono::DateTime<chrono::Utc>,
    }
    
    impl Task {
        pub fn new(content: TaskContent) -> Self {
            let now = chrono::Utc::now();
            Self {
                id: TaskId::new(),
                content,
                status: TaskStatus::Pending,
                priority: Priority::Medium,
                due_date: None,
                created_at: now,
                updated_at: now,
            }
        }
        
        // é¢†åŸŸè¡Œä¸º
        pub fn complete(&mut self) -> Result<TaskCompleted, DomainError> {
            if self.status == TaskStatus::Completed {
                return Err(DomainError::AlreadyCompleted);
            }
            
            self.status = TaskStatus::Completed;
            self.updated_at = chrono::Utc::now();
            
            Ok(TaskCompleted {
                task_id: self.id.clone(),
                completed_at: self.updated_at,
            })
        }
        
        pub fn set_priority(&mut self, priority: Priority) -> Result<(), DomainError> {
            self.priority = priority;
            self.updated_at = chrono::Utc::now();
            Ok(())
        }
        
        pub fn set_due_date(&mut self, due_date: DueDate) -> Result<(), DomainError> {
            if due_date.is_past() {
                return Err(DomainError::InvalidDueDate);
            }
            
            self.due_date = Some(due_date);
            self.updated_at = chrono::Utc::now();
            Ok(())
        }
        
        pub fn is_overdue(&self) -> bool {
            if let Some(due_date) = &self.due_date {
                due_date.is_past() && self.status != TaskStatus::Completed
            } else {
                false
            }
        }
    }
    
    // å€¼å¯¹è±¡
    #[derive(Debug, Clone, PartialEq, Eq)]
    pub struct TaskContent(String);
    
    impl TaskContent {
        pub fn new(content: String) -> Result<Self, DomainError> {
            if content.trim().is_empty() {
                return Err(DomainError::EmptyContent);
            }
            
            if content.len() > 10000 {
                return Err(DomainError::ContentTooLong);
            }
            
            Ok(Self(content))
        }
        
        pub fn value(&self) -> &str {
            &self.0
        }
    }
    
    #[derive(Debug, Clone, PartialEq, Eq)]
    pub struct DueDate(chrono::DateTime<chrono::Utc>);
    
    impl DueDate {
        pub fn new(date: chrono::DateTime<chrono::Utc>) -> Self {
            Self(date)
        }
        
        pub fn is_past(&self) -> bool {
            self.0 < chrono::Utc::now()
        }
        
        pub fn days_until(&self) -> i64 {
            (self.0 - chrono::Utc::now()).num_days()
        }
    }
    
    // é¢†åŸŸäº‹ä»¶
    #[derive(Debug, Clone)]
    pub struct TaskCompleted {
        pub task_id: TaskId,
        pub completed_at: chrono::DateTime<chrono::Utc>,
    }
    
    #[derive(Debug, Clone)]
    pub struct TaskCreated {
        pub task_id: TaskId,
        pub content: TaskContent,
        pub created_at: chrono::DateTime<chrono::Utc>,
    }
    
    // é¢†åŸŸæœåŠ¡
    pub struct TaskDomainService;
    
    impl TaskDomainService {
        pub fn can_delete_task(task: &Task, user_role: &UserRole) -> bool {
            match user_role {
                UserRole::Admin => true,
                UserRole::Owner => true,
                UserRole::Member => task.status != TaskStatus::Completed,
                UserRole::Guest => false,
            }
        }
        
        pub fn calculate_task_score(task: &Task) -> f64 {
            let mut score = 0.0;
            
            // ä¼˜å…ˆçº§æƒé‡
            score += match task.priority {
                Priority::High => 3.0,
                Priority::Medium => 2.0,
                Priority::Low => 1.0,
            };
            
            // æˆªæ­¢æ—¥æœŸæƒé‡
            if let Some(due_date) = &task.due_date {
                let days_until = due_date.days_until();
                if days_until < 0 {
                    score += 5.0;  // å·²é€¾æœŸ
                } else if days_until <= 1 {
                    score += 4.0;  // ä»Šå¤©æˆ–æ˜å¤©
                } else if days_until <= 7 {
                    score += 2.0;  // æœ¬å‘¨å†…
                }
            }
            
            score
        }
    }
    
    // ä»“å‚¨æ¥å£ï¼ˆåœ¨é¢†åŸŸå±‚å®šä¹‰ï¼Œåœ¨åŸºç¡€è®¾æ–½å±‚å®ç°ï¼‰
    #[async_trait::async_trait]
    pub trait TaskRepository: Send + Sync {
        async fn find_by_id(&self, id: &TaskId) -> Result<Option<Task>, RepositoryError>;
        async fn save(&self, task: &Task) -> Result<(), RepositoryError>;
        async fn delete(&self, id: &TaskId) -> Result<(), RepositoryError>;
        async fn find_all(&self) -> Result<Vec<Task>, RepositoryError>;
        async fn find_by_status(&self, status: TaskStatus) -> Result<Vec<Task>, RepositoryError>;
    }
    
    // é¢†åŸŸé”™è¯¯
    #[derive(Debug, thiserror::Error)]
    pub enum DomainError {
        #[error("Invalid task ID")]
        InvalidId,
        
        #[error("Task content cannot be empty")]
        EmptyContent,
        
        #[error("Task content is too long")]
        ContentTooLong,
        
        #[error("Task is already completed")]
        AlreadyCompleted,
        
        #[error("Invalid due date")]
        InvalidDueDate,
    }
    
    #[derive(Debug, thiserror::Error)]
    pub enum RepositoryError {
        #[error("Database error: {0}")]
        Database(String),
        
        #[error("Not found")]
        NotFound,
    }
}
```

#### 16.2 CQRSï¼ˆå‘½ä»¤æŸ¥è¯¢èŒè´£åˆ†ç¦»ï¼‰æ¨¡å¼
```rust
// å‘½ä»¤å±‚
pub mod commands {
    use super::domain::*;
    
    // å‘½ä»¤
    #[derive(Debug, Clone)]
    pub struct CreateTaskCommand {
        pub content: String,
        pub priority: Option<Priority>,
        pub due_date: Option<chrono::DateTime<chrono::Utc>>,
    }
    
    #[derive(Debug, Clone)]
    pub struct CompleteTaskCommand {
        pub task_id: String,
    }
    
    #[derive(Debug, Clone)]
    pub struct UpdateTaskCommand {
        pub task_id: String,
        pub content: Option<String>,
        pub priority: Option<Priority>,
        pub due_date: Option<chrono::DateTime<chrono::Utc>>,
    }
    
    // å‘½ä»¤å¤„ç†å™¨
    pub struct TaskCommandHandler {
        repository: Arc<dyn TaskRepository>,
        event_bus: Arc<EventBus>,
    }
    
    impl TaskCommandHandler {
        pub fn new(repository: Arc<dyn TaskRepository>, event_bus: Arc<EventBus>) -> Self {
            Self { repository, event_bus }
        }
        
        pub async fn handle_create_task(
            &self,
            command: CreateTaskCommand,
        ) -> Result<TaskId, CommandError> {
            // åˆ›å»ºä»»åŠ¡
            let content = TaskContent::new(command.content)?;
            let mut task = Task::new(content);
            
            if let Some(priority) = command.priority {
                task.set_priority(priority)?;
            }
            
            if let Some(due_date) = command.due_date {
                task.set_due_date(DueDate::new(due_date))?;
            }
            
            // ä¿å­˜
            let task_id = task.id().clone();
            self.repository.save(&task).await?;
            
            // å‘å¸ƒäº‹ä»¶
            self.event_bus.publish(DomainEvent::TaskCreated(TaskCreated {
                task_id: task_id.clone(),
                content: task.content().clone(),
                created_at: task.created_at(),
            }));
            
            Ok(task_id)
        }
        
        pub async fn handle_complete_task(
            &self,
            command: CompleteTaskCommand,
        ) -> Result<(), CommandError> {
            let task_id = TaskId::from_string(command.task_id)?;
            
            // åŠ è½½ä»»åŠ¡
            let mut task = self.repository.find_by_id(&task_id).await?
                .ok_or(CommandError::TaskNotFound)?;
            
            // å®Œæˆä»»åŠ¡
            let event = task.complete()?;
            
            // ä¿å­˜
            self.repository.save(&task).await?;
            
            // å‘å¸ƒäº‹ä»¶
            self.event_bus.publish(DomainEvent::TaskCompleted(event));
            
            Ok(())
        }
        
        pub async fn handle_update_task(
            &self,
            command: UpdateTaskCommand,
        ) -> Result<(), CommandError> {
            let task_id = TaskId::from_string(command.task_id)?;
            
            let mut task = self.repository.find_by_id(&task_id).await?
                .ok_or(CommandError::TaskNotFound)?;
            
            if let Some(content) = command.content {
                task.set_content(TaskContent::new(content)?)?;
            }
            
            if let Some(priority) = command.priority {
                task.set_priority(priority)?;
            }
            
            if let Some(due_date) = command.due_date {
                task.set_due_date(DueDate::new(due_date))?;
            }
            
            self.repository.save(&task).await?;
            
            Ok(())
        }
    }
    
    #[derive(Debug, thiserror::Error)]
    pub enum CommandError {
        #[error("Domain error: {0}")]
        Domain(#[from] DomainError),
        
        #[error("Repository error: {0}")]
        Repository(#[from] RepositoryError),
        
        #[error("Task not found")]
        TaskNotFound,
    }
}

// æŸ¥è¯¢å±‚
pub mod queries {
    use super::domain::*;
    
    // æŸ¥è¯¢
    #[derive(Debug, Clone)]
    pub struct GetTaskQuery {
        pub task_id: String,
    }
    
    #[derive(Debug, Clone)]
    pub struct ListTasksQuery {
        pub status: Option<TaskStatus>,
        pub priority: Option<Priority>,
        pub limit: Option<usize>,
        pub offset: Option<usize>,
    }
    
    // æŸ¥è¯¢ç»“æœï¼ˆDTOï¼‰
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct TaskDto {
        pub id: String,
        pub content: String,
        pub status: String,
        pub priority: String,
        pub due_date: Option<String>,
        pub is_overdue: bool,
        pub created_at: String,
        pub updated_at: String,
    }
    
    #[derive(Debug, Clone, Serialize, Deserialize)]
    pub struct TaskListDto {
        pub tasks: Vec<TaskDto>,
        pub total: usize,
        pub has_more: bool,
    }
    
    // æŸ¥è¯¢å¤„ç†å™¨
    pub struct TaskQueryHandler {
        repository: Arc<dyn TaskRepository>,
    }
    
    impl TaskQueryHandler {
        pub fn new(repository: Arc<dyn TaskRepository>) -> Self {
            Self { repository }
        }
        
        pub async fn handle_get_task(
            &self,
            query: GetTaskQuery,
        ) -> Result<TaskDto, QueryError> {
            let task_id = TaskId::from_string(query.task_id)?;
            
            let task = self.repository.find_by_id(&task_id).await?
                .ok_or(QueryError::TaskNotFound)?;
            
            Ok(Self::task_to_dto(&task))
        }
        
        pub async fn handle_list_tasks(
            &self,
            query: ListTasksQuery,
        ) -> Result<TaskListDto, QueryError> {
            let mut tasks = if let Some(status) = query.status {
                self.repository.find_by_status(status).await?
            } else {
                self.repository.find_all().await?
            };
            
            // è¿‡æ»¤ä¼˜å…ˆçº§
            if let Some(priority) = query.priority {
                tasks.retain(|t| t.priority() == &priority);
            }
            
            let total = tasks.len();
            
            // åˆ†é¡µ
            let offset = query.offset.unwrap_or(0);
            let limit = query.limit.unwrap_or(50);
            
            let has_more = total > offset + limit;
            let tasks: Vec<_> = tasks
                .into_iter()
                .skip(offset)
                .take(limit)
                .map(|t| Self::task_to_dto(&t))
                .collect();
            
            Ok(TaskListDto {
                tasks,
                total,
                has_more,
            })
        }
        
        fn task_to_dto(task: &Task) -> TaskDto {
            TaskDto {
                id: task.id().value().to_string(),
                content: task.content().value().to_string(),
                status: format!("{:?}", task.status()),
                priority: format!("{:?}", task.priority()),
                due_date: task.due_date().map(|d| d.to_rfc3339()),
                is_overdue: task.is_overdue(),
                created_at: task.created_at().to_rfc3339(),
                updated_at: task.updated_at().to_rfc3339(),
            }
        }
    }
    
    #[derive(Debug, thiserror::Error)]
    pub enum QueryError {
        #[error("Domain error: {0}")]
        Domain(#[from] DomainError),
        
        #[error("Repository error: {0}")]
        Repository(#[from] RepositoryError),
        
        #[error("Task not found")]
        TaskNotFound,
    }
}
```

#### 16.3 å¾®æœåŠ¡æ¶æ„å‡†å¤‡
```rust
// API ç½‘å…³å±‚
pub mod api_gateway {
    use axum::{
        Router,
        routing::{get, post, put, delete},
        extract::{Path, Query, State},
        Json,
    };
    
    pub struct ApiGateway {
        command_handler: Arc<TaskCommandHandler>,
        query_handler: Arc<TaskQueryHandler>,
    }
    
    impl ApiGateway {
        pub fn new(
            command_handler: Arc<TaskCommandHandler>,
            query_handler: Arc<TaskQueryHandler>,
        ) -> Self {
            Self { command_handler, query_handler }
        }
        
        pub fn router(self) -> Router {
            Router::new()
                .route("/api/tasks", post(Self::create_task))
                .route("/api/tasks", get(Self::list_tasks))
                .route("/api/tasks/:id", get(Self::get_task))
                .route("/api/tasks/:id", put(Self::update_task))
                .route("/api/tasks/:id", delete(Self::delete_task))
                .route("/api/tasks/:id/complete", post(Self::complete_task))
                .with_state(Arc::new(self))
        }
        
        async fn create_task(
            State(gateway): State<Arc<ApiGateway>>,
            Json(request): Json<CreateTaskRequest>,
        ) -> Result<Json<CreateTaskResponse>, ApiError> {
            let command = CreateTaskCommand {
                content: request.content,
                priority: request.priority,
                due_date: request.due_date,
            };
            
            let task_id = gateway.command_handler.handle_create_task(command).await?;
            
            Ok(Json(CreateTaskResponse {
                task_id: task_id.value().to_string(),
            }))
        }
        
        async fn list_tasks(
            State(gateway): State<Arc<ApiGateway>>,
            Query(params): Query<ListTasksParams>,
        ) -> Result<Json<TaskListDto>, ApiError> {
            let query = ListTasksQuery {
                status: params.status,
                priority: params.priority,
                limit: params.limit,
                offset: params.offset,
            };
            
            let result = gateway.query_handler.handle_list_tasks(query).await?;
            
            Ok(Json(result))
        }
        
        // ... å…¶ä»–ç«¯ç‚¹
    }
    
    #[derive(Debug, Deserialize)]
    pub struct CreateTaskRequest {
        pub content: String,
        pub priority: Option<Priority>,
        pub due_date: Option<chrono::DateTime<chrono::Utc>>,
    }
    
    #[derive(Debug, Serialize)]
    pub struct CreateTaskResponse {
        pub task_id: String,
    }
    
    #[derive(Debug, Deserialize)]
    pub struct ListTasksParams {
        pub status: Option<TaskStatus>,
        pub priority: Option<Priority>,
        pub limit: Option<usize>,
        pub offset: Option<usize>,
    }
    
    #[derive(Debug, thiserror::Error)]
    pub enum ApiError {
        #[error("Command error: {0}")]
        Command(#[from] CommandError),
        
        #[error("Query error: {0}")]
        Query(#[from] QueryError),
    }
}
```



---

## ğŸ¯ å®Œæ•´å®æ–½è®¡åˆ’ï¼ˆæ‰©å±•ç‰ˆï¼‰

### é˜¶æ®µ 0ï¼šå‡†å¤‡é˜¶æ®µï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**: å»ºç«‹åŸºç¡€è®¾æ–½å’Œå·¥å…·é“¾

**ä»»åŠ¡**:
- [ ] è®¾ç½® CI/CD æµæ°´çº¿
- [ ] é…ç½®ä»£ç è´¨é‡å·¥å…·ï¼ˆclippy, rustfmt, cargo-auditï¼‰
- [ ] å»ºç«‹æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] åˆ›å»ºå¼€å‘æ–‡æ¡£
- [ ] è®¾ç½®é—®é¢˜è·Ÿè¸ªç³»ç»Ÿ

### é˜¶æ®µ 1ï¼šæ ¸å¿ƒæ€§èƒ½ä¼˜åŒ–ï¼ˆ3å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šç´¢å¼•å’Œç¼“å­˜**
- [ ] å®ç°ç´¢å¼•å¢é‡æ›´æ–°
- [ ] æ·»åŠ æŸ¥è¯¢ç»“æœç¼“å­˜
- [ ] ä¼˜åŒ–æ•°æ®åº“è¿æ¥ç®¡ç†
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

**ç¬¬2å‘¨ï¼šè§‚å¯Ÿè€…å’Œå“åº”å¼**
- [ ] å®ç°ç‰ˆæœ¬å·æœºåˆ¶
- [ ] ä¼˜åŒ–è§‚å¯Ÿè€…è®¢é˜…
- [ ] æ·»åŠ è„æ ‡è®°ç³»ç»Ÿ
- [ ] å‡å°‘ä¸å¿…è¦çš„é‡æ–°æ¸²æŸ“

**ç¬¬3å‘¨ï¼šå†…å­˜å’Œç¼–è¯‘ä¼˜åŒ–**
- [ ] ä¼˜åŒ– Arc ä½¿ç”¨
- [ ] æ”¹è¿›ç¼–è¯‘é…ç½®
- [ ] å®ç°æ‰¹é‡æ“ä½œ
- [ ] å†…å­˜æ³„æ¼æ£€æµ‹

**éªŒæ”¶æ ‡å‡†**:
- ä»»åŠ¡æ“ä½œå“åº”æ—¶é—´ < 50ms
- è§†å›¾åˆ‡æ¢å»¶è¿Ÿ < 100ms
- ç¼–è¯‘æ—¶é—´å‡å°‘ 30%
- å†…å­˜ä½¿ç”¨ç¨³å®š

### é˜¶æ®µ 2ï¼šç”¨æˆ·ä½“éªŒæå‡ï¼ˆ3å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šäº¤äº’ä¼˜åŒ–**
- [ ] å®ç°é”®ç›˜å¿«æ·é”®ç³»ç»Ÿ
- [ ] æ·»åŠ æ‹–æ‹½æ’åº
- [ ] æ”¹è¿›é”™è¯¯æç¤º
- [ ] æ·»åŠ åŠ è½½çŠ¶æ€

**ç¬¬2å‘¨ï¼šè§†è§‰ä¼˜åŒ–**
- [ ] å¢å¼ºè§†è§‰å±‚æ¬¡
- [ ] ä¼˜åŒ–é¢œè‰²ç³»ç»Ÿ
- [ ] æ·»åŠ åŠ¨ç”»å’Œè¿‡æ¸¡
- [ ] æ”¹è¿›å›¾æ ‡å’Œå­—ä½“

**ç¬¬3å‘¨ï¼šæ™ºèƒ½åŠŸèƒ½**
- [ ] è‡ªç„¶è¯­è¨€è¾“å…¥è§£æ
- [ ] æ™ºèƒ½æé†’ç³»ç»Ÿ
- [ ] ä»»åŠ¡ä¼˜å…ˆçº§å»ºè®®
- [ ] æ—¶é—´ä¼°ç®—

**éªŒæ”¶æ ‡å‡†**:
- æ‰€æœ‰ä¸»è¦æ“ä½œæ”¯æŒå¿«æ·é”®
- UI åŠ¨ç”»æµç•…ï¼ˆ60fpsï¼‰
- ç”¨æˆ·æ»¡æ„åº¦æå‡ 40%

### é˜¶æ®µ 3ï¼šé«˜çº§åŠŸèƒ½ï¼ˆ4å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šæœç´¢å’Œåˆ†æ**
- [ ] å…¨æ–‡æœç´¢å¼•æ“
- [ ] æ¨¡ç³Šæœç´¢
- [ ] ä»»åŠ¡ç»Ÿè®¡åˆ†æ
- [ ] å¯è§†åŒ–å›¾è¡¨

**ç¬¬2å‘¨ï¼šåä½œåŠŸèƒ½**
- [ ] å®æ—¶åä½œç³»ç»Ÿ
- [ ] WebSocket é€šä¿¡
- [ ] å†²çªè§£å†³
- [ ] ç”¨æˆ·åœ¨çº¿çŠ¶æ€

**ç¬¬3å‘¨ï¼šç¦»çº¿æ”¯æŒ**
- [ ] ç¦»çº¿ä¼˜å…ˆæ¶æ„
- [ ] åŒæ­¥é˜Ÿåˆ—
- [ ] å†²çªæ£€æµ‹
- [ ] è‡ªåŠ¨é‡è¿

**ç¬¬4å‘¨ï¼šAI é›†æˆ**
- [ ] AI åŠ©æ‰‹é›†æˆ
- [ ] ä»»åŠ¡åˆ†è§£
- [ ] æ™ºèƒ½æ—¥ç¨‹å®‰æ’
- [ ] æ ‡ç­¾å»ºè®®

**éªŒæ”¶æ ‡å‡†**:
- æœç´¢å“åº”æ—¶é—´ < 200ms
- ç¦»çº¿æ¨¡å¼æ­£å¸¸å·¥ä½œ
- AI å»ºè®®å‡†ç¡®ç‡ > 80%

### é˜¶æ®µ 4ï¼šæ’ä»¶å’Œæ‰©å±•ï¼ˆ3å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šæ’ä»¶ç³»ç»Ÿ**
- [ ] å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
- [ ] æ’ä»¶é€šä¿¡æ€»çº¿
- [ ] æƒé™å’Œæ²™ç®±
- [ ] æ’ä»¶å¸‚åœº

**ç¬¬2å‘¨ï¼šçƒ­é‡è½½å’Œæ›´æ–°**
- [ ] æ’ä»¶çƒ­é‡è½½
- [ ] è‡ªåŠ¨æ›´æ–°ç³»ç»Ÿ
- [ ] ç‰ˆæœ¬ç®¡ç†
- [ ] å›æ»šæœºåˆ¶

**ç¬¬3å‘¨ï¼šç¤ºä¾‹æ’ä»¶**
- [ ] ç•ªèŒ„é’Ÿæ’ä»¶
- [ ] GitHub é›†æˆ
- [ ] æ—¥å†åŒæ­¥
- [ ] å¯¼å‡ºæ’ä»¶

**éªŒæ”¶æ ‡å‡†**:
- æ’ä»¶ç³»ç»Ÿç¨³å®šè¿è¡Œ
- æ”¯æŒçƒ­é‡è½½
- è‡³å°‘ 5 ä¸ªç¤ºä¾‹æ’ä»¶

### é˜¶æ®µ 5ï¼šæ¶æ„é‡æ„ï¼ˆ4å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šé¢†åŸŸé©±åŠ¨è®¾è®¡**
- [ ] å®šä¹‰é¢†åŸŸæ¨¡å‹
- [ ] å®ç°å€¼å¯¹è±¡
- [ ] é¢†åŸŸæœåŠ¡
- [ ] é¢†åŸŸäº‹ä»¶

**ç¬¬2å‘¨ï¼šCQRS æ¨¡å¼**
- [ ] å‘½ä»¤å¤„ç†å™¨
- [ ] æŸ¥è¯¢å¤„ç†å™¨
- [ ] äº‹ä»¶æº¯æº
- [ ] è¯»å†™åˆ†ç¦»

**ç¬¬3å‘¨ï¼šå¾®æœåŠ¡å‡†å¤‡**
- [ ] API ç½‘å…³
- [ ] æœåŠ¡å‘ç°
- [ ] è´Ÿè½½å‡è¡¡
- [ ] ç†”æ–­å™¨

**ç¬¬4å‘¨ï¼šæµ‹è¯•å’Œæ–‡æ¡£**
- [ ] å•å…ƒæµ‹è¯•
- [ ] é›†æˆæµ‹è¯•
- [ ] API æ–‡æ¡£
- [ ] æ¶æ„æ–‡æ¡£

**éªŒæ”¶æ ‡å‡†**:
- æµ‹è¯•è¦†ç›–ç‡ > 70%
- æ¶æ„æ¸…æ™°å¯ç»´æŠ¤
- æ–‡æ¡£å®Œæ•´

### é˜¶æ®µ 6ï¼šå›½é™…åŒ–å’Œæœ¬åœ°åŒ–ï¼ˆ2å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šå¤šè¯­è¨€æ”¯æŒ**
- [ ] åŠ¨æ€è¯­è¨€åˆ‡æ¢
- [ ] å¤æ•°è§„åˆ™
- [ ] æ—¥æœŸæ ¼å¼åŒ–
- [ ] æ•°å­—æ ¼å¼åŒ–

**ç¬¬2å‘¨ï¼šRTL å’Œæ–‡åŒ–é€‚é…**
- [ ] RTL å¸ƒå±€æ”¯æŒ
- [ ] æ–‡åŒ–ç‰¹å®šæ ¼å¼
- [ ] ç¿»è¯‘ç®¡ç†
- [ ] è¯­è¨€åŒ…

**éªŒæ”¶æ ‡å‡†**:
- æ”¯æŒè‡³å°‘ 5 ç§è¯­è¨€
- RTL è¯­è¨€æ­£å¸¸æ˜¾ç¤º
- ç¿»è¯‘è¦†ç›–ç‡ > 95%

### é˜¶æ®µ 7ï¼šéƒ¨ç½²å’Œè¿ç»´ï¼ˆ2å‘¨ï¼‰

**ç¬¬1å‘¨ï¼šæ„å»ºå’Œæ‰“åŒ…**
- [ ] è·¨å¹³å°æ„å»º
- [ ] å®‰è£…ç¨‹åº
- [ ] è‡ªåŠ¨ç­¾å
- [ ] å‘å¸ƒæµç¨‹

**ç¬¬2å‘¨ï¼šç›‘æ§å’Œè¯Šæ–­**
- [ ] æ€§èƒ½ç›‘æ§
- [ ] é”™è¯¯è¿½è¸ª
- [ ] ä½¿ç”¨ç»Ÿè®¡
- [ ] å¥åº·æ£€æŸ¥

**éªŒæ”¶æ ‡å‡†**:
- æ”¯æŒ Windows/macOS/Linux
- è‡ªåŠ¨åŒ–å‘å¸ƒæµç¨‹
- å®Œæ•´çš„ç›‘æ§ç³»ç»Ÿ

---

## ğŸ“Š é¢„æœŸæ”¶ç›Šæ€»ç»“

### æ€§èƒ½æå‡
- **å“åº”é€Ÿåº¦**: æå‡ 50-70%
- **å†…å­˜ä½¿ç”¨**: å‡å°‘ 30-40%
- **ç¼–è¯‘æ—¶é—´**: å‡å°‘ 30-50%
- **å¯åŠ¨æ—¶é—´**: å‡å°‘ 40%

### ç”¨æˆ·ä½“éªŒ
- **æ“ä½œæ•ˆç‡**: æå‡ 40-60%ï¼ˆå¿«æ·é”®ã€æ™ºèƒ½è¾“å…¥ï¼‰
- **è§†è§‰ä½“éªŒ**: æå‡ 50%ï¼ˆåŠ¨ç”»ã€å±‚æ¬¡æ„Ÿï¼‰
- **é”™è¯¯å¤„ç†**: æå‡ 80%ï¼ˆå‹å¥½æç¤ºï¼‰
- **å­¦ä¹ æ›²çº¿**: é™ä½ 30%ï¼ˆæ›´å¥½çš„å¼•å¯¼ï¼‰

### ä»£ç è´¨é‡
- **å¯ç»´æŠ¤æ€§**: æå‡ 60%ï¼ˆæ¸…æ™°æ¶æ„ï¼‰
- **æµ‹è¯•è¦†ç›–**: ä» 0% åˆ° 70%+
- **æ–‡æ¡£å®Œæ•´æ€§**: æå‡ 80%
- **Bug ç‡**: é™ä½ 50%

### åŠŸèƒ½ä¸°å¯Œåº¦
- **æ ¸å¿ƒåŠŸèƒ½**: å¢åŠ  15+ æ–°åŠŸèƒ½
- **æ’ä»¶ç”Ÿæ€**: æ”¯æŒæ— é™æ‰©å±•
- **AI èƒ½åŠ›**: æ™ºèƒ½åŒ–ç¨‹åº¦æå‡ 100%
- **åä½œèƒ½åŠ›**: ä»æ— åˆ°æœ‰

### å•†ä¸šä»·å€¼
- **ç”¨æˆ·ç•™å­˜**: æå‡ 40%
- **ç”¨æˆ·æ»¡æ„åº¦**: æå‡ 50%
- **å¸‚åœºç«äº‰åŠ›**: æå‡ 60%
- **å¯æ‰©å±•æ€§**: æå‡ 100%

---

## ğŸ”„ æŒç»­æ”¹è¿›å»ºè®®

### æ¯å‘¨
- ä»£ç å®¡æŸ¥
- æ€§èƒ½ç›‘æ§
- ç”¨æˆ·åé¦ˆæ”¶é›†
- Bug ä¿®å¤

### æ¯æœˆ
- åŠŸèƒ½è¿­ä»£
- æ€§èƒ½ä¼˜åŒ–
- æ–‡æ¡£æ›´æ–°
- å®‰å…¨å®¡è®¡

### æ¯å­£åº¦
- æ¶æ„è¯„å®¡
- æŠ€æœ¯å€ºåŠ¡æ¸…ç†
- å¤§ç‰ˆæœ¬å‘å¸ƒ
- ç”¨æˆ·è°ƒç ”

### æ¯å¹´
- æŠ€æœ¯æ ˆå‡çº§
- é‡å¤§é‡æ„
- æˆ˜ç•¥è§„åˆ’
- å›¢é˜ŸåŸ¹è®­

---

## ğŸ“š æ¨èå­¦ä¹ èµ„æº

### Rust è¿›é˜¶
- [The Rust Performance Book](https://nnethercote.github.io/perf-book/)
- [Rust Design Patterns](https://rust-unofficial.github.io/patterns/)
- [Async Rust](https://rust-lang.github.io/async-book/)

### æ¶æ„è®¾è®¡
- [Domain-Driven Design](https://www.domainlanguage.com/ddd/)
- [Microservices Patterns](https://microservices.io/patterns/)
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)

### UI/UX
- [Laws of UX](https://lawsofux.com/)
- [Refactoring UI](https://www.refactoringui.com/)
- [Material Design](https://material.io/design)

### æ€§èƒ½ä¼˜åŒ–
- [High Performance Browser Networking](https://hpbn.co/)
- [Systems Performance](http://www.brendangregg.com/systems-performance-2nd-edition-book.html)

---

## ğŸ“ æœ€ç»ˆæ€»ç»“

è¿™ä»½ä¼˜åŒ–æ–¹æ¡ˆæ¶µç›–äº† **16 ä¸ªä¸»è¦ç»´åº¦**ï¼ŒåŒ…å« **200+ æ¡å…·ä½“ä¼˜åŒ–å»ºè®®**ï¼Œé¢„è®¡å®æ–½å‘¨æœŸ **20-24 å‘¨**ã€‚

### æ ¸å¿ƒäº®ç‚¹

1. **å…¨é¢æ€§**: ä»æ€§èƒ½åˆ°ç”¨æˆ·ä½“éªŒï¼Œä»æ¶æ„åˆ°éƒ¨ç½²ï¼Œè¦†ç›–æ‰€æœ‰æ–¹é¢
2. **å®ç”¨æ€§**: æ¯æ¡å»ºè®®éƒ½æœ‰å®Œæ•´çš„ä»£ç ç¤ºä¾‹å’Œå®æ–½æ­¥éª¤
3. **å¯è¡Œæ€§**: åˆ†é˜¶æ®µå®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰æ˜ç¡®çš„ç›®æ ‡å’ŒéªŒæ”¶æ ‡å‡†
4. **å‰ç»æ€§**: åŒ…å« AIã€åä½œã€å¾®æœåŠ¡ç­‰å‰æ²¿æŠ€æœ¯
5. **å¯æ‰©å±•æ€§**: æ’ä»¶ç³»ç»Ÿå’Œæ¨¡å—åŒ–è®¾è®¡æ”¯æŒæ— é™æ‰©å±•

### å…³é”®æˆåŠŸå› ç´ 

1. **å›¢é˜Ÿåä½œ**: éœ€è¦å‰ç«¯ã€åç«¯ã€UI/UX ç­‰å¤šæ–¹é¢äººæ‰
2. **æŒç»­è¿­ä»£**: ä¸è¦è¯•å›¾ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰ä¼˜åŒ–
3. **ç”¨æˆ·åé¦ˆ**: åŠæ—¶æ”¶é›†å’Œå“åº”ç”¨æˆ·åé¦ˆ
4. **æ€§èƒ½ç›‘æ§**: å»ºç«‹å®Œå–„çš„ç›‘æ§ä½“ç³»
5. **æ–‡æ¡£ç»´æŠ¤**: ä¿æŒæ–‡æ¡£ä¸ä»£ç åŒæ­¥

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **è¯„ä¼°ç°çŠ¶**: ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·è¯„ä¼°å½“å‰çŠ¶æ€
2. **ç¡®å®šä¼˜å…ˆçº§**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´å®æ–½é¡ºåº
3. **ç»„å»ºå›¢é˜Ÿ**: åˆ†é…ä»»åŠ¡å’Œè´£ä»»
4. **å¼€å§‹å®æ–½**: ä»é«˜ä¼˜å…ˆçº§é¡¹ç›®å¼€å§‹
5. **æŒç»­è·Ÿè¸ª**: å®šæœŸè¯„ä¼°è¿›åº¦å’Œæ•ˆæœ

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0 (æ‰©å±•ç‰ˆ)  
**æœ€åæ›´æ–°**: 2026-02-19  
**ä½œè€…**: Claude (Kiro AI Assistant)  
**æ€»é¡µæ•°**: çº¦ 150 é¡µ  
**ä»£ç ç¤ºä¾‹**: 100+ ä¸ª  
**ä¼˜åŒ–å»ºè®®**: 200+ æ¡

